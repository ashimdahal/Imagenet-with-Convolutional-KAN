{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":19988,"databundleVersionId":1651354,"sourceType":"competition"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/IvanDrokin/torch-conv-kan.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T04:11:11.774855Z","iopub.execute_input":"2025-01-16T04:11:11.775249Z","iopub.status.idle":"2025-01-16T04:11:12.877292Z","shell.execute_reply.started":"2025-01-16T04:11:11.775220Z","shell.execute_reply":"2025-01-16T04:11:12.876102Z"}},"outputs":[{"name":"stdout","text":"fatal: destination path 'torch-conv-kan' already exists and is not an empty directory.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"!mv torch-conv-kan/* ./","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T04:11:12.879441Z","iopub.execute_input":"2025-01-16T04:11:12.879766Z","iopub.status.idle":"2025-01-16T04:11:13.979011Z","shell.execute_reply.started":"2025-01-16T04:11:12.879736Z","shell.execute_reply":"2025-01-16T04:11:13.977686Z"}},"outputs":[{"name":"stdout","text":"mv: cannot stat 'torch-conv-kan/*': No such file or directory\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"!pip install torchsummary\n!pip install fvcore","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T04:11:13.981012Z","iopub.execute_input":"2025-01-16T04:11:13.981396Z","iopub.status.idle":"2025-01-16T04:11:31.912469Z","shell.execute_reply.started":"2025-01-16T04:11:13.981362Z","shell.execute_reply":"2025-01-16T04:11:31.911462Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchsummary in /opt/conda/lib/python3.10/site-packages (1.5.1)\nRequirement already satisfied: fvcore in /opt/conda/lib/python3.10/site-packages (0.1.5.post20221221)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from fvcore) (1.26.4)\nRequirement already satisfied: yacs>=0.1.6 in /opt/conda/lib/python3.10/site-packages (from fvcore) (0.1.8)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from fvcore) (6.0.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from fvcore) (4.66.4)\nRequirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.10/site-packages (from fvcore) (2.4.0)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from fvcore) (10.3.0)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from fvcore) (0.9.0)\nRequirement already satisfied: iopath>=0.1.7 in /opt/conda/lib/python3.10/site-packages (from fvcore) (0.1.10)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from iopath>=0.1.7->fvcore) (4.12.2)\nRequirement already satisfied: portalocker in /opt/conda/lib/python3.10/site-packages (from iopath>=0.1.7->fvcore) (3.1.1)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"!pip install -r requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T04:11:31.915519Z","iopub.execute_input":"2025-01-16T04:11:31.915834Z","iopub.status.idle":"2025-01-16T04:11:52.778971Z","shell.execute_reply.started":"2025-01-16T04:11:31.915802Z","shell.execute_reply":"2025-01-16T04:11:52.777795Z"}},"outputs":[{"name":"stdout","text":"Collecting optuna@ git+https://github.com/optuna/optuna (from -r requirements.txt (line 19))\n  Cloning https://github.com/optuna/optuna to /tmp/pip-install-wn61w3rr/optuna_8c06607fe14c43c685e2ce2e60b8809d\n  Running command git clone --filter=blob:none --quiet https://github.com/optuna/optuna /tmp/pip-install-wn61w3rr/optuna_8c06607fe14c43c685e2ce2e60b8809d\n  Resolved https://github.com/optuna/optuna to commit 92df0b25569bb8133da308a615a483785d12cb35\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.4.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.19.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (4.66.4)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.34.2)\nRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.18.3)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (1.2.2)\nRequirement already satisfied: omegaconf in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (2.3.0)\nRequirement already satisfied: hydra-core in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.3.2)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (3.0.1)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (10.3.0)\nRequirement already satisfied: torchinfo in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (1.8.0)\nRequirement already satisfied: torchmetrics in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (1.4.2)\nRequirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (0.8.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (3.7.5)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (0.25.1)\nRequirement already satisfied: lion-pytorch in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (0.2.3)\nRequirement already satisfied: imbalanced-learn in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 17)) (0.12.3)\nRequirement already satisfied: albumentations in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 18)) (1.4.17)\nRequirement already satisfied: medpy in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 21)) (0.5.2)\nRequirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 22)) (1.0.9)\nRequirement already satisfied: ray[tune] in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 20)) (2.24.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (2024.6.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->-r requirements.txt (line 2)) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate->-r requirements.txt (line 4)) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->-r requirements.txt (line 4)) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate->-r requirements.txt (line 4)) (6.0.2)\nRequirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate->-r requirements.txt (line 4)) (0.4.5)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 5)) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 5)) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 5)) (3.1.43)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 5)) (3.11.0)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 5)) (3.20.3)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 5)) (2.32.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 5)) (2.15.0)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 5)) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 5)) (70.0.0)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->-r requirements.txt (line 6)) (1.14.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->-r requirements.txt (line 6)) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->-r requirements.txt (line 6)) (3.5.0)\nRequirement already satisfied: antlr4-python3-runtime==4.9.* in /opt/conda/lib/python3.10/site-packages (from omegaconf->-r requirements.txt (line 7)) (4.9.3)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 9)) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 9)) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 9)) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 9)) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 9)) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 9)) (3.9.5)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics->-r requirements.txt (line 12)) (0.11.7)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 14)) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 14)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 14)) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 14)) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 14)) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 14)) (2.9.0.post0)\nRequirement already satisfied: scikit-image>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from albumentations->-r requirements.txt (line 18)) (0.23.2)\nRequirement already satisfied: pydantic>=2.7.0 in /opt/conda/lib/python3.10/site-packages (from albumentations->-r requirements.txt (line 18)) (2.9.2)\nRequirement already satisfied: albucore==0.0.17 in /opt/conda/lib/python3.10/site-packages (from albumentations->-r requirements.txt (line 18)) (0.0.17)\nRequirement already satisfied: eval-type-backport in /opt/conda/lib/python3.10/site-packages (from albumentations->-r requirements.txt (line 18)) (0.2.0)\nRequirement already satisfied: opencv-python-headless>=4.9.0.80 in /opt/conda/lib/python3.10/site-packages (from albumentations->-r requirements.txt (line 18)) (4.10.0.84)\nRequirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna@ git+https://github.com/optuna/optuna->-r requirements.txt (line 19)) (1.13.3)\nRequirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna@ git+https://github.com/optuna/optuna->-r requirements.txt (line 19)) (6.8.2)\nRequirement already satisfied: sqlalchemy>=1.4.2 in /opt/conda/lib/python3.10/site-packages (from optuna@ git+https://github.com/optuna/optuna->-r requirements.txt (line 19)) (2.0.30)\nRequirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from ray[tune]->-r requirements.txt (line 20)) (4.22.0)\nRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray[tune]->-r requirements.txt (line 20)) (1.0.8)\nRequirement already satisfied: aiosignal in /opt/conda/lib/python3.10/site-packages (from ray[tune]->-r requirements.txt (line 20)) (1.3.1)\nRequirement already satisfied: frozenlist in /opt/conda/lib/python3.10/site-packages (from ray[tune]->-r requirements.txt (line 20)) (1.4.1)\nRequirement already satisfied: tensorboardX>=1.9 in /opt/conda/lib/python3.10/site-packages (from ray[tune]->-r requirements.txt (line 20)) (2.6.2.2)\nRequirement already satisfied: SimpleITK>=2.1 in /opt/conda/lib/python3.10/site-packages (from medpy->-r requirements.txt (line 21)) (2.4.0)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna@ git+https://github.com/optuna/optuna->-r requirements.txt (line 19)) (1.3.5)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 5)) (1.16.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 9)) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 9)) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 9)) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 9)) (4.0.3)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5)) (4.0.11)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations->-r requirements.txt (line 18)) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations->-r requirements.txt (line 18)) (2.23.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 5)) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 5)) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 5)) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 5)) (2024.8.30)\nRequirement already satisfied: imageio>=2.33 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations->-r requirements.txt (line 18)) (2.34.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations->-r requirements.txt (line 18)) (2024.5.22)\nRequirement already satisfied: lazy-loader>=0.4 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations->-r requirements.txt (line 18)) (0.4)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.4.2->optuna@ git+https://github.com/optuna/optuna->-r requirements.txt (line 19)) (3.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->-r requirements.txt (line 1)) (2.1.5)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray[tune]->-r requirements.txt (line 20)) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray[tune]->-r requirements.txt (line 20)) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray[tune]->-r requirements.txt (line 20)) (0.18.1)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 9)) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 9)) (2024.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5)) (5.0.1)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"!pip install iterative-stratification","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T04:11:52.780410Z","iopub.execute_input":"2025-01-16T04:11:52.780729Z","iopub.status.idle":"2025-01-16T04:12:01.719123Z","shell.execute_reply.started":"2025-01-16T04:11:52.780697Z","shell.execute_reply":"2025-01-16T04:12:01.717766Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: iterative-stratification in /opt/conda/lib/python3.10/site-packages (0.1.9)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from iterative-stratification) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from iterative-stratification) (1.14.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from iterative-stratification) (1.2.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->iterative-stratification) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->iterative-stratification) (3.5.0)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"from torchsummary import summary\nimport time\nfrom fvcore.nn import FlopCountAnalysis","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T04:12:01.720852Z","iopub.execute_input":"2025-01-16T04:12:01.721193Z","iopub.status.idle":"2025-01-16T04:12:01.726104Z","shell.execute_reply.started":"2025-01-16T04:12:01.721161Z","shell.execute_reply":"2025-01-16T04:12:01.725120Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-16T04:12:01.727596Z","iopub.execute_input":"2025-01-16T04:12:01.728267Z","iopub.status.idle":"2025-01-16T04:12:01.743423Z","shell.execute_reply.started":"2025-01-16T04:12:01.728237Z","shell.execute_reply":"2025-01-16T04:12:01.742578Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/lish-moa/train_targets_scored.csv\n/kaggle/input/lish-moa/sample_submission.csv\n/kaggle/input/lish-moa/train_drug.csv\n/kaggle/input/lish-moa/train_targets_nonscored.csv\n/kaggle/input/lish-moa/train_features.csv\n/kaggle/input/lish-moa/test_features.csv\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import sys\nsys.path.append('../input/iterative-stratification/iterative-stratification-master')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n\nimport numpy as np\nimport random\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport copy\nfrom copy import deepcopy as dp\nimport seaborn as sns\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import log_loss\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nfrom kan_convs import FastKANConv1DLayer\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndef norm_fit(df_1,saveM = True, sc_name = 'zsco'):   \n    from sklearn.preprocessing import StandardScaler,MinMaxScaler,MaxAbsScaler,RobustScaler,Normalizer,QuantileTransformer,PowerTransformer\n    ss_1_dic = {'zsco':StandardScaler(),\n                'mima':MinMaxScaler(),\n                'maxb':MaxAbsScaler(), \n                'robu':RobustScaler(),\n                'norm':Normalizer(), \n                'quan':QuantileTransformer(n_quantiles=100,random_state=0, output_distribution=\"normal\"),\n                'powe':PowerTransformer()}\n    ss_1 = ss_1_dic[sc_name]\n    df_2 = pd.DataFrame(ss_1.fit_transform(df_1),index = df_1.index,columns = df_1.columns)\n    if saveM == False:\n        return(df_2)\n    else:\n        return(df_2,ss_1)\n\ndef norm_tra(df_1,ss_x):\n    df_2 = pd.DataFrame(ss_x.transform(df_1),index = df_1.index,columns = df_1.columns)\n    return(df_2)\n\ndef g_table(list1):\n    table_dic = {}\n    for i in list1:\n        if i not in table_dic.keys():\n            table_dic[i] = 1\n        else:\n            table_dic[i] += 1\n    return(table_dic)\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(seed=42)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"execution":{"iopub.status.busy":"2025-01-16T04:12:01.745152Z","iopub.execute_input":"2025-01-16T04:12:01.745457Z","iopub.status.idle":"2025-01-16T04:12:01.759003Z","shell.execute_reply.started":"2025-01-16T04:12:01.745428Z","shell.execute_reply":"2025-01-16T04:12:01.758016Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"SEED = [0, 1, 2, 3 ,4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\ninput_dir = '../input/lish-moa/'\n\nsc_dic = {}\nfeat_dic = {}\ntrain_features = pd.read_csv(input_dir+'train_features.csv')\ntrain_targets_scored = pd.read_csv(input_dir+'train_targets_scored.csv')\ntrain_targets_nonscored = pd.read_csv(input_dir+'train_targets_nonscored.csv')\ntest_features = pd.read_csv(input_dir+'test_features.csv')\nsample_submission = pd.read_csv(input_dir+'sample_submission.csv')\ntrain_drug = pd.read_csv(input_dir+'train_drug.csv')\n\ntarget_cols = train_targets_scored.drop('sig_id', axis=1).columns.values.tolist()\ntarget_nonsc_cols = train_targets_nonscored.drop('sig_id', axis=1).columns.values.tolist()\n\n######## non-score ########\nnonctr_id = train_features.loc[train_features['cp_type']!='ctl_vehicle','sig_id'].tolist()\ntmp_con1 = [i in nonctr_id for i in train_targets_scored['sig_id']]\nmat_cor = pd.DataFrame(np.corrcoef(train_targets_scored.drop('sig_id',axis = 1)[tmp_con1].T,\n                      train_targets_nonscored.drop('sig_id',axis = 1)[tmp_con1].T))\nmat_cor2 = mat_cor.iloc[(train_targets_scored.shape[1]-1):,0:train_targets_scored.shape[1]-1]\nmat_cor2.index = target_nonsc_cols\nmat_cor2.columns = target_cols\nmat_cor2 = mat_cor2.dropna()\nmat_cor2_max = mat_cor2.abs().max(axis = 1)\n\nq_n_cut = 0.9\ntarget_nonsc_cols2 = mat_cor2_max[mat_cor2_max > np.quantile(mat_cor2_max,q_n_cut)].index.tolist()\nprint(len(target_nonsc_cols2))\n\nGENES = [col for col in train_features.columns if col.startswith('g-')]\nCELLS = [col for col in train_features.columns if col.startswith('c-')]\nfeat_dic['gene'] = GENES\nfeat_dic['cell'] = CELLS\n\n# sample norm \nq2 = train_features[feat_dic['gene']].apply(np.quantile,axis = 1,q = 0.25).copy()\nq7 = train_features[feat_dic['gene']].apply(np.quantile,axis = 1,q = 0.75).copy()\nqmean = (q2+q7)/2\ntrain_features[feat_dic['gene']] = (train_features[feat_dic['gene']].T - qmean.values).T\nq2 = test_features[feat_dic['gene']].apply(np.quantile,axis = 1,q = 0.25).copy()\nq7 = test_features[feat_dic['gene']].apply(np.quantile,axis = 1,q = 0.75).copy()\nqmean = (q2+q7)/2\ntest_features[feat_dic['gene']] = (test_features[feat_dic['gene']].T - qmean.values).T\n\nq2 = train_features[feat_dic['cell']].apply(np.quantile,axis = 1,q = 0.25).copy()\nq7 = train_features[feat_dic['cell']].apply(np.quantile,axis = 1,q = 0.72).copy()\nqmean = (q2+q7)/2\ntrain_features[feat_dic['cell']] = (train_features[feat_dic['cell']].T - qmean.values).T\nqmean2 = train_features[feat_dic['cell']].abs().apply(np.quantile,axis = 1,q = 0.75).copy()+4\ntrain_features[feat_dic['cell']] = (train_features[feat_dic['cell']].T / qmean2.values).T.copy()\n\nq2 = test_features[feat_dic['cell']].apply(np.quantile,axis = 1,q = 0.25).copy()\nq7 = test_features[feat_dic['cell']].apply(np.quantile,axis = 1,q = 0.72).copy()\nqmean = (q2+q7)/2\ntest_features[feat_dic['cell']] = (test_features[feat_dic['cell']].T - qmean.values).T\nqmean2 = test_features[feat_dic['cell']].abs().apply(np.quantile,axis = 1,q = 0.75).copy()+4\ntest_features[feat_dic['cell']] = (test_features[feat_dic['cell']].T / qmean2.values).T.copy()\n\n# remove ctl\ntrain = train_features.merge(train_targets_scored, on='sig_id')\ntrain = train.merge(train_targets_nonscored[['sig_id']+target_nonsc_cols2], on='sig_id')\n\ntrain = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\ntest = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n\ntarget = train[['sig_id']+target_cols]\ntarget_ns = train[['sig_id']+target_nonsc_cols2]\n\ntrain0 = train.drop('cp_type', axis=1)\ntest = test.drop('cp_type', axis=1)\n\ntarget_cols = target.drop('sig_id', axis=1).columns.values.tolist()\n\n# drug ids\ntar_sig = target['sig_id'].tolist()\ntrain_drug = train_drug.loc[[i in tar_sig for i in train_drug['sig_id']]]\ntarget = target.merge(train_drug, on='sig_id', how='left') \n\n# LOCATE DRUGS\nvc = train_drug.drug_id.value_counts()\nvc1 = vc.loc[vc <= 19].index\nvc2 = vc.loc[vc > 19].index\n\nfeature_cols = []\nfor key_i in feat_dic.keys():\n    value_i = feat_dic[key_i]\n    print(key_i,len(value_i))\n    feature_cols += value_i\nlen(feature_cols)\nfeature_cols0 = dp(feature_cols)\n    \noof = np.zeros((len(train), len(target_cols)))\npredictions = np.zeros((len(test), len(target_cols)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T04:12:01.760457Z","iopub.execute_input":"2025-01-16T04:12:01.760996Z","iopub.status.idle":"2025-01-16T04:12:33.811915Z","shell.execute_reply.started":"2025-01-16T04:12:01.760934Z","shell.execute_reply":"2025-01-16T04:12:33.810899Z"}},"outputs":[{"name":"stdout","text":"33\ngene 772\ncell 100\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# Averaging on multiple SEEDS\nfor seed in SEED:\n\n    seed_everything(seed=seed)\n    folds = train0.copy()\n    feature_cols = dp(feature_cols0)\n    \n    # kfold - leave drug out\n    target2 = target.copy()\n    dct1 = {}; dct2 = {}\n    skf = MultilabelStratifiedKFold(n_splits = 5) # , shuffle = True, random_state = seed\n    tmp = target2.groupby('drug_id')[target_cols].mean().loc[vc1]\n    tmp_idx = tmp.index.tolist()\n    tmp_idx.sort()\n    tmp_idx2 = random.sample(tmp_idx,len(tmp_idx))\n    tmp = tmp.loc[tmp_idx2]\n    for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[target_cols])):\n        dd = {k:fold for k in tmp.index[idxV].values}\n        dct1.update(dd)\n\n    # STRATIFY DRUGS MORE THAN 19X\n    skf = MultilabelStratifiedKFold(n_splits = 5) # , shuffle = True, random_state = seed\n    tmp = target2.loc[target2.drug_id.isin(vc2)].reset_index(drop = True)\n    tmp_idx = tmp.index.tolist()\n    tmp_idx.sort()\n    tmp_idx2 = random.sample(tmp_idx,len(tmp_idx))\n    tmp = tmp.loc[tmp_idx2]\n    for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[target_cols])):\n        dd = {k:fold for k in tmp.sig_id[idxV].values}\n        dct2.update(dd)\n\n    target2['kfold'] = target2.drug_id.map(dct1)\n    target2.loc[target2.kfold.isna(),'kfold'] = target2.loc[target2.kfold.isna(),'sig_id'].map(dct2)\n    target2.kfold = target2.kfold.astype(int)\n\n    folds['kfold'] = target2['kfold'].copy()\n\n    train = folds.copy()\n    test_ = test.copy()\n\n    # HyperParameters\n    DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n    EPOCHS = 25\n    BATCH_SIZE = 128\n    LEARNING_RATE = 1e-3\n    WEIGHT_DECAY = 1e-5\n    NFOLDS = 5\n    EARLY_STOPPING_STEPS = 10\n    EARLY_STOP = False\n\n    n_comp1 = 50\n    n_comp2 = 15\n\n    num_features=len(feature_cols) + n_comp1 + n_comp2\n    num_targets=len(target_cols)\n    num_targets_0=len(target_nonsc_cols2)\n    hidden_size=4096\n\n    tar_freq = np.array([np.min(list(g_table(train[target_cols].iloc[:,i]).values())) for i in range(len(target_cols))])\n    tar_weight0 = np.array([np.log(i+100) for i in tar_freq])\n    tar_weight0_min = dp(np.min(tar_weight0))\n    tar_weight = tar_weight0_min/tar_weight0\n    pos_weight = torch.tensor(tar_weight).to(DEVICE)\n    from torch.nn.modules.loss import _WeightedLoss\n    class SmoothBCEwLogits(_WeightedLoss):\n        def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n            super().__init__(weight=weight, reduction=reduction)\n            self.smoothing = smoothing\n            self.weight = weight\n            self.reduction = reduction\n\n        @staticmethod\n        def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n            assert 0 <= smoothing < 1\n            with torch.no_grad():\n                targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n            return targets\n\n        def forward(self, inputs, targets):\n            targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n                self.smoothing)\n            loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight,\n                                                      pos_weight = pos_weight)\n\n            if  self.reduction == 'sum':\n                loss = loss.sum()\n            elif  self.reduction == 'mean':\n                loss = loss.mean()\n\n            return loss\n\n    class TrainDataset:\n        def __init__(self, features, targets):\n            self.features = features\n            self.targets = targets\n\n        def __len__(self):\n            return (self.features.shape[0])\n\n        def __getitem__(self, idx):\n            dct = {\n                'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n                'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n            }\n            return dct\n\n    class TestDataset:\n        def __init__(self, features):\n            self.features = features\n\n        def __len__(self):\n            return (self.features.shape[0])\n\n        def __getitem__(self, idx):\n            dct = {\n                'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n            }\n            return dct\n\n\n    def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n        model.train()\n        final_loss = 0\n\n        for data in dataloader:\n            optimizer.zero_grad()\n            inputs, targets = data['x'].to(device), data['y'].to(device)\n            outputs = model(inputs)\n            loss = loss_fn(outputs, targets)\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n\n            final_loss += loss.item()\n\n        final_loss /= len(dataloader)\n\n        return final_loss\n\n\n    def valid_fn(model, loss_fn, dataloader, device):\n        model.eval()\n        final_loss = 0\n        valid_preds = []\n\n        for data in dataloader:\n            inputs, targets = data['x'].to(device), data['y'].to(device)\n            outputs = model(inputs)\n            loss = loss_fn(outputs, targets)\n\n            final_loss += loss.item()\n            valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n\n        final_loss /= len(dataloader)\n        valid_preds = np.concatenate(valid_preds)\n\n        return final_loss, valid_preds\n\n    def inference_fn(model, dataloader, device):\n        model.eval()\n        preds = []\n\n        for data in dataloader:\n            inputs = data['x'].to(device)\n            with torch.no_grad():\n                outputs = model(inputs)\n\n            preds.append(outputs.sigmoid().detach().cpu().numpy())\n\n        preds = np.concatenate(preds)\n\n        return preds\n\n    class Model(nn.Module):\n        def __init__(self, num_features, num_targets, hidden_size):\n            super(Model, self).__init__()\n#             cha_1 = 256\n#             cha_2 = 512\n#             cha_3 = 512\n            \n            cha_1 = 64\n            cha_2 = 128\n            cha_3 = 128\n\n            cha_1_reshape = int(hidden_size/cha_1)\n            cha_po_1 = int(hidden_size/cha_1/2)\n            cha_po_2 = int(hidden_size/cha_1/2/2) * cha_3\n\n            self.cha_1 = cha_1\n            self.cha_2 = cha_2\n            self.cha_3 = cha_3\n            self.cha_1_reshape = cha_1_reshape\n            self.cha_po_1 = cha_po_1\n            self.cha_po_2 = cha_po_2\n\n            self.batch_norm1 = nn.BatchNorm1d(num_features)\n            self.dropout1 = nn.Dropout(0.1)\n            self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n\n            self.batch_norm_c1 = nn.BatchNorm1d(cha_1)\n            self.dropout_c1 = nn.Dropout(0.1)\n            self.conv1 = FastKANConv1DLayer(cha_1,cha_2, kernel_size = 5, stride = 1, padding=2)\n\n            self.ave_po_c1 = nn.AdaptiveAvgPool1d(output_size = cha_po_1)\n\n            self.batch_norm_c2 = nn.BatchNorm1d(cha_2)\n            self.dropout_c2 = nn.Dropout(0.1)\n            self.conv2 = FastKANConv1DLayer(cha_2,cha_2, kernel_size = 3, stride = 1, padding=1)\n\n            self.batch_norm_c2_1 = nn.BatchNorm1d(cha_2)\n            self.dropout_c2_1 = nn.Dropout(0.3)\n            self.conv2_1 = FastKANConv1DLayer(cha_2,cha_2, kernel_size = 3, stride = 1, padding=1)\n\n            self.batch_norm_c2_2 = nn.BatchNorm1d(cha_2)\n            self.dropout_c2_2 = nn.Dropout(0.2)\n            self.conv2_2 = FastKANConv1DLayer(cha_2,cha_3, kernel_size = 5, stride = 1, padding=2)\n\n            self.max_po_c2 = nn.MaxPool1d(kernel_size=4, stride=2, padding=1)\n\n            self.flt = nn.Flatten()\n\n            self.batch_norm3 = nn.BatchNorm1d(cha_po_2)\n            self.dropout3 = nn.Dropout(0.2)\n            self.dense3 = nn.utils.weight_norm(nn.Linear(cha_po_2, num_targets))\n\n        def forward(self, x):\n\n            x = self.batch_norm1(x)\n            x = self.dropout1(x)\n            x = F.celu(self.dense1(x), alpha=0.06)\n\n            x = x.reshape(x.shape[0],self.cha_1,\n                          self.cha_1_reshape)\n\n            x = self.batch_norm_c1(x)\n            x = self.dropout_c1(x)\n            x = F.relu(self.conv1(x))\n\n            x = self.ave_po_c1(x)\n\n            x = self.batch_norm_c2(x)\n            x = self.dropout_c2(x)\n            x = F.relu(self.conv2(x))\n            x_s = x\n\n            x = self.batch_norm_c2_1(x)\n            x = self.dropout_c2_1(x)\n            x = F.relu(self.conv2_1(x))\n\n            x = self.batch_norm_c2_2(x)\n            x = self.dropout_c2_2(x)\n            x = F.relu(self.conv2_2(x))\n            x =  x * x_s\n\n            x = self.max_po_c2(x)\n\n            x = self.flt(x)\n\n            x = self.batch_norm3(x)\n            x = self.dropout3(x)\n            x = self.dense3(x)\n\n            return x\n\n    def run_training(fold, seed):\n\n        seed_everything(seed)\n\n        trn_idx = train[train['kfold'] != fold].index\n        val_idx = train[train['kfold'] == fold].index\n\n        train_df = train[train['kfold'] != fold].reset_index(drop=True).copy()\n        valid_df = train[train['kfold'] == fold].reset_index(drop=True).copy()\n\n        x_train, y_train,y_train_ns = train_df[feature_cols], train_df[target_cols].values,train_df[target_nonsc_cols2].values\n        x_valid, y_valid,y_valid_ns  =  valid_df[feature_cols], valid_df[target_cols].values,valid_df[target_nonsc_cols2].values\n        x_test = test_[feature_cols]\n\n        #------------ norm --------------\n        col_num = list(set(feat_dic['gene'] + feat_dic['cell']) & set(feature_cols))\n        col_num.sort()\n        x_train[col_num],ss = norm_fit(x_train[col_num],True,'quan')\n        x_valid[col_num]    = norm_tra(x_valid[col_num],ss)\n        x_test[col_num]     = norm_tra(x_test[col_num],ss)\n\n        #------------ pca --------------\n        def pca_pre(tr,va,te,\n                    n_comp,feat_raw,feat_new):\n            pca = PCA(n_components=n_comp, random_state=42)\n            tr2 = pd.DataFrame(pca.fit_transform(tr[feat_raw]),columns=feat_new)\n            va2 = pd.DataFrame(pca.transform(va[feat_raw]),columns=feat_new)\n            te2 = pd.DataFrame(pca.transform(te[feat_raw]),columns=feat_new)\n            return(tr2,va2,te2)\n\n\n        pca_feat_g = [f'pca_G-{i}' for i in range(n_comp1)]\n        feat_dic['pca_g'] = pca_feat_g\n        x_tr_g_pca,x_va_g_pca,x_te_g_pca = pca_pre(x_train,x_valid,x_test,\n                                                   n_comp1,feat_dic['gene'],pca_feat_g)\n        x_train = pd.concat([x_train,x_tr_g_pca],axis = 1)\n        x_valid = pd.concat([x_valid,x_va_g_pca],axis = 1)\n        x_test  = pd.concat([x_test,x_te_g_pca],axis = 1)\n\n        pca_feat_g = [f'pca_C-{i}' for i in range(n_comp2)]\n        feat_dic['pca_c'] = pca_feat_g\n        x_tr_c_pca,x_va_c_pca,x_te_c_pca = pca_pre(x_train,x_valid,x_test,\n                                                   n_comp2,feat_dic['cell'],pca_feat_g)\n        x_train = pd.concat([x_train,x_tr_c_pca],axis = 1)\n        x_valid = pd.concat([x_valid,x_va_c_pca],axis = 1)\n        x_test  = pd.concat([x_test,x_te_c_pca], axis = 1)\n\n        x_train,x_valid,x_test = x_train.values,x_valid.values,x_test.values\n\n        train_dataset = TrainDataset(x_train, y_train_ns)\n        valid_dataset = TrainDataset(x_valid, y_valid_ns)\n        trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n        validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n        model = Model(\n            num_features=num_features,\n            num_targets=num_targets_0,\n            hidden_size=hidden_size,\n        )\n\n        model.to(DEVICE)\n\n        optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=0.0001)\n        scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e5, \n                                                  max_lr=0.0001, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n\n        loss_tr = nn.BCEWithLogitsLoss()   #SmoothBCEwLogits(smoothing = 0.001)\n        loss_va = nn.BCEWithLogitsLoss()    \n\n        early_stopping_steps = EARLY_STOPPING_STEPS\n        early_step = 0\n\n        for epoch in range(1):\n            train_loss = train_fn(model, optimizer,scheduler, loss_tr, trainloader, DEVICE)\n            valid_loss, valid_preds = valid_fn(model, loss_va, validloader, DEVICE)\n            print(f\"FOLD: {fold}, EPOCH: {epoch},train_loss: {train_loss}, valid_loss: {valid_loss}\")\n\n        model.dense3 = nn.utils.weight_norm(nn.Linear(model.cha_po_2, num_targets))\n        model.to(DEVICE)\n\n        train_dataset = TrainDataset(x_train, y_train)\n        valid_dataset = TrainDataset(x_valid, y_valid)\n        trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n        validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n        optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n        scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n                                                  max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n\n        loss_tr = SmoothBCEwLogits(smoothing = 0.001)\n        loss_va = nn.BCEWithLogitsLoss()    \n\n        early_stopping_steps = EARLY_STOPPING_STEPS\n        early_step = 0\n\n        oof = np.zeros((len(train), len(target_cols)))\n        best_loss = np.inf\n\n        mod_name = f\"FOLD_KAN_{seed}_{fold}_.pth\"\n        \n        for epoch in range(EPOCHS):\n\n            train_loss = train_fn(model, optimizer,scheduler, loss_tr, trainloader, DEVICE)\n            valid_loss, valid_preds = valid_fn(model, loss_va, validloader, DEVICE)\n            print(f\"SEED: {seed}, FOLD: {fold}, EPOCH: {epoch},train_loss: {train_loss}, valid_loss: {valid_loss}\")\n\n            if valid_loss < best_loss:\n\n                best_loss = valid_loss\n                oof[val_idx] = valid_preds\n                torch.save(model.state_dict(), mod_name)\n\n            elif(EARLY_STOP == True):\n\n                early_step += 1\n                if (early_step >= early_stopping_steps):\n                    break\n        \n        testdataset = TestDataset(x_test)\n        testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n\n        if seed == SEED[-1]:\n            valid_sam = torch.utils.data.DataLoader(testdataset, batch_size=1, shuffle=False)\n            sample = next(iter(valid_sam))\n            inputs = sample['x'].to(DEVICE)\n            flops = FlopCountAnalysis(model, inputs)\n            print(\"*\"*20)\n            print(f\"Flops for KAN: {flops.total()}\")\n            print(\"*\"*20)\n            # print(summary(model, tuple(inputs.shape[1:]), \"cuda\"))\n        \n        #--------------------- PREDICTION---------------------\n       \n        model = Model(\n            num_features=num_features,\n            num_targets=num_targets,\n            hidden_size=hidden_size,\n        )\n\n        model.load_state_dict(torch.load(mod_name))\n        model.to(DEVICE)\n\n        predictions = np.zeros((len(test_), len(target_cols)))\n        predictions = inference_fn(model, testloader, DEVICE)\n        return oof, predictions\n\n    def run_k_fold(NFOLDS, seed):\n        oof = np.zeros((len(train), len(target_cols)))\n        predictions = np.zeros((len(test), len(target_cols)))\n\n        for fold in range(NFOLDS):\n            oof_, pred_ = run_training(fold, seed)\n\n            predictions += pred_ / NFOLDS\n            oof += oof_\n\n        return oof, predictions\n\n    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n    oof += oof_ / len(SEED)\n    predictions += predictions_ / len(SEED)\n    \n    oof_tmp = dp(oof)\n    oof_tmp = oof_tmp * len(SEED) / (SEED.index(seed)+1)\n    sc_dic[seed] = np.mean([log_loss(train[target_cols].iloc[:,i],oof_tmp[:,i]) for i in range(len(target_cols))])\n    \n    \nfrom sklearn.metrics import log_loss\nprint(np.mean([log_loss(train[target_cols].iloc[:,i],oof[:,i]) for i in range(len(target_cols))]))\n\ntrain0[target_cols] = oof\ntest[target_cols] = predictions\n\n### for blend test ###\ntrain0.to_csv('train_pred.csv', index=False)\n### for blend test ###\n\nsub = sample_submission.drop(columns=target_cols).merge(test[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\nsub.to_csv('submission_kan.csv', index=False)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T04:12:33.814457Z","iopub.execute_input":"2025-01-16T04:12:33.814770Z","iopub.status.idle":"2025-01-16T07:03:00.434773Z","shell.execute_reply.started":"2025-01-16T04:12:33.814739Z","shell.execute_reply":"2025-01-16T07:03:00.433660Z"}},"outputs":[{"name":"stdout","text":"FOLD: 0, EPOCH: 0,train_loss: 0.7333418066086976, valid_loss: 0.6978098733084542\nSEED: 0, FOLD: 0, EPOCH: 0,train_loss: 0.4691720162315861, valid_loss: 0.024828314408659936\nSEED: 0, FOLD: 0, EPOCH: 1,train_loss: 0.021686490935583908, valid_loss: 0.021153220374669348\nSEED: 0, FOLD: 0, EPOCH: 2,train_loss: 0.020258854507752087, valid_loss: 0.018883360709462848\nSEED: 0, FOLD: 0, EPOCH: 3,train_loss: 0.018956109543965347, valid_loss: 0.018219612405768464\nSEED: 0, FOLD: 0, EPOCH: 4,train_loss: 0.018420447892360928, valid_loss: 7.687085860116142\nSEED: 0, FOLD: 0, EPOCH: 5,train_loss: 0.017728823000916105, valid_loss: 0.018102741693811757\nSEED: 0, FOLD: 0, EPOCH: 6,train_loss: 0.01726946557291608, valid_loss: 0.018393209709652834\nSEED: 0, FOLD: 0, EPOCH: 7,train_loss: 0.016965936275496, valid_loss: 0.018016721068748406\nSEED: 0, FOLD: 0, EPOCH: 8,train_loss: 0.016656766287928473, valid_loss: 0.01830864708338465\nSEED: 0, FOLD: 0, EPOCH: 9,train_loss: 0.016537004629608946, valid_loss: 0.018210702602352413\nSEED: 0, FOLD: 0, EPOCH: 10,train_loss: 0.016184001830339, valid_loss: 0.018183661438524724\nSEED: 0, FOLD: 0, EPOCH: 11,train_loss: 0.016130904127182304, valid_loss: 0.025438798697931427\nSEED: 0, FOLD: 0, EPOCH: 12,train_loss: 0.015525981358697882, valid_loss: 0.019846734856920584\nSEED: 0, FOLD: 0, EPOCH: 13,train_loss: 0.015070946192017931, valid_loss: 0.018466632201203276\nSEED: 0, FOLD: 0, EPOCH: 14,train_loss: 0.014650702753198751, valid_loss: 0.01873619465955666\nSEED: 0, FOLD: 0, EPOCH: 15,train_loss: 0.013541980977237656, valid_loss: 0.019354425211037907\nSEED: 0, FOLD: 0, EPOCH: 16,train_loss: 0.012458801337018393, valid_loss: 0.01976603264255183\nSEED: 0, FOLD: 0, EPOCH: 17,train_loss: 0.011178229415816242, valid_loss: 0.02042157697890486\nSEED: 0, FOLD: 0, EPOCH: 18,train_loss: 0.00973562876680407, valid_loss: 0.021424718680126326\nSEED: 0, FOLD: 0, EPOCH: 19,train_loss: 0.008278017347354604, valid_loss: 0.02131173158330577\nSEED: 0, FOLD: 0, EPOCH: 20,train_loss: 0.00706255504105618, valid_loss: 0.021314780041575433\nSEED: 0, FOLD: 0, EPOCH: 21,train_loss: 0.0062595670975312805, valid_loss: 0.021559150410549982\nSEED: 0, FOLD: 0, EPOCH: 22,train_loss: 0.0058219784573800325, valid_loss: 0.021497274349842752\nSEED: 0, FOLD: 0, EPOCH: 23,train_loss: 0.005589121473494215, valid_loss: 0.02151253798178264\nSEED: 0, FOLD: 0, EPOCH: 24,train_loss: 0.005489002447575331, valid_loss: 0.021535770169326236\nFOLD: 1, EPOCH: 0,train_loss: 0.733479095636493, valid_loss: 0.6968707067625863\nSEED: 0, FOLD: 1, EPOCH: 0,train_loss: 0.4700301517426533, valid_loss: 0.024759012194616455\nSEED: 0, FOLD: 1, EPOCH: 1,train_loss: 0.02173280476653663, valid_loss: 0.02152007333934307\nSEED: 0, FOLD: 1, EPOCH: 2,train_loss: 0.019984895145914852, valid_loss: 0.019173225707241465\nSEED: 0, FOLD: 1, EPOCH: 3,train_loss: 0.01868028099220382, valid_loss: 0.018826371005603245\nSEED: 0, FOLD: 1, EPOCH: 4,train_loss: 0.017957215360535756, valid_loss: 0.018460196895258768\nSEED: 0, FOLD: 1, EPOCH: 5,train_loss: 0.017422093282433323, valid_loss: 0.018350583421332497\nSEED: 0, FOLD: 1, EPOCH: 6,train_loss: 0.017136440435628387, valid_loss: 0.018455733465296883\nSEED: 0, FOLD: 1, EPOCH: 7,train_loss: 0.01678701952426103, valid_loss: 0.018529427370854785\nSEED: 0, FOLD: 1, EPOCH: 8,train_loss: 0.016658725468509824, valid_loss: 0.01936226968786546\nSEED: 0, FOLD: 1, EPOCH: 9,train_loss: 0.016473989396689148, valid_loss: 0.018687049565570695\nSEED: 0, FOLD: 1, EPOCH: 10,train_loss: 0.01622610549394884, valid_loss: 0.019797203317284583\nSEED: 0, FOLD: 1, EPOCH: 11,train_loss: 0.016012564151935332, valid_loss: 0.019048398839575903\nSEED: 0, FOLD: 1, EPOCH: 12,train_loss: 0.015633888073591857, valid_loss: 0.0192043415669884\nSEED: 0, FOLD: 1, EPOCH: 13,train_loss: 0.015225065681729873, valid_loss: 0.019419032388499805\nSEED: 0, FOLD: 1, EPOCH: 14,train_loss: 0.014649622339456186, valid_loss: 0.020231292290346963\nSEED: 0, FOLD: 1, EPOCH: 15,train_loss: 0.01385532115606496, valid_loss: 0.020506225526332855\nSEED: 0, FOLD: 1, EPOCH: 16,train_loss: 0.012919276320531855, valid_loss: 0.02116582196738039\nSEED: 0, FOLD: 1, EPOCH: 17,train_loss: 0.011618952423225354, valid_loss: 0.021623144085918155\nSEED: 0, FOLD: 1, EPOCH: 18,train_loss: 0.010344890700857135, valid_loss: 0.02208589597472123\nSEED: 0, FOLD: 1, EPOCH: 19,train_loss: 0.008868902374439649, valid_loss: 0.02212848945387772\nSEED: 0, FOLD: 1, EPOCH: 20,train_loss: 0.007618546615062404, valid_loss: 0.02185268753341266\nSEED: 0, FOLD: 1, EPOCH: 21,train_loss: 0.006680210460874721, valid_loss: 0.02216511235705444\nSEED: 0, FOLD: 1, EPOCH: 22,train_loss: 0.00609898625662292, valid_loss: 0.022021124511957167\nSEED: 0, FOLD: 1, EPOCH: 23,train_loss: 0.0058307541554698545, valid_loss: 0.022178983209388596\nSEED: 0, FOLD: 1, EPOCH: 24,train_loss: 0.005712577784230022, valid_loss: 0.0221987320376294\nFOLD: 2, EPOCH: 0,train_loss: 0.733432276957277, valid_loss: 0.6979047358036041\nSEED: 0, FOLD: 2, EPOCH: 0,train_loss: 0.4708032043299813, valid_loss: 0.024234397062922224\nSEED: 0, FOLD: 2, EPOCH: 1,train_loss: 0.021838780843477318, valid_loss: 0.02117411107482279\nSEED: 0, FOLD: 2, EPOCH: 2,train_loss: 0.02048455787471671, valid_loss: 0.018904475221300825\nSEED: 0, FOLD: 2, EPOCH: 3,train_loss: 0.019191935159050037, valid_loss: 0.018365936518153724\nSEED: 0, FOLD: 2, EPOCH: 4,train_loss: 0.018329565804721653, valid_loss: 0.01806376627920305\nSEED: 0, FOLD: 2, EPOCH: 5,train_loss: 0.017841368083558653, valid_loss: 0.01843235964941628\nSEED: 0, FOLD: 2, EPOCH: 6,train_loss: 0.017519086896293404, valid_loss: 0.017946193022105622\nSEED: 0, FOLD: 2, EPOCH: 7,train_loss: 0.017311544198056927, valid_loss: 0.017942030777168626\nSEED: 0, FOLD: 2, EPOCH: 8,train_loss: 0.01710053724979145, valid_loss: 0.017850453828406686\nSEED: 0, FOLD: 2, EPOCH: 9,train_loss: 0.016952879159994747, valid_loss: 0.01810225222588462\nSEED: 0, FOLD: 2, EPOCH: 10,train_loss: 0.01687615916834793, valid_loss: 0.018260409124195576\nSEED: 0, FOLD: 2, EPOCH: 11,train_loss: 0.016730364115125892, valid_loss: 0.09595809307168512\nSEED: 0, FOLD: 2, EPOCH: 12,train_loss: 0.016501617671894855, valid_loss: 0.01833317198735826\nSEED: 0, FOLD: 2, EPOCH: 13,train_loss: 0.01618771935286729, valid_loss: 0.01819387379595462\nSEED: 0, FOLD: 2, EPOCH: 14,train_loss: 0.01588037900923603, valid_loss: 0.023994547041023478\nSEED: 0, FOLD: 2, EPOCH: 15,train_loss: 0.015212237794438133, valid_loss: 0.018495729193091393\nSEED: 0, FOLD: 2, EPOCH: 16,train_loss: 0.014392147738270569, valid_loss: 0.018707707743434346\nSEED: 0, FOLD: 2, EPOCH: 17,train_loss: 0.013369325595651415, valid_loss: 0.020358028164242998\nSEED: 0, FOLD: 2, EPOCH: 18,train_loss: 0.012015265237162079, valid_loss: 0.021537464933798593\nSEED: 0, FOLD: 2, EPOCH: 19,train_loss: 0.010502413691331943, valid_loss: 0.02029201908804038\nSEED: 0, FOLD: 2, EPOCH: 20,train_loss: 0.008953959124324761, valid_loss: 0.02061958676751922\nSEED: 0, FOLD: 2, EPOCH: 21,train_loss: 0.007691638787155566, valid_loss: 0.02074587230077561\nSEED: 0, FOLD: 2, EPOCH: 22,train_loss: 0.006877391615990496, valid_loss: 0.020803497775512582\nSEED: 0, FOLD: 2, EPOCH: 23,train_loss: 0.006489325868154781, valid_loss: 0.020787690985290444\nSEED: 0, FOLD: 2, EPOCH: 24,train_loss: 0.0063290200634873, valid_loss: 0.02087055749314673\nFOLD: 3, EPOCH: 0,train_loss: 0.7333921194076538, valid_loss: 0.6939650450434004\nSEED: 0, FOLD: 3, EPOCH: 0,train_loss: 0.4694407752080672, valid_loss: 0.023439589834639004\nSEED: 0, FOLD: 3, EPOCH: 1,train_loss: 0.02169295635236346, valid_loss: 42.68824479430914\nSEED: 0, FOLD: 3, EPOCH: 2,train_loss: 0.02038837483395701, valid_loss: 0.01894897994186197\nSEED: 0, FOLD: 3, EPOCH: 3,train_loss: 0.01917763660405425, valid_loss: 0.018303867110184262\nSEED: 0, FOLD: 3, EPOCH: 4,train_loss: 0.018414149054096662, valid_loss: 0.01820855340255158\nSEED: 0, FOLD: 3, EPOCH: 5,train_loss: 0.01789881384162151, valid_loss: 0.018052426166832447\nSEED: 0, FOLD: 3, EPOCH: 6,train_loss: 0.017536185472609774, valid_loss: 0.017815890855022838\nSEED: 0, FOLD: 3, EPOCH: 7,train_loss: 0.01723522853538178, valid_loss: 0.04827205544071538\nSEED: 0, FOLD: 3, EPOCH: 8,train_loss: 0.017097686214939407, valid_loss: 0.5048168049859149\nSEED: 0, FOLD: 3, EPOCH: 9,train_loss: 0.01694121730743327, valid_loss: 0.018163891934922762\nSEED: 0, FOLD: 3, EPOCH: 10,train_loss: 0.01685714423386515, valid_loss: 0.018068664920117175\nSEED: 0, FOLD: 3, EPOCH: 11,train_loss: 0.01669418683572524, valid_loss: 0.017969761522752897\nSEED: 0, FOLD: 3, EPOCH: 12,train_loss: 0.016445311312766178, valid_loss: 0.017924830663417067\nSEED: 0, FOLD: 3, EPOCH: 13,train_loss: 0.016235386919014265, valid_loss: 0.019482142797538213\nSEED: 0, FOLD: 3, EPOCH: 14,train_loss: 0.015857420719998037, valid_loss: 0.018274800532630513\nSEED: 0, FOLD: 3, EPOCH: 15,train_loss: 0.015323339536300173, valid_loss: 0.02158181459775993\nSEED: 0, FOLD: 3, EPOCH: 16,train_loss: 0.014565261688245379, valid_loss: 0.018907072395086287\nSEED: 0, FOLD: 3, EPOCH: 17,train_loss: 0.013380449987354054, valid_loss: 0.019212153447525842\nSEED: 0, FOLD: 3, EPOCH: 18,train_loss: 0.012063404005290806, valid_loss: 0.01955481804907322\nSEED: 0, FOLD: 3, EPOCH: 19,train_loss: 0.010479591010759274, valid_loss: 0.02031294389494828\nSEED: 0, FOLD: 3, EPOCH: 20,train_loss: 0.00896294729149752, valid_loss: 0.02045267889542239\nSEED: 0, FOLD: 3, EPOCH: 21,train_loss: 0.007740984249023208, valid_loss: 0.020467942314488546\nSEED: 0, FOLD: 3, EPOCH: 22,train_loss: 0.00695307361488433, valid_loss: 0.02055452588413443\nSEED: 0, FOLD: 3, EPOCH: 23,train_loss: 0.006568389759142546, valid_loss: 0.02074840659541743\nSEED: 0, FOLD: 3, EPOCH: 24,train_loss: 0.006423500494734532, valid_loss: 0.02075584733060428\nFOLD: 4, EPOCH: 0,train_loss: 0.7326504350572393, valid_loss: 0.6960134369986398\nSEED: 0, FOLD: 4, EPOCH: 0,train_loss: 0.46944465882320335, valid_loss: 0.02347536182829312\nSEED: 0, FOLD: 4, EPOCH: 1,train_loss: 0.021822439628126827, valid_loss: 0.02097381880240781\nSEED: 0, FOLD: 4, EPOCH: 2,train_loss: 0.020296507339546646, valid_loss: 0.01924306744975703\nSEED: 0, FOLD: 4, EPOCH: 3,train_loss: 0.019065063176811604, valid_loss: 0.018382870725222995\nSEED: 0, FOLD: 4, EPOCH: 4,train_loss: 0.01827236192057962, valid_loss: 0.018494795794997895\nSEED: 0, FOLD: 4, EPOCH: 5,train_loss: 0.01780806980568214, valid_loss: 0.01854261372770582\nSEED: 0, FOLD: 4, EPOCH: 6,train_loss: 0.017512856186300083, valid_loss: 0.01826569376779454\nSEED: 0, FOLD: 4, EPOCH: 7,train_loss: 0.017223416746634503, valid_loss: 0.018167866447142193\nSEED: 0, FOLD: 4, EPOCH: 8,train_loss: 0.017012702294395887, valid_loss: 0.019276757591537068\nSEED: 0, FOLD: 4, EPOCH: 9,train_loss: 0.016810579279410667, valid_loss: 0.01846677836562906\nSEED: 0, FOLD: 4, EPOCH: 10,train_loss: 0.016606425825992355, valid_loss: 0.01846144252589771\nSEED: 0, FOLD: 4, EPOCH: 11,train_loss: 0.016275070992338915, valid_loss: 0.01824687078062977\nSEED: 0, FOLD: 4, EPOCH: 12,train_loss: 0.016032239449196968, valid_loss: 0.01867635329919202\nSEED: 0, FOLD: 4, EPOCH: 13,train_loss: 0.0156997032193602, valid_loss: 0.018480598979762623\nSEED: 0, FOLD: 4, EPOCH: 14,train_loss: 0.015221350529379602, valid_loss: 0.019222415877240044\nSEED: 0, FOLD: 4, EPOCH: 15,train_loss: 0.014515281762873781, valid_loss: 0.019285854910101208\nSEED: 0, FOLD: 4, EPOCH: 16,train_loss: 0.01367191677454157, valid_loss: 0.019597696991903443\nSEED: 0, FOLD: 4, EPOCH: 17,train_loss: 0.012617429050252489, valid_loss: 0.019815724662372042\nSEED: 0, FOLD: 4, EPOCH: 18,train_loss: 0.011178239815584991, valid_loss: 0.02046067432633468\nSEED: 0, FOLD: 4, EPOCH: 19,train_loss: 0.009583619288236334, valid_loss: 0.020679650296057974\nSEED: 0, FOLD: 4, EPOCH: 20,train_loss: 0.008216242046108928, valid_loss: 0.0208637858075755\nSEED: 0, FOLD: 4, EPOCH: 21,train_loss: 0.007150712659231563, valid_loss: 0.021027878512229238\nSEED: 0, FOLD: 4, EPOCH: 22,train_loss: 0.0064872230733812285, valid_loss: 0.021178046773586954\nSEED: 0, FOLD: 4, EPOCH: 23,train_loss: 0.006164534287392229, valid_loss: 0.021207413556320328\nSEED: 0, FOLD: 4, EPOCH: 24,train_loss: 0.006045856303872837, valid_loss: 0.021227133965917997\nFOLD: 0, EPOCH: 0,train_loss: 0.7320367490899735, valid_loss: 0.7013229216848101\nSEED: 1, FOLD: 0, EPOCH: 0,train_loss: 0.46885296710483404, valid_loss: 0.024464149134499687\nSEED: 1, FOLD: 0, EPOCH: 1,train_loss: 0.02195081874674213, valid_loss: 0.020545612062726704\nSEED: 1, FOLD: 0, EPOCH: 2,train_loss: 0.02057718279083138, valid_loss: 0.018908540744866642\nSEED: 1, FOLD: 0, EPOCH: 3,train_loss: 0.01934946784614653, valid_loss: 0.018577133305370808\nSEED: 1, FOLD: 0, EPOCH: 4,train_loss: 0.018454754104216892, valid_loss: 0.017415542847343854\nSEED: 1, FOLD: 0, EPOCH: 5,train_loss: 0.01790026050951818, valid_loss: 0.01769387304250683\nSEED: 1, FOLD: 0, EPOCH: 6,train_loss: 0.017564016326830006, valid_loss: 0.017498543299734593\nSEED: 1, FOLD: 0, EPOCH: 7,train_loss: 0.017263318115062473, valid_loss: 0.027856714704207013\nSEED: 1, FOLD: 0, EPOCH: 8,train_loss: 0.016993725253943947, valid_loss: 0.01761309528457267\nSEED: 1, FOLD: 0, EPOCH: 9,train_loss: 0.016816016644293417, valid_loss: 0.017697860566633087\nSEED: 1, FOLD: 0, EPOCH: 10,train_loss: 0.016681434485413458, valid_loss: 0.020241586358419487\nSEED: 1, FOLD: 0, EPOCH: 11,train_loss: 0.01646237774495629, valid_loss: 0.017454637454024383\nSEED: 1, FOLD: 0, EPOCH: 12,train_loss: 0.016140751898342718, valid_loss: 0.017810571433178015\nSEED: 1, FOLD: 0, EPOCH: 13,train_loss: 0.01581258355113475, valid_loss: 0.01936542194868837\nSEED: 1, FOLD: 0, EPOCH: 14,train_loss: 0.015266148022551468, valid_loss: 0.01836299414613417\nSEED: 1, FOLD: 0, EPOCH: 15,train_loss: 0.014541687916262426, valid_loss: 0.019972916346575532\nSEED: 1, FOLD: 0, EPOCH: 16,train_loss: 0.013608653057852516, valid_loss: 0.01896612766597952\nSEED: 1, FOLD: 0, EPOCH: 17,train_loss: 0.01250133641820023, valid_loss: 0.01961976071553571\nSEED: 1, FOLD: 0, EPOCH: 18,train_loss: 0.011046110368941141, valid_loss: 0.019494925918323653\nSEED: 1, FOLD: 0, EPOCH: 19,train_loss: 0.00939627879879613, valid_loss: 0.019972618030650275\nSEED: 1, FOLD: 0, EPOCH: 20,train_loss: 0.007908885326722393, valid_loss: 0.020774911876235688\nSEED: 1, FOLD: 0, EPOCH: 21,train_loss: 0.00686692926303848, valid_loss: 0.02143194978790624\nSEED: 1, FOLD: 0, EPOCH: 22,train_loss: 0.0061994331814618645, valid_loss: 0.02033172313656126\nSEED: 1, FOLD: 0, EPOCH: 23,train_loss: 0.005899261774333275, valid_loss: 0.02029239455504077\nSEED: 1, FOLD: 0, EPOCH: 24,train_loss: 0.005784784609019972, valid_loss: 0.020446839343224252\nFOLD: 1, EPOCH: 0,train_loss: 0.7323248925870353, valid_loss: 0.7030059712273734\nSEED: 1, FOLD: 1, EPOCH: 0,train_loss: 0.4704640671393297, valid_loss: 0.023449871156896864\nSEED: 1, FOLD: 1, EPOCH: 1,train_loss: 0.021768100614095256, valid_loss: 4.576690958493522\nSEED: 1, FOLD: 1, EPOCH: 2,train_loss: 0.020405319594118718, valid_loss: 0.021235992759466173\nSEED: 1, FOLD: 1, EPOCH: 3,train_loss: 0.01902506662274364, valid_loss: 0.018676005090985978\nSEED: 1, FOLD: 1, EPOCH: 4,train_loss: 0.018389737410266904, valid_loss: 0.018173020439488548\nSEED: 1, FOLD: 1, EPOCH: 5,train_loss: 0.01785186461995553, valid_loss: 0.01803418951375144\nSEED: 1, FOLD: 1, EPOCH: 6,train_loss: 0.01745193170206825, valid_loss: 0.018149335948484283\nSEED: 1, FOLD: 1, EPOCH: 7,train_loss: 0.017196319113573888, valid_loss: 0.018151307106018068\nSEED: 1, FOLD: 1, EPOCH: 8,train_loss: 0.016991489893165384, valid_loss: 0.017778849149388928\nSEED: 1, FOLD: 1, EPOCH: 9,train_loss: 0.016823430729173396, valid_loss: 0.018573697124208723\nSEED: 1, FOLD: 1, EPOCH: 10,train_loss: 0.0167024461212602, valid_loss: 0.017807069207940784\nSEED: 1, FOLD: 1, EPOCH: 11,train_loss: 0.016527047278835392, valid_loss: 0.017836493360144753\nSEED: 1, FOLD: 1, EPOCH: 12,train_loss: 0.016232392805064246, valid_loss: 0.01825891046651772\nSEED: 1, FOLD: 1, EPOCH: 13,train_loss: 0.015941967711831533, valid_loss: 0.018245261082691807\nSEED: 1, FOLD: 1, EPOCH: 14,train_loss: 0.015554920362349409, valid_loss: 0.01834307930299214\nSEED: 1, FOLD: 1, EPOCH: 15,train_loss: 0.014804085383504412, valid_loss: 0.018483075233442444\nSEED: 1, FOLD: 1, EPOCH: 16,train_loss: 0.013972816173068798, valid_loss: 0.018988874767507824\nSEED: 1, FOLD: 1, EPOCH: 17,train_loss: 0.012819166016513414, valid_loss: 0.019390495653663364\nSEED: 1, FOLD: 1, EPOCH: 18,train_loss: 0.011275447857477805, valid_loss: 0.02033199141068118\nSEED: 1, FOLD: 1, EPOCH: 19,train_loss: 0.009638095628062305, valid_loss: 0.02049306801387242\nSEED: 1, FOLD: 1, EPOCH: 20,train_loss: 0.008087248667177275, valid_loss: 0.02074588324342455\nSEED: 1, FOLD: 1, EPOCH: 21,train_loss: 0.006980062492980357, valid_loss: 0.02079656246517386\nSEED: 1, FOLD: 1, EPOCH: 22,train_loss: 0.006321694419794056, valid_loss: 0.02095243866954531\nSEED: 1, FOLD: 1, EPOCH: 23,train_loss: 0.005978718525764063, valid_loss: 0.020975040537970408\nSEED: 1, FOLD: 1, EPOCH: 24,train_loss: 0.0058565902877191125, valid_loss: 0.02102488721055644\nFOLD: 2, EPOCH: 0,train_loss: 0.7318112016588018, valid_loss: 0.7043154069355556\nSEED: 1, FOLD: 2, EPOCH: 0,train_loss: 0.46820941764483415, valid_loss: 0.0243729688759361\nSEED: 1, FOLD: 2, EPOCH: 1,train_loss: 0.02177435557857372, valid_loss: 0.02142864428460598\nSEED: 1, FOLD: 2, EPOCH: 2,train_loss: 0.020646978520612785, valid_loss: 0.019539500613297733\nSEED: 1, FOLD: 2, EPOCH: 3,train_loss: 0.01905593351609465, valid_loss: 0.018436739673571928\nSEED: 1, FOLD: 2, EPOCH: 4,train_loss: 0.018279178007303373, valid_loss: 0.01823886965534517\nSEED: 1, FOLD: 2, EPOCH: 5,train_loss: 0.017862311301186033, valid_loss: 0.018198970971362933\nSEED: 1, FOLD: 2, EPOCH: 6,train_loss: 0.017444174662502348, valid_loss: 0.01795477329620293\nSEED: 1, FOLD: 2, EPOCH: 7,train_loss: 0.017233990315023973, valid_loss: 0.01805944735450404\nSEED: 1, FOLD: 2, EPOCH: 8,train_loss: 0.017036838679695906, valid_loss: 0.02258320525288582\nSEED: 1, FOLD: 2, EPOCH: 9,train_loss: 0.017039279250994972, valid_loss: 0.018003135813134057\nSEED: 1, FOLD: 2, EPOCH: 10,train_loss: 0.016889254960730887, valid_loss: 0.018119451749537673\nSEED: 1, FOLD: 2, EPOCH: 11,train_loss: 0.016772207642055077, valid_loss: 0.01900840981730393\nSEED: 1, FOLD: 2, EPOCH: 12,train_loss: 0.016544795676094036, valid_loss: 0.057917475407677034\nSEED: 1, FOLD: 2, EPOCH: 13,train_loss: 0.016316890264388876, valid_loss: 0.0182313559576869\nSEED: 1, FOLD: 2, EPOCH: 14,train_loss: 0.015907484997549782, valid_loss: 0.018466374544160707\nSEED: 1, FOLD: 2, EPOCH: 15,train_loss: 0.015354279273500046, valid_loss: 0.01880050322839192\nSEED: 1, FOLD: 2, EPOCH: 16,train_loss: 0.014733074253182049, valid_loss: 0.018689327713634286\nSEED: 1, FOLD: 2, EPOCH: 17,train_loss: 0.013576984655220007, valid_loss: 0.019464362944875444\nSEED: 1, FOLD: 2, EPOCH: 18,train_loss: 0.012245081047918917, valid_loss: 0.021170626633933612\nSEED: 1, FOLD: 2, EPOCH: 19,train_loss: 0.010655648689177157, valid_loss: 0.020560180076531\nSEED: 1, FOLD: 2, EPOCH: 20,train_loss: 0.008936173603127616, valid_loss: 0.02099793255329132\nSEED: 1, FOLD: 2, EPOCH: 21,train_loss: 0.007617187588408157, valid_loss: 0.020980658488614218\nSEED: 1, FOLD: 2, EPOCH: 22,train_loss: 0.006734625787298748, valid_loss: 0.02138004329587732\nSEED: 1, FOLD: 2, EPOCH: 23,train_loss: 0.006291414536805689, valid_loss: 0.0216636097324746\nSEED: 1, FOLD: 2, EPOCH: 24,train_loss: 0.006136754834754527, valid_loss: 0.021417683522616113\nFOLD: 3, EPOCH: 0,train_loss: 0.7320777834325597, valid_loss: 0.7014131648199898\nSEED: 1, FOLD: 3, EPOCH: 0,train_loss: 0.468350468378892, valid_loss: 0.024147321549909454\nSEED: 1, FOLD: 3, EPOCH: 1,train_loss: 0.021903979281584423, valid_loss: 0.02168341034225055\nSEED: 1, FOLD: 3, EPOCH: 2,train_loss: 0.020500184212257896, valid_loss: 0.020143871967281613\nSEED: 1, FOLD: 3, EPOCH: 3,train_loss: 0.019155092031249533, valid_loss: 0.019071066805294582\nSEED: 1, FOLD: 3, EPOCH: 4,train_loss: 0.018309231726047787, valid_loss: 0.018926711965884482\nSEED: 1, FOLD: 3, EPOCH: 5,train_loss: 0.017820329432362232, valid_loss: 0.110971838714821\nSEED: 1, FOLD: 3, EPOCH: 6,train_loss: 0.017375901408925438, valid_loss: 0.019036359659263067\nSEED: 1, FOLD: 3, EPOCH: 7,train_loss: 0.017039841830568468, valid_loss: 0.01883309528763805\nSEED: 1, FOLD: 3, EPOCH: 8,train_loss: 0.016849510304197884, valid_loss: 0.018690407888165544\nSEED: 1, FOLD: 3, EPOCH: 9,train_loss: 0.016717286551020283, valid_loss: 0.018685540051332543\nSEED: 1, FOLD: 3, EPOCH: 10,train_loss: 0.01663884356536943, valid_loss: 0.01863298879138061\nSEED: 1, FOLD: 3, EPOCH: 11,train_loss: 0.01639962861098457, valid_loss: 0.01896029444677489\nSEED: 1, FOLD: 3, EPOCH: 12,train_loss: 0.016204952734751976, valid_loss: 0.01904762743839196\nSEED: 1, FOLD: 3, EPOCH: 13,train_loss: 0.015864516399206892, valid_loss: 0.01883059356893812\nSEED: 1, FOLD: 3, EPOCH: 14,train_loss: 0.015431147804348797, valid_loss: 0.01907460168004036\nSEED: 1, FOLD: 3, EPOCH: 15,train_loss: 0.014648456551620493, valid_loss: 0.020413831514971597\nSEED: 1, FOLD: 3, EPOCH: 16,train_loss: 0.013775588033477898, valid_loss: 0.01977121186043535\nSEED: 1, FOLD: 3, EPOCH: 17,train_loss: 0.012499635681455982, valid_loss: 0.020736518129706383\nSEED: 1, FOLD: 3, EPOCH: 18,train_loss: 0.011015313157838756, valid_loss: 0.021117625491959707\nSEED: 1, FOLD: 3, EPOCH: 19,train_loss: 0.00932791138715718, valid_loss: 0.02159321089940412\nSEED: 1, FOLD: 3, EPOCH: 20,train_loss: 0.00784361371230604, valid_loss: 0.021775165359888757\nSEED: 1, FOLD: 3, EPOCH: 21,train_loss: 0.006781358997324022, valid_loss: 0.021942167835576194\nSEED: 1, FOLD: 3, EPOCH: 22,train_loss: 0.0061725872312335004, valid_loss: 0.021874113540564264\nSEED: 1, FOLD: 3, EPOCH: 23,train_loss: 0.0058730649795599174, valid_loss: 0.021851858124136925\nSEED: 1, FOLD: 3, EPOCH: 24,train_loss: 0.005775377620011568, valid_loss: 0.021869099725569996\nFOLD: 4, EPOCH: 0,train_loss: 0.7326514294547756, valid_loss: 0.7044573613575527\nSEED: 1, FOLD: 4, EPOCH: 0,train_loss: 0.46983665333938424, valid_loss: 0.024401525301592692\nSEED: 1, FOLD: 4, EPOCH: 1,train_loss: 0.021671846237060796, valid_loss: 0.02728052373443331\nSEED: 1, FOLD: 4, EPOCH: 2,train_loss: 0.020236331588812988, valid_loss: 0.019282412555600915\nSEED: 1, FOLD: 4, EPOCH: 3,train_loss: 0.018750566214214275, valid_loss: 0.01848030649125576\nSEED: 1, FOLD: 4, EPOCH: 4,train_loss: 0.0179739446739537, valid_loss: 0.018420505709946154\nSEED: 1, FOLD: 4, EPOCH: 5,train_loss: 0.01748853118369614, valid_loss: 0.018461003793137414\nSEED: 1, FOLD: 4, EPOCH: 6,train_loss: 0.017110853816253425, valid_loss: 0.904168009438685\nSEED: 1, FOLD: 4, EPOCH: 7,train_loss: 0.01682569463159481, valid_loss: 0.018775495860193458\nSEED: 1, FOLD: 4, EPOCH: 8,train_loss: 0.016675915460299402, valid_loss: 0.018543672348771776\nSEED: 1, FOLD: 4, EPOCH: 9,train_loss: 0.016693106138684452, valid_loss: 0.01867725383490324\nSEED: 1, FOLD: 4, EPOCH: 10,train_loss: 0.016581122246808813, valid_loss: 0.01868075763008424\nSEED: 1, FOLD: 4, EPOCH: 11,train_loss: 0.016238903667587432, valid_loss: 0.018626152617590767\nSEED: 1, FOLD: 4, EPOCH: 12,train_loss: 0.016007121903889806, valid_loss: 0.019292080056454455\nSEED: 1, FOLD: 4, EPOCH: 13,train_loss: 0.015559116480396177, valid_loss: 0.019068785517343454\nSEED: 1, FOLD: 4, EPOCH: 14,train_loss: 0.01492233271880524, valid_loss: 0.019558498103703772\nSEED: 1, FOLD: 4, EPOCH: 15,train_loss: 0.01429994402276556, valid_loss: 0.02191679695887225\nSEED: 1, FOLD: 4, EPOCH: 16,train_loss: 0.013322121334554505, valid_loss: 0.02080930753477982\nSEED: 1, FOLD: 4, EPOCH: 17,train_loss: 0.012001419929366042, valid_loss: 0.02099574665938105\nSEED: 1, FOLD: 4, EPOCH: 18,train_loss: 0.01058577175122978, valid_loss: 0.021836322173476218\nSEED: 1, FOLD: 4, EPOCH: 19,train_loss: 0.009100987589544189, valid_loss: 0.02189605012536049\nSEED: 1, FOLD: 4, EPOCH: 20,train_loss: 0.007693428726336599, valid_loss: 0.022141766494938306\nSEED: 1, FOLD: 4, EPOCH: 21,train_loss: 0.0067344275915002735, valid_loss: 0.02209813216967242\nSEED: 1, FOLD: 4, EPOCH: 22,train_loss: 0.006115931076045237, valid_loss: 0.02221883444913796\nSEED: 1, FOLD: 4, EPOCH: 23,train_loss: 0.0058156204219554026, valid_loss: 0.022176870544041907\nSEED: 1, FOLD: 4, EPOCH: 24,train_loss: 0.005713239539904098, valid_loss: 0.022179819430623735\nFOLD: 0, EPOCH: 0,train_loss: 0.7316791264043339, valid_loss: 0.6929982304573059\nSEED: 2, FOLD: 0, EPOCH: 0,train_loss: 0.4702505792450646, valid_loss: 0.022944854040231024\nSEED: 2, FOLD: 0, EPOCH: 1,train_loss: 0.021650737326970135, valid_loss: 812.5395028604993\nSEED: 2, FOLD: 0, EPOCH: 2,train_loss: 0.020684365884981293, valid_loss: 0.02109117747417518\nSEED: 2, FOLD: 0, EPOCH: 3,train_loss: 0.019234242606098236, valid_loss: 0.017974716424942017\nSEED: 2, FOLD: 0, EPOCH: 4,train_loss: 0.018349704467623993, valid_loss: 0.017673621220248088\nSEED: 2, FOLD: 0, EPOCH: 5,train_loss: 0.017864197425112343, valid_loss: 0.01795240185622658\nSEED: 2, FOLD: 0, EPOCH: 6,train_loss: 0.01760062160294341, valid_loss: 0.017601817367332323\nSEED: 2, FOLD: 0, EPOCH: 7,train_loss: 0.017361299789416185, valid_loss: 0.019029036563422\nSEED: 2, FOLD: 0, EPOCH: 8,train_loss: 0.017134288643095373, valid_loss: 0.017627423256635667\nSEED: 2, FOLD: 0, EPOCH: 9,train_loss: 0.017086644238535908, valid_loss: 0.01744800212660006\nSEED: 2, FOLD: 0, EPOCH: 10,train_loss: 0.016867639233722635, valid_loss: 0.017706324266535897\nSEED: 2, FOLD: 0, EPOCH: 11,train_loss: 0.016750941599678736, valid_loss: 0.017733962115432534\nSEED: 2, FOLD: 0, EPOCH: 12,train_loss: 0.016452840131208086, valid_loss: 0.018126140800969942\nSEED: 2, FOLD: 0, EPOCH: 13,train_loss: 0.0162385827726752, valid_loss: 0.017986532779676573\nSEED: 2, FOLD: 0, EPOCH: 14,train_loss: 0.015786175123429384, valid_loss: 0.017944102681108885\nSEED: 2, FOLD: 0, EPOCH: 15,train_loss: 0.015195709443988575, valid_loss: 0.018193613258855684\nSEED: 2, FOLD: 0, EPOCH: 16,train_loss: 0.014378103980983513, valid_loss: 0.019203413543956622\nSEED: 2, FOLD: 0, EPOCH: 17,train_loss: 0.013261755604458891, valid_loss: 0.01925226894340345\nSEED: 2, FOLD: 0, EPOCH: 18,train_loss: 0.012061517159252064, valid_loss: 0.019802186425243104\nSEED: 2, FOLD: 0, EPOCH: 19,train_loss: 0.010449861776947544, valid_loss: 0.020221912621387412\nSEED: 2, FOLD: 0, EPOCH: 20,train_loss: 0.00884717149808463, valid_loss: 0.020539353575025288\nSEED: 2, FOLD: 0, EPOCH: 21,train_loss: 0.007550154195126632, valid_loss: 0.020317613945475647\nSEED: 2, FOLD: 0, EPOCH: 22,train_loss: 0.006758822890781406, valid_loss: 0.020559797968183247\nSEED: 2, FOLD: 0, EPOCH: 23,train_loss: 0.0063428165850000105, valid_loss: 0.020663139490144592\nSEED: 2, FOLD: 0, EPOCH: 24,train_loss: 0.006210137877370353, valid_loss: 0.0206795244078551\nFOLD: 1, EPOCH: 0,train_loss: 0.7309916386569756, valid_loss: 0.6889405710356576\nSEED: 2, FOLD: 1, EPOCH: 0,train_loss: 0.4692039661433386, valid_loss: 0.02568268621606486\nSEED: 2, FOLD: 1, EPOCH: 1,train_loss: 0.021864001855146194, valid_loss: 0.020634548578943524\nSEED: 2, FOLD: 1, EPOCH: 2,train_loss: 0.0200724381737519, valid_loss: 0.018431987560221127\nSEED: 2, FOLD: 1, EPOCH: 3,train_loss: 0.0188337921610345, valid_loss: 0.018065238185226918\nSEED: 2, FOLD: 1, EPOCH: 4,train_loss: 0.018204557581170313, valid_loss: 0.017820380069315432\nSEED: 2, FOLD: 1, EPOCH: 5,train_loss: 0.017799428475183853, valid_loss: 0.01776593987430845\nSEED: 2, FOLD: 1, EPOCH: 6,train_loss: 0.017502823635341898, valid_loss: 0.4035938018134662\nSEED: 2, FOLD: 1, EPOCH: 7,train_loss: 0.017310110379712307, valid_loss: 0.017550987750291826\nSEED: 2, FOLD: 1, EPOCH: 8,train_loss: 0.017217535093642662, valid_loss: 0.06823610062045711\nSEED: 2, FOLD: 1, EPOCH: 9,train_loss: 0.01713396191758954, valid_loss: 0.12352479211986064\nSEED: 2, FOLD: 1, EPOCH: 10,train_loss: 0.016934598708336336, valid_loss: 0.01956980430654117\nSEED: 2, FOLD: 1, EPOCH: 11,train_loss: 0.01675662580553604, valid_loss: 0.01796835746083941\nSEED: 2, FOLD: 1, EPOCH: 12,train_loss: 0.016549252891454144, valid_loss: 0.017865866741963794\nSEED: 2, FOLD: 1, EPOCH: 13,train_loss: 0.016200444154927263, valid_loss: 0.018278977328113146\nSEED: 2, FOLD: 1, EPOCH: 14,train_loss: 0.01593015449580507, valid_loss: 0.018111096961157664\nSEED: 2, FOLD: 1, EPOCH: 15,train_loss: 0.015211036226347736, valid_loss: 0.018328542209097316\nSEED: 2, FOLD: 1, EPOCH: 16,train_loss: 0.0143656678551781, valid_loss: 0.01865814072745187\nSEED: 2, FOLD: 1, EPOCH: 17,train_loss: 0.013502017628617477, valid_loss: 0.01907531949026244\nSEED: 2, FOLD: 1, EPOCH: 18,train_loss: 0.012127605199381926, valid_loss: 0.01943591263677393\nSEED: 2, FOLD: 1, EPOCH: 19,train_loss: 0.010477681097615025, valid_loss: 0.019705411046743393\nSEED: 2, FOLD: 1, EPOCH: 20,train_loss: 0.00891214531198468, valid_loss: 0.01999519568468843\nSEED: 2, FOLD: 1, EPOCH: 21,train_loss: 0.0076775387354681025, valid_loss: 0.020226607684578214\nSEED: 2, FOLD: 1, EPOCH: 22,train_loss: 0.0068639675965127735, valid_loss: 0.02039012648165226\nSEED: 2, FOLD: 1, EPOCH: 23,train_loss: 0.006450664633345129, valid_loss: 0.020495653578213282\nSEED: 2, FOLD: 1, EPOCH: 24,train_loss: 0.006291793649206343, valid_loss: 0.020449853794915335\nFOLD: 2, EPOCH: 0,train_loss: 0.7312282958756322, valid_loss: 0.6901773078101022\nSEED: 2, FOLD: 2, EPOCH: 0,train_loss: 0.4691007705810277, valid_loss: 0.024494806144918713\nSEED: 2, FOLD: 2, EPOCH: 1,train_loss: 0.02170397735376289, valid_loss: 0.021721470994608742\nSEED: 2, FOLD: 2, EPOCH: 2,train_loss: 0.020328699071230232, valid_loss: 13.55055556478245\nSEED: 2, FOLD: 2, EPOCH: 3,train_loss: 0.01894392903921181, valid_loss: 0.018323259108832906\nSEED: 2, FOLD: 2, EPOCH: 4,train_loss: 0.018302950009271717, valid_loss: 0.017974250204861163\nSEED: 2, FOLD: 2, EPOCH: 5,train_loss: 0.01775716893725853, valid_loss: 0.018640122402991566\nSEED: 2, FOLD: 2, EPOCH: 6,train_loss: 0.017446926720710337, valid_loss: 0.01800791405673538\nSEED: 2, FOLD: 2, EPOCH: 7,train_loss: 0.017318081198449152, valid_loss: 0.018054324654596193\nSEED: 2, FOLD: 2, EPOCH: 8,train_loss: 0.01716763657801177, valid_loss: 13.087736659497022\nSEED: 2, FOLD: 2, EPOCH: 9,train_loss: 0.016991837962490063, valid_loss: 33.75297372192144\nSEED: 2, FOLD: 2, EPOCH: 10,train_loss: 0.016837358413993017, valid_loss: 13.184428609428661\nSEED: 2, FOLD: 2, EPOCH: 11,train_loss: 0.016743646921131058, valid_loss: 0.24776016814368113\nSEED: 2, FOLD: 2, EPOCH: 12,train_loss: 0.016530479945620333, valid_loss: 0.019959548488259315\nSEED: 2, FOLD: 2, EPOCH: 13,train_loss: 0.016274306936648445, valid_loss: 0.026693337543734482\nSEED: 2, FOLD: 2, EPOCH: 14,train_loss: 0.015844431219865448, valid_loss: 0.01869548721505063\nSEED: 2, FOLD: 2, EPOCH: 15,train_loss: 0.015413139663312746, valid_loss: 0.019128812849521636\nSEED: 2, FOLD: 2, EPOCH: 16,train_loss: 0.01467228298196974, valid_loss: 0.019821348626698765\nSEED: 2, FOLD: 2, EPOCH: 17,train_loss: 0.013551932172444851, valid_loss: 0.01971787762429033\nSEED: 2, FOLD: 2, EPOCH: 18,train_loss: 0.012346625928699539, valid_loss: 0.020618144742080142\nSEED: 2, FOLD: 2, EPOCH: 19,train_loss: 0.010721177875023821, valid_loss: 0.023515691608190538\nSEED: 2, FOLD: 2, EPOCH: 20,train_loss: 0.00917347667036929, valid_loss: 0.020819783210754395\nSEED: 2, FOLD: 2, EPOCH: 21,train_loss: 0.008096783978702582, valid_loss: 0.02115422540477344\nSEED: 2, FOLD: 2, EPOCH: 22,train_loss: 0.007289291254879124, valid_loss: 0.02117188796401024\nSEED: 2, FOLD: 2, EPOCH: 23,train_loss: 0.006745452091664723, valid_loss: 0.021353799051472118\nSEED: 2, FOLD: 2, EPOCH: 24,train_loss: 0.006563556174734148, valid_loss: 0.021300816110202243\nFOLD: 3, EPOCH: 0,train_loss: 0.7316494101155413, valid_loss: 0.6929674199649266\nSEED: 2, FOLD: 3, EPOCH: 0,train_loss: 0.4710747242028261, valid_loss: 0.023895507412297384\nSEED: 2, FOLD: 3, EPOCH: 1,train_loss: 0.021754568021227844, valid_loss: 0.021802722875561033\nSEED: 2, FOLD: 3, EPOCH: 2,train_loss: 0.020665913697903174, valid_loss: 0.019600150840623037\nSEED: 2, FOLD: 3, EPOCH: 3,train_loss: 0.019293719114069522, valid_loss: 0.018654156316603932\nSEED: 2, FOLD: 3, EPOCH: 4,train_loss: 0.018440812894136367, valid_loss: 0.01848495075745242\nSEED: 2, FOLD: 3, EPOCH: 5,train_loss: 0.017938225482502124, valid_loss: 0.018259448637919767\nSEED: 2, FOLD: 3, EPOCH: 6,train_loss: 0.0175360493620273, valid_loss: 0.018150258303752966\nSEED: 2, FOLD: 3, EPOCH: 7,train_loss: 0.01723498590698425, valid_loss: 0.018175795461450303\nSEED: 2, FOLD: 3, EPOCH: 8,train_loss: 0.017004132889428713, valid_loss: 0.01811381086174931\nSEED: 2, FOLD: 3, EPOCH: 9,train_loss: 0.01684446095142269, valid_loss: 0.018557738033788546\nSEED: 2, FOLD: 3, EPOCH: 10,train_loss: 0.016690149318671573, valid_loss: 0.018244882433542182\nSEED: 2, FOLD: 3, EPOCH: 11,train_loss: 0.016342620474089235, valid_loss: 0.018600227683782576\nSEED: 2, FOLD: 3, EPOCH: 12,train_loss: 0.016134688025680338, valid_loss: 0.018736987241676877\nSEED: 2, FOLD: 3, EPOCH: 13,train_loss: 0.01570229934542066, valid_loss: 0.01867948624172381\nSEED: 2, FOLD: 3, EPOCH: 14,train_loss: 0.015185272123963728, valid_loss: 0.019058898996029583\nSEED: 2, FOLD: 3, EPOCH: 15,train_loss: 0.01436199714857949, valid_loss: 0.01936540390763964\nSEED: 2, FOLD: 3, EPOCH: 16,train_loss: 0.013470234410551778, valid_loss: 0.019953920585768562\nSEED: 2, FOLD: 3, EPOCH: 17,train_loss: 0.01224675476822975, valid_loss: 0.020390136912465096\nSEED: 2, FOLD: 3, EPOCH: 18,train_loss: 0.010891139255768626, valid_loss: 0.02105881491942065\nSEED: 2, FOLD: 3, EPOCH: 19,train_loss: 0.009482895860271732, valid_loss: 0.021481753566435405\nSEED: 2, FOLD: 3, EPOCH: 20,train_loss: 0.008096093536239036, valid_loss: 0.021804718566792353\nSEED: 2, FOLD: 3, EPOCH: 21,train_loss: 0.00701536178371332, valid_loss: 0.02186424380966595\nSEED: 2, FOLD: 3, EPOCH: 22,train_loss: 0.006395256279349109, valid_loss: 0.021892964999590602\nSEED: 2, FOLD: 3, EPOCH: 23,train_loss: 0.006076377649947892, valid_loss: 0.022016707488468717\nSEED: 2, FOLD: 3, EPOCH: 24,train_loss: 0.0059614233896952045, valid_loss: 0.02200257017144135\nFOLD: 4, EPOCH: 0,train_loss: 0.7316205721834431, valid_loss: 0.691992437839508\nSEED: 2, FOLD: 4, EPOCH: 0,train_loss: 0.4694807737984735, valid_loss: 0.025273887813091277\nSEED: 2, FOLD: 4, EPOCH: 1,train_loss: 0.021482403903011826, valid_loss: 0.02133480188037668\nSEED: 2, FOLD: 4, EPOCH: 2,train_loss: 0.01981034762887419, valid_loss: 0.019490951778633255\nSEED: 2, FOLD: 4, EPOCH: 3,train_loss: 0.018529423107595547, valid_loss: 0.018748574224965914\nSEED: 2, FOLD: 4, EPOCH: 4,train_loss: 0.01787156803344471, valid_loss: 0.019533000460692816\nSEED: 2, FOLD: 4, EPOCH: 5,train_loss: 0.01747298281153907, valid_loss: 0.018698565768344062\nSEED: 2, FOLD: 4, EPOCH: 6,train_loss: 0.017138189804888723, valid_loss: 0.019229951394455772\nSEED: 2, FOLD: 4, EPOCH: 7,train_loss: 0.016944404178555462, valid_loss: 0.018674829761896813\nSEED: 2, FOLD: 4, EPOCH: 8,train_loss: 0.016857446421045755, valid_loss: 0.019227343425154687\nSEED: 2, FOLD: 4, EPOCH: 9,train_loss: 0.01677483736631879, valid_loss: 0.019270127000553267\nSEED: 2, FOLD: 4, EPOCH: 10,train_loss: 0.016620459298238806, valid_loss: 0.018722920838211265\nSEED: 2, FOLD: 4, EPOCH: 11,train_loss: 0.016529333379551554, valid_loss: 0.01899599879980087\nSEED: 2, FOLD: 4, EPOCH: 12,train_loss: 0.016455388513218233, valid_loss: 1.0654038453740733\nSEED: 2, FOLD: 4, EPOCH: 13,train_loss: 0.0160503546923291, valid_loss: 0.019376955713544572\nSEED: 2, FOLD: 4, EPOCH: 14,train_loss: 0.0157098191169401, valid_loss: 0.01984121131577662\nSEED: 2, FOLD: 4, EPOCH: 15,train_loss: 0.015189291092742613, valid_loss: 0.019369472989014216\nSEED: 2, FOLD: 4, EPOCH: 16,train_loss: 0.014457312938959702, valid_loss: 0.03868400811084679\nSEED: 2, FOLD: 4, EPOCH: 17,train_loss: 0.013545041917350845, valid_loss: 0.020571409431951387\nSEED: 2, FOLD: 4, EPOCH: 18,train_loss: 0.012230499006429876, valid_loss: 0.021388931572437285\nSEED: 2, FOLD: 4, EPOCH: 19,train_loss: 0.01066753133267596, valid_loss: 0.021278324191059385\nSEED: 2, FOLD: 4, EPOCH: 20,train_loss: 0.009034035605904848, valid_loss: 0.02161712098334517\nSEED: 2, FOLD: 4, EPOCH: 21,train_loss: 0.007676951350995164, valid_loss: 0.021955830497401102\nSEED: 2, FOLD: 4, EPOCH: 22,train_loss: 0.0067884217529301195, valid_loss: 0.021979934456092972\nSEED: 2, FOLD: 4, EPOCH: 23,train_loss: 0.0063482758055940485, valid_loss: 0.022017424181103706\nSEED: 2, FOLD: 4, EPOCH: 24,train_loss: 0.006182354294519493, valid_loss: 0.02205586140709264\nFOLD: 0, EPOCH: 0,train_loss: 0.7335456877514936, valid_loss: 0.7021780933652605\nSEED: 3, FOLD: 0, EPOCH: 0,train_loss: 0.4702220311172415, valid_loss: 0.02530229613184929\nSEED: 3, FOLD: 0, EPOCH: 1,train_loss: 0.02178251307349706, valid_loss: 0.02075144462287426\nSEED: 3, FOLD: 0, EPOCH: 2,train_loss: 0.020395713979783264, valid_loss: 0.01873214560161744\nSEED: 3, FOLD: 0, EPOCH: 3,train_loss: 0.019046004105737244, valid_loss: 0.021864416703049627\nSEED: 3, FOLD: 0, EPOCH: 4,train_loss: 0.01841784821337332, valid_loss: 0.01885338802156704\nSEED: 3, FOLD: 0, EPOCH: 5,train_loss: 0.01797841948227606, valid_loss: 30.269020215075994\nSEED: 3, FOLD: 0, EPOCH: 6,train_loss: 0.01766051929039152, valid_loss: 0.01804505094353642\nSEED: 3, FOLD: 0, EPOCH: 7,train_loss: 0.017634153015155724, valid_loss: 0.01836439786212785\nSEED: 3, FOLD: 0, EPOCH: 8,train_loss: 0.017436121199010075, valid_loss: 0.01791467406520886\nSEED: 3, FOLD: 0, EPOCH: 9,train_loss: 0.017257633551523304, valid_loss: 0.024336114026872174\nSEED: 3, FOLD: 0, EPOCH: 10,train_loss: 0.01711877727665115, valid_loss: 0.01798466295003891\nSEED: 3, FOLD: 0, EPOCH: 11,train_loss: 0.016945920074763504, valid_loss: 0.017865330167114734\nSEED: 3, FOLD: 0, EPOCH: 12,train_loss: 0.016680942281432774, valid_loss: 0.017857368104159832\nSEED: 3, FOLD: 0, EPOCH: 13,train_loss: 0.01645492926320952, valid_loss: 0.017914637437622463\nSEED: 3, FOLD: 0, EPOCH: 14,train_loss: 0.016110028477682583, valid_loss: 0.01802574247121811\nSEED: 3, FOLD: 0, EPOCH: 15,train_loss: 0.015653813865197742, valid_loss: 0.018403504130297472\nSEED: 3, FOLD: 0, EPOCH: 16,train_loss: 0.015027623076963684, valid_loss: 0.018429761273520334\nSEED: 3, FOLD: 0, EPOCH: 17,train_loss: 0.014208414929284565, valid_loss: 0.019010180354650533\nSEED: 3, FOLD: 0, EPOCH: 18,train_loss: 0.012942332153518995, valid_loss: 0.019243014553960946\nSEED: 3, FOLD: 0, EPOCH: 19,train_loss: 0.01151228488922335, valid_loss: 0.019665096104810282\nSEED: 3, FOLD: 0, EPOCH: 20,train_loss: 0.009953099809101095, valid_loss: 0.019995325437879987\nSEED: 3, FOLD: 0, EPOCH: 21,train_loss: 0.008468984464264435, valid_loss: 0.0202975720100637\nSEED: 3, FOLD: 0, EPOCH: 22,train_loss: 0.00743121665942928, valid_loss: 0.020372472277709417\nSEED: 3, FOLD: 0, EPOCH: 23,train_loss: 0.006916625037168463, valid_loss: 0.02053976607109819\nSEED: 3, FOLD: 0, EPOCH: 24,train_loss: 0.006695718723821683, valid_loss: 0.02050862944951015\nFOLD: 1, EPOCH: 0,train_loss: 0.7331535846426867, valid_loss: 0.7017844830240522\nSEED: 3, FOLD: 1, EPOCH: 0,train_loss: 0.4701928771573348, valid_loss: 0.02428007179072925\nSEED: 3, FOLD: 1, EPOCH: 1,train_loss: 0.02173010266615429, valid_loss: 0.02058611304632255\nSEED: 3, FOLD: 1, EPOCH: 2,train_loss: 0.020277987450253273, valid_loss: 0.018558450894696373\nSEED: 3, FOLD: 1, EPOCH: 3,train_loss: 0.01890620968534031, valid_loss: 37.80476018908833\nSEED: 3, FOLD: 1, EPOCH: 4,train_loss: 0.018119618634058945, valid_loss: 0.01803316990179675\nSEED: 3, FOLD: 1, EPOCH: 5,train_loss: 0.017643066595537937, valid_loss: 0.01805568624820028\nSEED: 3, FOLD: 1, EPOCH: 6,train_loss: 0.017365644409226767, valid_loss: 0.01790964063256979\nSEED: 3, FOLD: 1, EPOCH: 7,train_loss: 0.017134272466427174, valid_loss: 0.017920106649398804\nSEED: 3, FOLD: 1, EPOCH: 8,train_loss: 0.017067067743535492, valid_loss: 0.02352068658385958\nSEED: 3, FOLD: 1, EPOCH: 9,train_loss: 0.016949479090238827, valid_loss: 0.018061465184603418\nSEED: 3, FOLD: 1, EPOCH: 10,train_loss: 0.01694250247184781, valid_loss: 0.01805821329887424\nSEED: 3, FOLD: 1, EPOCH: 11,train_loss: 0.016799059089111244, valid_loss: 0.36709718927741053\nSEED: 3, FOLD: 1, EPOCH: 12,train_loss: 0.016486418507723272, valid_loss: 0.017952690991972175\nSEED: 3, FOLD: 1, EPOCH: 13,train_loss: 0.016270818026817364, valid_loss: 0.018069328341100897\nSEED: 3, FOLD: 1, EPOCH: 14,train_loss: 0.01589050925458255, valid_loss: 0.01789086844239916\nSEED: 3, FOLD: 1, EPOCH: 15,train_loss: 0.015417245911785227, valid_loss: 0.018202432777200427\nSEED: 3, FOLD: 1, EPOCH: 16,train_loss: 0.014669805846136549, valid_loss: 0.01942749960081918\nSEED: 3, FOLD: 1, EPOCH: 17,train_loss: 0.013677806107570295, valid_loss: 0.019021334924868176\nSEED: 3, FOLD: 1, EPOCH: 18,train_loss: 0.012357892063648804, valid_loss: 0.019724327751568387\nSEED: 3, FOLD: 1, EPOCH: 19,train_loss: 0.010653473828257858, valid_loss: 0.020085486343928746\nSEED: 3, FOLD: 1, EPOCH: 20,train_loss: 0.008992749873710714, valid_loss: 0.020448907411524227\nSEED: 3, FOLD: 1, EPOCH: 21,train_loss: 0.007678866005111216, valid_loss: 0.020695483152355466\nSEED: 3, FOLD: 1, EPOCH: 22,train_loss: 0.0067587175872176886, valid_loss: 0.020880409862313952\nSEED: 3, FOLD: 1, EPOCH: 23,train_loss: 0.006318317311208533, valid_loss: 0.020981426537036895\nSEED: 3, FOLD: 1, EPOCH: 24,train_loss: 0.006146137079601918, valid_loss: 0.020946198595421656\nFOLD: 2, EPOCH: 0,train_loss: 0.7332160290140305, valid_loss: 0.7014123831476484\nSEED: 3, FOLD: 2, EPOCH: 0,train_loss: 0.4706819709390402, valid_loss: 0.02472070466194834\nSEED: 3, FOLD: 2, EPOCH: 1,train_loss: 0.02199273575505201, valid_loss: 0.02173606934291976\nSEED: 3, FOLD: 2, EPOCH: 2,train_loss: 0.020463820533269513, valid_loss: 0.019565114166055407\nSEED: 3, FOLD: 2, EPOCH: 3,train_loss: 0.01903480447720002, valid_loss: 0.018991662827985627\nSEED: 3, FOLD: 2, EPOCH: 4,train_loss: 0.018328402069036978, valid_loss: 0.024732377167258943\nSEED: 3, FOLD: 2, EPOCH: 5,train_loss: 0.017931507900357246, valid_loss: 0.018967579305171966\nSEED: 3, FOLD: 2, EPOCH: 6,train_loss: 0.017763687392873484, valid_loss: 0.018641829783363\nSEED: 3, FOLD: 2, EPOCH: 7,train_loss: 0.017400767327877726, valid_loss: 0.019023722037672997\nSEED: 3, FOLD: 2, EPOCH: 8,train_loss: 0.017242363110239054, valid_loss: 0.018655288432325636\nSEED: 3, FOLD: 2, EPOCH: 9,train_loss: 0.01699770157001097, valid_loss: 0.01873142501073224\nSEED: 3, FOLD: 2, EPOCH: 10,train_loss: 0.016864770703887852, valid_loss: 0.018299564187015806\nSEED: 3, FOLD: 2, EPOCH: 11,train_loss: 0.01663053094198669, valid_loss: 0.018786227676485266\nSEED: 3, FOLD: 2, EPOCH: 12,train_loss: 0.01631210046908716, valid_loss: 0.018643517792224885\nSEED: 3, FOLD: 2, EPOCH: 13,train_loss: 0.016000463926389704, valid_loss: 0.018859208508261612\nSEED: 3, FOLD: 2, EPOCH: 14,train_loss: 0.01562922296325003, valid_loss: 0.01870725854699101\nSEED: 3, FOLD: 2, EPOCH: 15,train_loss: 0.015070322819434814, valid_loss: 0.019655133464506695\nSEED: 3, FOLD: 2, EPOCH: 16,train_loss: 0.014309987031521589, valid_loss: 0.020197951634015356\nSEED: 3, FOLD: 2, EPOCH: 17,train_loss: 0.013334003576233874, valid_loss: 0.019973576707499368\nSEED: 3, FOLD: 2, EPOCH: 18,train_loss: 0.012174671182721636, valid_loss: 0.02050068559391158\nSEED: 3, FOLD: 2, EPOCH: 19,train_loss: 0.01084047535529537, valid_loss: 0.020827750914863177\nSEED: 3, FOLD: 2, EPOCH: 20,train_loss: 0.00935199345550398, valid_loss: 0.021269593547497478\nSEED: 3, FOLD: 2, EPOCH: 21,train_loss: 0.008110658041317097, valid_loss: 0.021393723306911333\nSEED: 3, FOLD: 2, EPOCH: 22,train_loss: 0.007236230207511979, valid_loss: 0.02160737035529954\nSEED: 3, FOLD: 2, EPOCH: 23,train_loss: 0.006757741566257973, valid_loss: 0.021539070350783212\nSEED: 3, FOLD: 2, EPOCH: 24,train_loss: 0.006566665628177188, valid_loss: 0.021549325329916817\nFOLD: 3, EPOCH: 0,train_loss: 0.7330808902996174, valid_loss: 0.6999652368681771\nSEED: 3, FOLD: 3, EPOCH: 0,train_loss: 0.4696438139493483, valid_loss: 0.024151586049369404\nSEED: 3, FOLD: 3, EPOCH: 1,train_loss: 0.021709081568363785, valid_loss: 0.02052308762712138\nSEED: 3, FOLD: 3, EPOCH: 2,train_loss: 0.020268452731703503, valid_loss: 0.018686613706605775\nSEED: 3, FOLD: 3, EPOCH: 3,train_loss: 0.019084968874096008, valid_loss: 0.021750707738101484\nSEED: 3, FOLD: 3, EPOCH: 4,train_loss: 0.01846094582688765, valid_loss: 0.018292708482061115\nSEED: 3, FOLD: 3, EPOCH: 5,train_loss: 0.017942132947939463, valid_loss: 0.018062093295156956\nSEED: 3, FOLD: 3, EPOCH: 6,train_loss: 0.017659460552090753, valid_loss: 0.018460536535297122\nSEED: 3, FOLD: 3, EPOCH: 7,train_loss: 0.017360315455690674, valid_loss: 0.018214409026716435\nSEED: 3, FOLD: 3, EPOCH: 8,train_loss: 0.017132105076334614, valid_loss: 0.018124612207923618\nSEED: 3, FOLD: 3, EPOCH: 9,train_loss: 0.016964721898345844, valid_loss: 0.01840576332594667\nSEED: 3, FOLD: 3, EPOCH: 10,train_loss: 0.0168754318729043, valid_loss: 0.017983365298381872\nSEED: 3, FOLD: 3, EPOCH: 11,train_loss: 0.016676551183226748, valid_loss: 0.018355448544025422\nSEED: 3, FOLD: 3, EPOCH: 12,train_loss: 0.01635564075431962, valid_loss: 0.018355923970895156\nSEED: 3, FOLD: 3, EPOCH: 13,train_loss: 0.016071844731282064, valid_loss: 0.018399575405887197\nSEED: 3, FOLD: 3, EPOCH: 14,train_loss: 0.01566729465148587, valid_loss: 0.019336193108132907\nSEED: 3, FOLD: 3, EPOCH: 15,train_loss: 0.015239515017880045, valid_loss: 0.018911276864154\nSEED: 3, FOLD: 3, EPOCH: 16,train_loss: 0.01446459007759889, valid_loss: 0.019173689346228328\nSEED: 3, FOLD: 3, EPOCH: 17,train_loss: 0.013502652365444363, valid_loss: 0.019624742014067515\nSEED: 3, FOLD: 3, EPOCH: 18,train_loss: 0.012077561593142109, valid_loss: 0.0201087336987257\nSEED: 3, FOLD: 3, EPOCH: 19,train_loss: 0.010489738957983429, valid_loss: 0.020514032670429776\nSEED: 3, FOLD: 3, EPOCH: 20,train_loss: 0.009021942753452753, valid_loss: 0.02086180097290448\nSEED: 3, FOLD: 3, EPOCH: 21,train_loss: 0.007730317420150706, valid_loss: 0.021369538935167447\nSEED: 3, FOLD: 3, EPOCH: 22,train_loss: 0.00689086108468473, valid_loss: 0.02104791205908571\nSEED: 3, FOLD: 3, EPOCH: 23,train_loss: 0.006445082336448241, valid_loss: 0.021062730625271798\nSEED: 3, FOLD: 3, EPOCH: 24,train_loss: 0.006313405269621939, valid_loss: 0.02108997032046318\nFOLD: 4, EPOCH: 0,train_loss: 0.7331804267681428, valid_loss: 0.7040667278426034\nSEED: 3, FOLD: 4, EPOCH: 0,train_loss: 0.47120354842584933, valid_loss: 0.024491594039968083\nSEED: 3, FOLD: 4, EPOCH: 1,train_loss: 0.02189886024779212, valid_loss: 0.020592315707887922\nSEED: 3, FOLD: 4, EPOCH: 2,train_loss: 0.02062670368510876, valid_loss: 0.018780013333473886\nSEED: 3, FOLD: 4, EPOCH: 3,train_loss: 0.01926073310964734, valid_loss: 0.017887835444084236\nSEED: 3, FOLD: 4, EPOCH: 4,train_loss: 0.01837451236635229, valid_loss: 0.017744873304452215\nSEED: 3, FOLD: 4, EPOCH: 5,train_loss: 0.01795042945874216, valid_loss: 0.01777755195008857\nSEED: 3, FOLD: 4, EPOCH: 6,train_loss: 0.017611850719273524, valid_loss: 0.23380259773028747\nSEED: 3, FOLD: 4, EPOCH: 7,train_loss: 0.01731049705867785, valid_loss: 0.018200211519641536\nSEED: 3, FOLD: 4, EPOCH: 8,train_loss: 0.01717504241034715, valid_loss: 0.017809169207300458\nSEED: 3, FOLD: 4, EPOCH: 9,train_loss: 0.017051401289764546, valid_loss: 0.017732111950005805\nSEED: 3, FOLD: 4, EPOCH: 10,train_loss: 0.016846547909352902, valid_loss: 0.018203031670834337\nSEED: 3, FOLD: 4, EPOCH: 11,train_loss: 0.016724955141000503, valid_loss: 0.0177844785419958\nSEED: 3, FOLD: 4, EPOCH: 12,train_loss: 0.016518130912071598, valid_loss: 0.017909793662173407\nSEED: 3, FOLD: 4, EPOCH: 13,train_loss: 0.01619534627500459, valid_loss: 0.01776737373854433\nSEED: 3, FOLD: 4, EPOCH: 14,train_loss: 0.01580930737112343, valid_loss: 0.14904016639505113\nSEED: 3, FOLD: 4, EPOCH: 15,train_loss: 0.015611198798746524, valid_loss: 0.018085439396756036\nSEED: 3, FOLD: 4, EPOCH: 16,train_loss: 0.014676282032780404, valid_loss: 0.01885012664965221\nSEED: 3, FOLD: 4, EPOCH: 17,train_loss: 0.013677767260394392, valid_loss: 0.019142783699291094\nSEED: 3, FOLD: 4, EPOCH: 18,train_loss: 0.012302673204264937, valid_loss: 0.019874113744923046\nSEED: 3, FOLD: 4, EPOCH: 19,train_loss: 0.010707452342621167, valid_loss: 0.020222465747169086\nSEED: 3, FOLD: 4, EPOCH: 20,train_loss: 0.009143256133653386, valid_loss: 0.02041981481015682\nSEED: 3, FOLD: 4, EPOCH: 21,train_loss: 0.007794526171102358, valid_loss: 0.020514201585735595\nSEED: 3, FOLD: 4, EPOCH: 22,train_loss: 0.0069272175879917875, valid_loss: 0.020536835757749422\nSEED: 3, FOLD: 4, EPOCH: 23,train_loss: 0.006469702436486735, valid_loss: 0.020595888420939446\nSEED: 3, FOLD: 4, EPOCH: 24,train_loss: 0.0063382399907458, valid_loss: 0.020621133223176002\nFOLD: 0, EPOCH: 0,train_loss: 0.733754473319952, valid_loss: 0.695405924320221\nSEED: 4, FOLD: 0, EPOCH: 0,train_loss: 0.4680735827221171, valid_loss: 0.024467648885079792\nSEED: 4, FOLD: 0, EPOCH: 1,train_loss: 0.021612441072753376, valid_loss: 0.020710616292698044\nSEED: 4, FOLD: 0, EPOCH: 2,train_loss: 0.020396591191166553, valid_loss: 0.020262358923043525\nSEED: 4, FOLD: 0, EPOCH: 3,train_loss: 0.019228630051340744, valid_loss: 0.019260741184864726\nSEED: 4, FOLD: 0, EPOCH: 4,train_loss: 0.01861711985607078, valid_loss: 202.25520723760127\nSEED: 4, FOLD: 0, EPOCH: 5,train_loss: 0.01813989085401746, valid_loss: 4.949755712119597\nSEED: 4, FOLD: 0, EPOCH: 6,train_loss: 0.0178061470227397, valid_loss: 3.9903491270861458\nSEED: 4, FOLD: 0, EPOCH: 7,train_loss: 0.017514000147365143, valid_loss: 0.0179931621200272\nSEED: 4, FOLD: 0, EPOCH: 8,train_loss: 0.017318942503112812, valid_loss: 0.018701447173953056\nSEED: 4, FOLD: 0, EPOCH: 9,train_loss: 0.017095381758459236, valid_loss: 0.02234257427709443\nSEED: 4, FOLD: 0, EPOCH: 10,train_loss: 0.016804525534203953, valid_loss: 0.02191685044339725\nSEED: 4, FOLD: 0, EPOCH: 11,train_loss: 0.016609457739885303, valid_loss: 0.018238461523183754\nSEED: 4, FOLD: 0, EPOCH: 12,train_loss: 0.016276733072447605, valid_loss: 0.019486169304166523\nSEED: 4, FOLD: 0, EPOCH: 13,train_loss: 0.015888178025952715, valid_loss: 2.1996303093220506\nSEED: 4, FOLD: 0, EPOCH: 14,train_loss: 0.015378566647785297, valid_loss: 0.17839543633162974\nSEED: 4, FOLD: 0, EPOCH: 15,train_loss: 0.014705216302873863, valid_loss: 0.02000562468809741\nSEED: 4, FOLD: 0, EPOCH: 16,train_loss: 0.013790404322840597, valid_loss: 0.020529263306941305\nSEED: 4, FOLD: 0, EPOCH: 17,train_loss: 0.01269859276657951, valid_loss: 0.020006000037704197\nSEED: 4, FOLD: 0, EPOCH: 18,train_loss: 0.011285563795894816, valid_loss: 0.02135121471115521\nSEED: 4, FOLD: 0, EPOCH: 19,train_loss: 0.009806889386010775, valid_loss: 0.021402662566729954\nSEED: 4, FOLD: 0, EPOCH: 20,train_loss: 0.008438005284203784, valid_loss: 0.022258819001061577\nSEED: 4, FOLD: 0, EPOCH: 21,train_loss: 0.007333086354765987, valid_loss: 0.02305325312273843\nSEED: 4, FOLD: 0, EPOCH: 22,train_loss: 0.006662996060660352, valid_loss: 0.02310356205063207\nSEED: 4, FOLD: 0, EPOCH: 23,train_loss: 0.006305647801364894, valid_loss: 0.021729598992637225\nSEED: 4, FOLD: 0, EPOCH: 24,train_loss: 0.006155828850856726, valid_loss: 0.027569601738027163\nFOLD: 1, EPOCH: 0,train_loss: 0.7336443809495456, valid_loss: 0.6956124831648434\nSEED: 4, FOLD: 1, EPOCH: 0,train_loss: 0.46978994720763917, valid_loss: 0.023851695470511913\nSEED: 4, FOLD: 1, EPOCH: 1,train_loss: 0.021885919182196907, valid_loss: 13.69665890334941\nSEED: 4, FOLD: 1, EPOCH: 2,train_loss: 0.020064574895777565, valid_loss: 0.01897101816447342\nSEED: 4, FOLD: 1, EPOCH: 3,train_loss: 0.01880185922904723, valid_loss: 0.018688070752164897\nSEED: 4, FOLD: 1, EPOCH: 4,train_loss: 0.018127263267187103, valid_loss: 0.018493763116352698\nSEED: 4, FOLD: 1, EPOCH: 5,train_loss: 0.01766907168633264, valid_loss: 0.01920572087606963\nSEED: 4, FOLD: 1, EPOCH: 6,train_loss: 0.017332941536670147, valid_loss: 0.018412295427611646\nSEED: 4, FOLD: 1, EPOCH: 7,train_loss: 0.016942500831910234, valid_loss: 0.018592494485132834\nSEED: 4, FOLD: 1, EPOCH: 8,train_loss: 0.01668366437534923, valid_loss: 0.018656891661093515\nSEED: 4, FOLD: 1, EPOCH: 9,train_loss: 0.01642207116347508, valid_loss: 0.018677466905073208\nSEED: 4, FOLD: 1, EPOCH: 10,train_loss: 0.016147033102216497, valid_loss: 0.019270963254658616\nSEED: 4, FOLD: 1, EPOCH: 11,train_loss: 0.0158224877010545, valid_loss: 0.019027579164899448\nSEED: 4, FOLD: 1, EPOCH: 12,train_loss: 0.0154881054279057, valid_loss: 0.01926616151981494\nSEED: 4, FOLD: 1, EPOCH: 13,train_loss: 0.014958414323358, valid_loss: 0.019692119320525843\nSEED: 4, FOLD: 1, EPOCH: 14,train_loss: 0.014343449130546356, valid_loss: 0.019845286439008573\nSEED: 4, FOLD: 1, EPOCH: 15,train_loss: 0.013490603602342848, valid_loss: 0.020199728088782114\nSEED: 4, FOLD: 1, EPOCH: 16,train_loss: 0.01240804073387298, valid_loss: 0.021464827415697715\nSEED: 4, FOLD: 1, EPOCH: 17,train_loss: 0.01123676503725026, valid_loss: 0.021609374212429804\nSEED: 4, FOLD: 1, EPOCH: 18,train_loss: 0.009748862597389498, valid_loss: 0.021984967074411756\nSEED: 4, FOLD: 1, EPOCH: 19,train_loss: 0.008340514781277465, valid_loss: 0.02184570038362461\nSEED: 4, FOLD: 1, EPOCH: 20,train_loss: 0.007172782247400154, valid_loss: 0.021903065690661177\nSEED: 4, FOLD: 1, EPOCH: 21,train_loss: 0.0063712209112186365, valid_loss: 0.0218671155436074\nSEED: 4, FOLD: 1, EPOCH: 22,train_loss: 0.005879534158747697, valid_loss: 0.021826739696895376\nSEED: 4, FOLD: 1, EPOCH: 23,train_loss: 0.005625045638990359, valid_loss: 0.021774475079248932\nSEED: 4, FOLD: 1, EPOCH: 24,train_loss: 0.005542537983695882, valid_loss: 0.021837157745133427\nFOLD: 2, EPOCH: 0,train_loss: 0.7337059313836305, valid_loss: 0.6945890733173915\nSEED: 4, FOLD: 2, EPOCH: 0,train_loss: 0.4686448779632, valid_loss: 0.023157321475446226\nSEED: 4, FOLD: 2, EPOCH: 1,train_loss: 0.02152257713664701, valid_loss: 0.020197990483471324\nSEED: 4, FOLD: 2, EPOCH: 2,train_loss: 0.02039450622987056, valid_loss: 0.01850315590522119\nSEED: 4, FOLD: 2, EPOCH: 3,train_loss: 0.01915604567182237, valid_loss: 0.017687950669122595\nSEED: 4, FOLD: 2, EPOCH: 4,train_loss: 0.018324681611704655, valid_loss: 0.017490759744708026\nSEED: 4, FOLD: 2, EPOCH: 5,train_loss: 0.017827271942751133, valid_loss: 0.01813538134364145\nSEED: 4, FOLD: 2, EPOCH: 6,train_loss: 0.017469687049911507, valid_loss: 0.01765400247116174\nSEED: 4, FOLD: 2, EPOCH: 7,train_loss: 0.017249430232829807, valid_loss: 0.02168181368282863\nSEED: 4, FOLD: 2, EPOCH: 8,train_loss: 0.01707354310117122, valid_loss: 0.017564395708697184\nSEED: 4, FOLD: 2, EPOCH: 9,train_loss: 0.01701508413163432, valid_loss: 0.018769067765346596\nSEED: 4, FOLD: 2, EPOCH: 10,train_loss: 0.01686639249648737, valid_loss: 0.05844368724418538\nSEED: 4, FOLD: 2, EPOCH: 11,train_loss: 0.016723547306289707, valid_loss: 0.018202125281095504\nSEED: 4, FOLD: 2, EPOCH: 12,train_loss: 0.016492175599695114, valid_loss: 0.017479107781712497\nSEED: 4, FOLD: 2, EPOCH: 13,train_loss: 0.01621641381306277, valid_loss: 0.018766316665070396\nSEED: 4, FOLD: 2, EPOCH: 14,train_loss: 0.015863992962176384, valid_loss: 0.024819316808134317\nSEED: 4, FOLD: 2, EPOCH: 15,train_loss: 0.015214694414179827, valid_loss: 0.01791902274957725\nSEED: 4, FOLD: 2, EPOCH: 16,train_loss: 0.014419088248109472, valid_loss: 0.01828284077346325\nSEED: 4, FOLD: 2, EPOCH: 17,train_loss: 0.013431822766374418, valid_loss: 0.01880215975855078\nSEED: 4, FOLD: 2, EPOCH: 18,train_loss: 0.011955459696659143, valid_loss: 0.018996573545570883\nSEED: 4, FOLD: 2, EPOCH: 19,train_loss: 0.01037167929166901, valid_loss: 0.02003993909539921\nSEED: 4, FOLD: 2, EPOCH: 20,train_loss: 0.008773338896613837, valid_loss: 0.01987619806480195\nSEED: 4, FOLD: 2, EPOCH: 21,train_loss: 0.0075467425580743866, valid_loss: 0.020113877772486636\nSEED: 4, FOLD: 2, EPOCH: 22,train_loss: 0.006734019438938602, valid_loss: 0.02029821528121829\nSEED: 4, FOLD: 2, EPOCH: 23,train_loss: 0.0063589169724803905, valid_loss: 0.02029684883808451\nSEED: 4, FOLD: 2, EPOCH: 24,train_loss: 0.006204991108751384, valid_loss: 0.020311281011839\nFOLD: 3, EPOCH: 0,train_loss: 0.7338532598122306, valid_loss: 0.6943812131881714\nSEED: 4, FOLD: 3, EPOCH: 0,train_loss: 0.4696593356548228, valid_loss: 0.02560509970145566\nSEED: 4, FOLD: 3, EPOCH: 1,train_loss: 0.02197136820388445, valid_loss: 0.020685620605945587\nSEED: 4, FOLD: 3, EPOCH: 2,train_loss: 0.020924976298018642, valid_loss: 53.48994697422854\nSEED: 4, FOLD: 3, EPOCH: 3,train_loss: 0.020107796753122322, valid_loss: 0.021378163993358613\nSEED: 4, FOLD: 3, EPOCH: 4,train_loss: 0.019370071826151747, valid_loss: 27.537232274402466\nSEED: 4, FOLD: 3, EPOCH: 5,train_loss: 0.0188019458083031, valid_loss: 0.018462159378187997\nSEED: 4, FOLD: 3, EPOCH: 6,train_loss: 0.01835376911027276, valid_loss: 0.02357362514095647\nSEED: 4, FOLD: 3, EPOCH: 7,train_loss: 0.01889764725406101, valid_loss: 0.6740098289613213\nSEED: 4, FOLD: 3, EPOCH: 8,train_loss: 0.018134985874960388, valid_loss: 0.08156628776341676\nSEED: 4, FOLD: 3, EPOCH: 9,train_loss: 0.01777867059074882, valid_loss: 0.026149164406316622\nSEED: 4, FOLD: 3, EPOCH: 10,train_loss: 0.01754619436932431, valid_loss: 0.2861300931711282\nSEED: 4, FOLD: 3, EPOCH: 11,train_loss: 0.01710904990930272, valid_loss: 0.023563895906720842\nSEED: 4, FOLD: 3, EPOCH: 12,train_loss: 0.019191795710366274, valid_loss: 0.018868411598461015\nSEED: 4, FOLD: 3, EPOCH: 13,train_loss: 0.018405256178769945, valid_loss: 0.9658348800880568\nSEED: 4, FOLD: 3, EPOCH: 14,train_loss: 0.019171614557558645, valid_loss: 1.9784555755289537\nSEED: 4, FOLD: 3, EPOCH: 15,train_loss: 0.018319065480128578, valid_loss: 0.8197303865637098\nSEED: 4, FOLD: 3, EPOCH: 16,train_loss: 0.017801358317281458, valid_loss: 0.07857784352132252\nSEED: 4, FOLD: 3, EPOCH: 17,train_loss: 0.017258399267397497, valid_loss: 0.01777147759816476\nSEED: 4, FOLD: 3, EPOCH: 18,train_loss: 0.016951049138130485, valid_loss: 0.09434411073369639\nSEED: 4, FOLD: 3, EPOCH: 19,train_loss: 0.016495650580179863, valid_loss: 0.02852999307215214\nSEED: 4, FOLD: 3, EPOCH: 20,train_loss: 0.017112026564722906, valid_loss: 0.02075331330831562\nSEED: 4, FOLD: 3, EPOCH: 21,train_loss: 0.0167336269059097, valid_loss: 0.018071507156959602\nSEED: 4, FOLD: 3, EPOCH: 22,train_loss: 0.01635296624558775, valid_loss: 0.017936012627823014\nSEED: 4, FOLD: 3, EPOCH: 23,train_loss: 0.016164110258113647, valid_loss: 0.026608397918088094\nSEED: 4, FOLD: 3, EPOCH: 24,train_loss: 0.016020840843734535, valid_loss: 0.018047850472586495\nFOLD: 4, EPOCH: 0,train_loss: 0.7334336699360479, valid_loss: 0.6918671250343322\nSEED: 4, FOLD: 4, EPOCH: 0,train_loss: 0.4699339180994425, valid_loss: 0.02447191732270377\nSEED: 4, FOLD: 4, EPOCH: 1,train_loss: 0.021717628464102745, valid_loss: 0.020848906306283815\nSEED: 4, FOLD: 4, EPOCH: 2,train_loss: 0.020275458584736734, valid_loss: 0.019129659182259014\nSEED: 4, FOLD: 4, EPOCH: 3,train_loss: 0.018924233170538922, valid_loss: 0.018589315935969353\nSEED: 4, FOLD: 4, EPOCH: 4,train_loss: 0.018246406444559132, valid_loss: 0.022755437876496996\nSEED: 4, FOLD: 4, EPOCH: 5,train_loss: 0.01773999216728402, valid_loss: 0.018668680797730174\nSEED: 4, FOLD: 4, EPOCH: 6,train_loss: 0.017431862659099764, valid_loss: 0.03395993845271213\nSEED: 4, FOLD: 4, EPOCH: 7,train_loss: 0.017160142316435374, valid_loss: 0.01844380867800542\nSEED: 4, FOLD: 4, EPOCH: 8,train_loss: 0.016934667727536094, valid_loss: 0.018282419443130492\nSEED: 4, FOLD: 4, EPOCH: 9,train_loss: 0.016768297051371884, valid_loss: 0.018327564187347888\nSEED: 4, FOLD: 4, EPOCH: 10,train_loss: 0.01668070454531125, valid_loss: 0.018405531799154624\nSEED: 4, FOLD: 4, EPOCH: 11,train_loss: 0.01651353539259982, valid_loss: 0.022402514410870416\nSEED: 4, FOLD: 4, EPOCH: 12,train_loss: 0.016195826266423193, valid_loss: 0.01847878218229328\nSEED: 4, FOLD: 4, EPOCH: 13,train_loss: 0.015836090746804747, valid_loss: 0.01869150722133262\nSEED: 4, FOLD: 4, EPOCH: 14,train_loss: 0.015389910090143663, valid_loss: 0.018849384625043188\nSEED: 4, FOLD: 4, EPOCH: 15,train_loss: 0.014695233780972278, valid_loss: 0.019236226699181964\nSEED: 4, FOLD: 4, EPOCH: 16,train_loss: 0.013848483338136307, valid_loss: 0.019573695957660675\nSEED: 4, FOLD: 4, EPOCH: 17,train_loss: 0.012748392781473859, valid_loss: 0.02042516613645213\nSEED: 4, FOLD: 4, EPOCH: 18,train_loss: 0.01130281619890763, valid_loss: 0.02038730861885207\nSEED: 4, FOLD: 4, EPOCH: 19,train_loss: 0.009812253765272397, valid_loss: 0.020868736558726855\nSEED: 4, FOLD: 4, EPOCH: 20,train_loss: 0.008429898489538554, valid_loss: 0.021195793311510766\nSEED: 4, FOLD: 4, EPOCH: 21,train_loss: 0.007330688729501554, valid_loss: 0.021313741430640222\nSEED: 4, FOLD: 4, EPOCH: 22,train_loss: 0.006618960604180385, valid_loss: 0.021355949235813958\nSEED: 4, FOLD: 4, EPOCH: 23,train_loss: 0.006265888320295698, valid_loss: 0.021403300921831812\nSEED: 4, FOLD: 4, EPOCH: 24,train_loss: 0.0061567928947943405, valid_loss: 0.02144788716520582\nFOLD: 0, EPOCH: 0,train_loss: 0.7326458709827368, valid_loss: 0.6857628038951329\nSEED: 5, FOLD: 0, EPOCH: 0,train_loss: 0.4677647775767938, valid_loss: 0.024590991916401045\nSEED: 5, FOLD: 0, EPOCH: 1,train_loss: 0.021654802334049473, valid_loss: 0.020457225186484202\nSEED: 5, FOLD: 0, EPOCH: 2,train_loss: 0.02002049338720415, valid_loss: 0.019921786284872463\nSEED: 5, FOLD: 0, EPOCH: 3,train_loss: 0.018826007930750864, valid_loss: 0.018864152234579837\nSEED: 5, FOLD: 0, EPOCH: 4,train_loss: 0.018091784108538126, valid_loss: 0.018247292217399392\nSEED: 5, FOLD: 0, EPOCH: 5,train_loss: 0.017453559053440888, valid_loss: 0.018863217293151786\nSEED: 5, FOLD: 0, EPOCH: 6,train_loss: 0.017031876822474642, valid_loss: 0.018341791204043795\nSEED: 5, FOLD: 0, EPOCH: 7,train_loss: 0.016664992316045624, valid_loss: 0.01841987608266728\nSEED: 5, FOLD: 0, EPOCH: 8,train_loss: 0.016387115718553894, valid_loss: 0.018406220179583346\nSEED: 5, FOLD: 0, EPOCH: 9,train_loss: 0.016256482677831165, valid_loss: 0.01854188766862665\nSEED: 5, FOLD: 0, EPOCH: 15,train_loss: 0.013042814273765121, valid_loss: 0.020457671050514492\nSEED: 5, FOLD: 0, EPOCH: 16,train_loss: 0.012010929201716099, valid_loss: 0.020683740877679418\nSEED: 5, FOLD: 0, EPOCH: 17,train_loss: 0.010720326997123766, valid_loss: 0.02197173668869904\nSEED: 5, FOLD: 0, EPOCH: 18,train_loss: 0.009191169157165332, valid_loss: 0.0221400826637234\nSEED: 5, FOLD: 0, EPOCH: 19,train_loss: 0.0077720424092874146, valid_loss: 0.02213177207325186\nSEED: 5, FOLD: 0, EPOCH: 20,train_loss: 0.006719239052736025, valid_loss: 0.021926691489560262\nSEED: 5, FOLD: 0, EPOCH: 21,train_loss: 0.005931679378736062, valid_loss: 0.022251971172434944\nFOLD: 1, EPOCH: 0,train_loss: 0.7325594895077447, valid_loss: 0.6884279234068734\nSEED: 5, FOLD: 1, EPOCH: 0,train_loss: 0.4706919244932432, valid_loss: 0.023798341516937528\nSEED: 5, FOLD: 1, EPOCH: 1,train_loss: 0.02194155865505229, valid_loss: 0.020423680809991702\nSEED: 5, FOLD: 1, EPOCH: 2,train_loss: 0.020520010582395713, valid_loss: 0.01907386103911059\nSEED: 5, FOLD: 1, EPOCH: 3,train_loss: 0.018981050577585715, valid_loss: 0.01805611095790352\nSEED: 5, FOLD: 1, EPOCH: 4,train_loss: 0.018191339903558694, valid_loss: 0.017807253184063093\nSEED: 5, FOLD: 1, EPOCH: 5,train_loss: 0.017684874362754125, valid_loss: 0.036119206036840164\nSEED: 5, FOLD: 1, EPOCH: 6,train_loss: 0.017387097667440447, valid_loss: 0.017969172155218465\nSEED: 5, FOLD: 1, EPOCH: 7,train_loss: 0.01715092838191203, valid_loss: 0.0181664999840515\nSEED: 5, FOLD: 1, EPOCH: 8,train_loss: 0.017115246429767486, valid_loss: 0.019348415679165294\nSEED: 5, FOLD: 1, EPOCH: 9,train_loss: 0.01700736727076073, valid_loss: 0.01821524713720594\nSEED: 5, FOLD: 1, EPOCH: 10,train_loss: 0.016861671649844107, valid_loss: 0.0178972632757255\nSEED: 5, FOLD: 1, EPOCH: 11,train_loss: 0.0168343218193002, valid_loss: 0.017672063569937432\nSEED: 5, FOLD: 1, EPOCH: 12,train_loss: 0.01645075508740044, valid_loss: 0.0315214563693319\nSEED: 5, FOLD: 1, EPOCH: 13,train_loss: 0.016257432031098508, valid_loss: 0.018336903303861618\nSEED: 5, FOLD: 1, EPOCH: 14,train_loss: 0.015835154590869906, valid_loss: 0.01793857842151608\nSEED: 5, FOLD: 1, EPOCH: 15,train_loss: 0.015339025146715398, valid_loss: 0.018407658327903066\nSEED: 5, FOLD: 1, EPOCH: 16,train_loss: 0.014574175020747811, valid_loss: 0.01900536412639277\nSEED: 5, FOLD: 1, EPOCH: 17,train_loss: 0.013607088184106523, valid_loss: 0.019408108560102326\nSEED: 5, FOLD: 1, EPOCH: 18,train_loss: 0.01218458993129269, valid_loss: 0.019705966008560998\nSEED: 5, FOLD: 1, EPOCH: 19,train_loss: 0.010421928997239926, valid_loss: 0.019915179429309707\nSEED: 5, FOLD: 1, EPOCH: 20,train_loss: 0.008703214527672008, valid_loss: 0.020219731224434715\nSEED: 5, FOLD: 1, EPOCH: 21,train_loss: 0.007379566927705586, valid_loss: 0.020426338698182788\nSEED: 5, FOLD: 1, EPOCH: 22,train_loss: 0.006558788073568666, valid_loss: 0.02051856123975345\nSEED: 5, FOLD: 1, EPOCH: 23,train_loss: 0.006147283615449267, valid_loss: 0.020605955964752606\nSEED: 5, FOLD: 1, EPOCH: 24,train_loss: 0.006011193958077117, valid_loss: 0.02060947333063398\nFOLD: 2, EPOCH: 0,train_loss: 0.7325884267903756, valid_loss: 0.6881399886948721\nSEED: 5, FOLD: 2, EPOCH: 0,train_loss: 0.46770075445427844, valid_loss: 0.02288665489426681\nSEED: 5, FOLD: 2, EPOCH: 1,train_loss: 0.021639601759396603, valid_loss: 0.0200103972107172\nSEED: 5, FOLD: 2, EPOCH: 2,train_loss: 0.020235375757666603, valid_loss: 0.8401420498000723\nSEED: 5, FOLD: 2, EPOCH: 3,train_loss: 0.018949177116155624, valid_loss: 0.017917420395783017\nSEED: 5, FOLD: 2, EPOCH: 4,train_loss: 0.01828005468553823, valid_loss: 0.02966240474155971\nSEED: 5, FOLD: 2, EPOCH: 5,train_loss: 0.01773742046477138, valid_loss: 0.017869976003255163\nSEED: 5, FOLD: 2, EPOCH: 6,train_loss: 0.017344352087356907, valid_loss: 0.017901926806994848\nSEED: 5, FOLD: 2, EPOCH: 7,train_loss: 0.017070412014921505, valid_loss: 0.01779116168618202\nSEED: 5, FOLD: 2, EPOCH: 8,train_loss: 0.016788584639088833, valid_loss: 0.01777188421360084\nSEED: 5, FOLD: 2, EPOCH: 9,train_loss: 0.01652262177642273, valid_loss: 0.017952266175832066\nSEED: 5, FOLD: 2, EPOCH: 10,train_loss: 0.016294536234783955, valid_loss: 0.018090803708348955\nSEED: 5, FOLD: 2, EPOCH: 11,train_loss: 0.015943858374342108, valid_loss: 0.01811191500829799\nSEED: 5, FOLD: 2, EPOCH: 12,train_loss: 0.015473436888145365, valid_loss: 0.018461205384560992\nSEED: 5, FOLD: 2, EPOCH: 13,train_loss: 0.015039352760852678, valid_loss: 0.018868259127650944\nSEED: 5, FOLD: 2, EPOCH: 14,train_loss: 0.014301015711996866, valid_loss: 0.019346305834395543\nSEED: 5, FOLD: 2, EPOCH: 15,train_loss: 0.01347648247104624, valid_loss: 0.01951384193130902\nSEED: 5, FOLD: 2, EPOCH: 16,train_loss: 0.012317293114366306, valid_loss: 0.019770467707089016\nSEED: 5, FOLD: 2, EPOCH: 17,train_loss: 0.010991181564125894, valid_loss: 0.020341992537890163\nSEED: 5, FOLD: 2, EPOCH: 18,train_loss: 0.00958538072966579, valid_loss: 0.020422825110810144\nSEED: 5, FOLD: 2, EPOCH: 19,train_loss: 0.008228225123974076, valid_loss: 0.020864079360451017\nSEED: 5, FOLD: 2, EPOCH: 20,train_loss: 0.007103106961923017, valid_loss: 0.020890373630183083\nSEED: 5, FOLD: 2, EPOCH: 21,train_loss: 0.0062760127931023426, valid_loss: 0.020849069420780453\nSEED: 5, FOLD: 2, EPOCH: 22,train_loss: 0.005789716387221562, valid_loss: 0.020841805104698453\nSEED: 5, FOLD: 2, EPOCH: 23,train_loss: 0.005584152361405068, valid_loss: 0.020922998019627163\nSEED: 5, FOLD: 2, EPOCH: 24,train_loss: 0.005480747541709655, valid_loss: 0.020903938902275904\nFOLD: 3, EPOCH: 0,train_loss: 0.7321574879388739, valid_loss: 0.689297992842538\nSEED: 5, FOLD: 3, EPOCH: 0,train_loss: 0.4704050928979677, valid_loss: 0.02429312366460051\nSEED: 5, FOLD: 3, EPOCH: 1,train_loss: 0.021566130139314344, valid_loss: 0.020699339147124973\nSEED: 5, FOLD: 3, EPOCH: 2,train_loss: 0.019817606056530546, valid_loss: 0.018989613971539906\nSEED: 5, FOLD: 3, EPOCH: 3,train_loss: 0.018549721184982, valid_loss: 0.018800395354628564\nSEED: 5, FOLD: 3, EPOCH: 4,train_loss: 0.017768489611573027, valid_loss: 0.018265184494001524\nSEED: 5, FOLD: 3, EPOCH: 5,train_loss: 0.017285573799299063, valid_loss: 0.01871312702340739\nSEED: 5, FOLD: 3, EPOCH: 6,train_loss: 0.01684729671989479, valid_loss: 0.018422783964446614\nSEED: 5, FOLD: 3, EPOCH: 7,train_loss: 0.016537802089957424, valid_loss: 0.018267871466066156\nSEED: 5, FOLD: 3, EPOCH: 8,train_loss: 0.016368319185273927, valid_loss: 0.01860925094889743\nSEED: 5, FOLD: 3, EPOCH: 9,train_loss: 0.016112076050608697, valid_loss: 0.01958734369171517\nSEED: 5, FOLD: 3, EPOCH: 10,train_loss: 0.01586991592045248, valid_loss: 0.01904608719050884\nSEED: 5, FOLD: 3, EPOCH: 11,train_loss: 0.015594088336466437, valid_loss: 0.019031950618539538\nSEED: 5, FOLD: 3, EPOCH: 12,train_loss: 0.015103798142097292, valid_loss: 0.01924272286040442\nSEED: 5, FOLD: 3, EPOCH: 13,train_loss: 0.014566386376854278, valid_loss: 0.019241166646991457\nSEED: 5, FOLD: 3, EPOCH: 14,train_loss: 0.01382021516915003, valid_loss: 0.019648057115929467\nSEED: 5, FOLD: 3, EPOCH: 15,train_loss: 0.012963447461489343, valid_loss: 0.020021160745194982\nSEED: 5, FOLD: 3, EPOCH: 16,train_loss: 0.01161035054438088, valid_loss: 0.021051283766116414\nSEED: 5, FOLD: 3, EPOCH: 17,train_loss: 0.010276899081620857, valid_loss: 0.02124640526516097\nSEED: 5, FOLD: 3, EPOCH: 18,train_loss: 0.008858850269993074, valid_loss: 0.02155360435800893\nSEED: 5, FOLD: 3, EPOCH: 19,train_loss: 0.007516690291953783, valid_loss: 0.02144278394324439\nSEED: 5, FOLD: 3, EPOCH: 20,train_loss: 0.006495702301362788, valid_loss: 0.021697419456073216\nSEED: 5, FOLD: 3, EPOCH: 21,train_loss: 0.005831622977462345, valid_loss: 0.021556378794567926\nSEED: 5, FOLD: 3, EPOCH: 22,train_loss: 0.0054451438843061886, valid_loss: 0.021593903803399633\nSEED: 5, FOLD: 3, EPOCH: 23,train_loss: 0.005271271391207501, valid_loss: 0.021579084119626453\nSEED: 5, FOLD: 3, EPOCH: 24,train_loss: 0.005191723608758545, valid_loss: 0.021545968683702604\nFOLD: 4, EPOCH: 0,train_loss: 0.7325960108335468, valid_loss: 0.6875758434043211\nSEED: 5, FOLD: 4, EPOCH: 0,train_loss: 0.46925672378552996, valid_loss: 0.023882145445574734\nSEED: 5, FOLD: 4, EPOCH: 1,train_loss: 0.021535981014586876, valid_loss: 0.02104585902655826\nSEED: 5, FOLD: 4, EPOCH: 2,train_loss: 0.019964473119572453, valid_loss: 0.019155839896377397\nSEED: 5, FOLD: 4, EPOCH: 3,train_loss: 0.018656156390257504, valid_loss: 0.01842827651211444\nSEED: 5, FOLD: 4, EPOCH: 4,train_loss: 0.017873383039419634, valid_loss: 0.01855372396462104\nSEED: 5, FOLD: 4, EPOCH: 5,train_loss: 0.01736287014099999, valid_loss: 0.8754287800368141\nSEED: 5, FOLD: 4, EPOCH: 6,train_loss: 0.016950306914530804, valid_loss: 0.018839323674054706\nSEED: 5, FOLD: 4, EPOCH: 7,train_loss: 0.016646277814077726, valid_loss: 0.018687335445600396\nSEED: 5, FOLD: 4, EPOCH: 8,train_loss: 0.01639834402695946, valid_loss: 0.01861680348348968\nSEED: 5, FOLD: 4, EPOCH: 9,train_loss: 0.016125583481313526, valid_loss: 0.018972608699079824\nSEED: 5, FOLD: 4, EPOCH: 10,train_loss: 0.015829613128596026, valid_loss: 0.019269456265165526\nSEED: 5, FOLD: 4, EPOCH: 11,train_loss: 0.015617626550458912, valid_loss: 0.018968808902975393\nSEED: 5, FOLD: 4, EPOCH: 12,train_loss: 0.015182625596829947, valid_loss: 0.01920278008808108\nSEED: 5, FOLD: 4, EPOCH: 13,train_loss: 0.014657043055563734, valid_loss: 0.01969540787532049\nSEED: 5, FOLD: 4, EPOCH: 14,train_loss: 0.013839760505040918, valid_loss: 0.01990778333343127\nSEED: 5, FOLD: 4, EPOCH: 15,train_loss: 0.01307814471774559, valid_loss: 0.020546928595970657\nSEED: 5, FOLD: 4, EPOCH: 16,train_loss: 0.0118953264048458, valid_loss: 0.021080303005874157\nSEED: 5, FOLD: 4, EPOCH: 17,train_loss: 0.01049894999469752, valid_loss: 0.021340382285416126\nSEED: 5, FOLD: 4, EPOCH: 18,train_loss: 0.009063998088780521, valid_loss: 0.02158872810575892\nSEED: 5, FOLD: 4, EPOCH: 19,train_loss: 0.007740278616952507, valid_loss: 0.021924940650077426\nSEED: 5, FOLD: 4, EPOCH: 20,train_loss: 0.00663218946547072, valid_loss: 0.022007510339950815\nSEED: 5, FOLD: 4, EPOCH: 21,train_loss: 0.005914261777196889, valid_loss: 0.021867723423330224\nSEED: 5, FOLD: 4, EPOCH: 22,train_loss: 0.005527546733914726, valid_loss: 0.021918879493194467\nSEED: 5, FOLD: 4, EPOCH: 23,train_loss: 0.005341980990994236, valid_loss: 0.021919345976236987\nSEED: 5, FOLD: 4, EPOCH: 24,train_loss: 0.00526451062667521, valid_loss: 0.02189555364277433\nFOLD: 0, EPOCH: 0,train_loss: 0.7315557333674744, valid_loss: 0.7042827929769243\nSEED: 6, FOLD: 0, EPOCH: 0,train_loss: 0.4710091977876468, valid_loss: 0.024834492589746203\nSEED: 6, FOLD: 0, EPOCH: 1,train_loss: 0.021876868825868097, valid_loss: 0.021125390008091927\nSEED: 6, FOLD: 0, EPOCH: 2,train_loss: 0.020332247535460188, valid_loss: 0.019464553679738726\nSEED: 6, FOLD: 0, EPOCH: 3,train_loss: 0.018990176709463995, valid_loss: 0.01874915600887367\nSEED: 6, FOLD: 0, EPOCH: 4,train_loss: 0.01830859753527563, valid_loss: 0.018494266218372753\nSEED: 6, FOLD: 0, EPOCH: 5,train_loss: 0.017940244379106664, valid_loss: 0.039975912044090886\nSEED: 6, FOLD: 0, EPOCH: 6,train_loss: 0.01742331014714972, valid_loss: 0.0180257931883846\nSEED: 6, FOLD: 0, EPOCH: 7,train_loss: 0.01723056407577365, valid_loss: 0.018071230367890427\nSEED: 6, FOLD: 0, EPOCH: 8,train_loss: 0.017089258403564893, valid_loss: 0.018762938997575213\nSEED: 6, FOLD: 0, EPOCH: 9,train_loss: 0.016898950840598042, valid_loss: 0.018083334554518972\nSEED: 6, FOLD: 0, EPOCH: 10,train_loss: 0.016768043908378938, valid_loss: 0.017986009057079044\nSEED: 6, FOLD: 0, EPOCH: 11,train_loss: 0.016579950343899048, valid_loss: 0.01828139972473894\nSEED: 6, FOLD: 0, EPOCH: 12,train_loss: 0.01640565653270396, valid_loss: 0.018370881729892322\nSEED: 6, FOLD: 0, EPOCH: 13,train_loss: 0.016086464571039173, valid_loss: 0.01884527099984033\nSEED: 6, FOLD: 0, EPOCH: 14,train_loss: 0.015552572124250178, valid_loss: 0.02202163413167\nSEED: 6, FOLD: 0, EPOCH: 15,train_loss: 0.015040758432969994, valid_loss: 0.018988331300871714\nSEED: 6, FOLD: 0, EPOCH: 16,train_loss: 0.014232594281924468, valid_loss: 0.01976718668426786\nSEED: 6, FOLD: 0, EPOCH: 17,train_loss: 0.013105151059962537, valid_loss: 0.020376804417797496\nSEED: 6, FOLD: 0, EPOCH: 18,train_loss: 0.011640813833877554, valid_loss: 0.021158350738031524\nSEED: 6, FOLD: 0, EPOCH: 19,train_loss: 0.010033179462010409, valid_loss: 0.0215080981275865\nSEED: 6, FOLD: 0, EPOCH: 20,train_loss: 0.00851816428063886, valid_loss: 0.021704411400215968\nSEED: 6, FOLD: 0, EPOCH: 21,train_loss: 0.00731153429628615, valid_loss: 0.021815449904118267\nSEED: 6, FOLD: 0, EPOCH: 22,train_loss: 0.006588484728233005, valid_loss: 0.021767941383378845\nSEED: 6, FOLD: 0, EPOCH: 23,train_loss: 0.006176891169055318, valid_loss: 0.02182846399290221\nSEED: 6, FOLD: 0, EPOCH: 24,train_loss: 0.006062603079761467, valid_loss: 0.02188256952379431\nFOLD: 1, EPOCH: 0,train_loss: 0.7320311764876047, valid_loss: 0.7081807340894427\nSEED: 6, FOLD: 1, EPOCH: 0,train_loss: 0.4694387978212773, valid_loss: 0.024221210022057807\nSEED: 6, FOLD: 1, EPOCH: 1,train_loss: 0.021801672713912052, valid_loss: 0.023926659034831183\nSEED: 6, FOLD: 1, EPOCH: 2,train_loss: 0.020487619030788756, valid_loss: 0.02127781409238066\nSEED: 6, FOLD: 1, EPOCH: 3,train_loss: 0.019244752675834774, valid_loss: 0.018580781561987742\nSEED: 6, FOLD: 1, EPOCH: 4,train_loss: 0.01849229303121135, valid_loss: 1.0241195250834738\nSEED: 6, FOLD: 1, EPOCH: 5,train_loss: 0.018105946487976587, valid_loss: 0.23571164325944016\nSEED: 6, FOLD: 1, EPOCH: 6,train_loss: 0.017579845793923174, valid_loss: 12.162906138173172\nSEED: 6, FOLD: 1, EPOCH: 7,train_loss: 0.017237359347442787, valid_loss: 0.018403582594224383\nSEED: 6, FOLD: 1, EPOCH: 8,train_loss: 0.017126242974368128, valid_loss: 0.874943863547274\nSEED: 6, FOLD: 1, EPOCH: 9,train_loss: 0.017058673915385767, valid_loss: 0.018740183700408253\nSEED: 6, FOLD: 1, EPOCH: 10,train_loss: 0.016851143729265616, valid_loss: 0.15471131993191584\nSEED: 6, FOLD: 1, EPOCH: 11,train_loss: 0.016625172755532505, valid_loss: 0.02365420726793153\nSEED: 6, FOLD: 1, EPOCH: 12,train_loss: 0.01669483978058333, valid_loss: 0.01861824542284012\nSEED: 6, FOLD: 1, EPOCH: 13,train_loss: 0.01655303570104466, valid_loss: 0.018666908411043032\nSEED: 6, FOLD: 1, EPOCH: 14,train_loss: 0.015720804464881836, valid_loss: 0.01923951953649521\nSEED: 6, FOLD: 1, EPOCH: 15,train_loss: 0.015433406275089668, valid_loss: 0.01973278932273388\nSEED: 6, FOLD: 1, EPOCH: 16,train_loss: 0.01487509203750802, valid_loss: 0.019320929263319287\nSEED: 6, FOLD: 1, EPOCH: 17,train_loss: 0.014114581817842049, valid_loss: 0.019681077397295407\nSEED: 6, FOLD: 1, EPOCH: 18,train_loss: 0.012609811357991852, valid_loss: 0.02060822466654437\nSEED: 6, FOLD: 1, EPOCH: 19,train_loss: 0.012267715824039085, valid_loss: 0.0202689102185624\nSEED: 6, FOLD: 1, EPOCH: 20,train_loss: 0.010132679385065601, valid_loss: 0.02072616038577897\nSEED: 6, FOLD: 1, EPOCH: 21,train_loss: 0.008967424051134267, valid_loss: 0.02097489966877869\nSEED: 6, FOLD: 1, EPOCH: 22,train_loss: 0.008024016334472792, valid_loss: 0.021069271489977837\nSEED: 6, FOLD: 1, EPOCH: 23,train_loss: 0.00740342072305688, valid_loss: 0.021150560943143708\nSEED: 6, FOLD: 1, EPOCH: 24,train_loss: 0.007236801745855938, valid_loss: 0.021195033458726746\nFOLD: 2, EPOCH: 0,train_loss: 0.7317757610857052, valid_loss: 0.7065558671951294\nSEED: 6, FOLD: 2, EPOCH: 0,train_loss: 0.4716815996072153, valid_loss: 0.02412707395851612\nSEED: 6, FOLD: 2, EPOCH: 1,train_loss: 0.021890706593429086, valid_loss: 0.020840312806623323\nSEED: 6, FOLD: 2, EPOCH: 2,train_loss: 0.020637547610885036, valid_loss: 0.35560268525566374\nSEED: 6, FOLD: 2, EPOCH: 3,train_loss: 0.019349981235326642, valid_loss: 0.019009579398802347\nSEED: 6, FOLD: 2, EPOCH: 4,train_loss: 0.01845414285976304, valid_loss: 0.018108950315841605\nSEED: 6, FOLD: 2, EPOCH: 5,train_loss: 0.01786297414261494, valid_loss: 0.018196545142148222\nSEED: 6, FOLD: 2, EPOCH: 6,train_loss: 0.017429383084123586, valid_loss: 0.017903451275612627\nSEED: 6, FOLD: 2, EPOCH: 7,train_loss: 0.017140623209250236, valid_loss: 0.018152950038867337\nSEED: 6, FOLD: 2, EPOCH: 8,train_loss: 0.01685092804178487, valid_loss: 0.018026403045015675\nSEED: 6, FOLD: 2, EPOCH: 9,train_loss: 0.016691527064264255, valid_loss: 0.018068059374179157\nSEED: 6, FOLD: 2, EPOCH: 10,train_loss: 0.01643146219642928, valid_loss: 0.0182949102882828\nSEED: 6, FOLD: 2, EPOCH: 11,train_loss: 0.016194825563715758, valid_loss: 0.018392679361360412\nSEED: 6, FOLD: 2, EPOCH: 12,train_loss: 0.015788574573876214, valid_loss: 0.018457747623324396\nSEED: 6, FOLD: 2, EPOCH: 13,train_loss: 0.015431221676514532, valid_loss: 0.018745766686541692\nSEED: 6, FOLD: 2, EPOCH: 14,train_loss: 0.014795306288249736, valid_loss: 0.019057512496198928\nSEED: 6, FOLD: 2, EPOCH: 15,train_loss: 0.014032766379307221, valid_loss: 0.019446638173290662\nSEED: 6, FOLD: 2, EPOCH: 16,train_loss: 0.013019254199997351, valid_loss: 0.10234798549541406\nSEED: 6, FOLD: 2, EPOCH: 17,train_loss: 0.01162921123369767, valid_loss: 0.020561579960797514\nSEED: 6, FOLD: 2, EPOCH: 18,train_loss: 0.010255248156668496, valid_loss: 0.02107894378049033\nSEED: 6, FOLD: 2, EPOCH: 19,train_loss: 0.008723254913776896, valid_loss: 0.021367146873048373\nSEED: 6, FOLD: 2, EPOCH: 20,train_loss: 0.007394014820320545, valid_loss: 0.021440757092620645\nSEED: 6, FOLD: 2, EPOCH: 21,train_loss: 0.006495076068507059, valid_loss: 0.0214698479909982\nSEED: 6, FOLD: 2, EPOCH: 22,train_loss: 0.005982328182507823, valid_loss: 0.02154012649719204\nSEED: 6, FOLD: 2, EPOCH: 23,train_loss: 0.005740598126239803, valid_loss: 0.02161011876804488\nSEED: 6, FOLD: 2, EPOCH: 24,train_loss: 0.005637631486475903, valid_loss: 0.021639447659254074\nFOLD: 3, EPOCH: 0,train_loss: 0.7317939884420754, valid_loss: 0.7051552755492074\nSEED: 6, FOLD: 3, EPOCH: 0,train_loss: 0.4683080800147592, valid_loss: 0.023894146510532923\nSEED: 6, FOLD: 3, EPOCH: 1,train_loss: 0.02175093573126672, valid_loss: 0.02122299186885357\nSEED: 6, FOLD: 3, EPOCH: 2,train_loss: 0.020688317729619102, valid_loss: 0.0202971734638725\nSEED: 6, FOLD: 3, EPOCH: 3,train_loss: 0.019423609343019947, valid_loss: 0.019103874133101533\nSEED: 6, FOLD: 3, EPOCH: 4,train_loss: 0.01844771931865725, valid_loss: 0.018527974667293685\nSEED: 6, FOLD: 3, EPOCH: 5,train_loss: 0.018026025344928105, valid_loss: 0.018432959036103317\nSEED: 6, FOLD: 3, EPOCH: 6,train_loss: 0.01763022465604371, valid_loss: 0.018133588560989924\nSEED: 6, FOLD: 3, EPOCH: 7,train_loss: 0.01739094824111764, valid_loss: 0.018381671740540437\nSEED: 6, FOLD: 3, EPOCH: 8,train_loss: 0.0170512189278784, valid_loss: 0.01875117870845965\nSEED: 6, FOLD: 3, EPOCH: 9,train_loss: 0.016974980888915234, valid_loss: 0.017999247993741717\nSEED: 6, FOLD: 3, EPOCH: 10,train_loss: 0.01679032322937164, valid_loss: 0.01807797034936292\nSEED: 6, FOLD: 3, EPOCH: 11,train_loss: 0.01657845510466807, valid_loss: 0.020828742454094547\nSEED: 6, FOLD: 3, EPOCH: 12,train_loss: 0.016273600245029596, valid_loss: 0.018529968416052204\nSEED: 6, FOLD: 3, EPOCH: 13,train_loss: 0.015866277320985344, valid_loss: 0.018536707998386453\nSEED: 6, FOLD: 3, EPOCH: 14,train_loss: 0.015407370632865292, valid_loss: 0.018491137214004992\nSEED: 6, FOLD: 3, EPOCH: 15,train_loss: 0.014785992136845985, valid_loss: 0.018824621263359275\nSEED: 6, FOLD: 3, EPOCH: 16,train_loss: 0.013873206930693941, valid_loss: 0.019277567602694036\nSEED: 6, FOLD: 3, EPOCH: 17,train_loss: 0.012700134058199499, valid_loss: 0.01949738793607269\nSEED: 6, FOLD: 3, EPOCH: 18,train_loss: 0.011224153120934532, valid_loss: 0.01986491046845913\nSEED: 6, FOLD: 3, EPOCH: 19,train_loss: 0.00962137179179252, valid_loss: 0.02061265329165118\nSEED: 6, FOLD: 3, EPOCH: 20,train_loss: 0.008147844045922377, valid_loss: 0.020893670591924873\nSEED: 6, FOLD: 3, EPOCH: 21,train_loss: 0.007117373389664335, valid_loss: 0.02097864600696734\nSEED: 6, FOLD: 3, EPOCH: 22,train_loss: 0.006432695631477712, valid_loss: 0.021179111514772687\nSEED: 6, FOLD: 3, EPOCH: 23,train_loss: 0.0060906674361963205, valid_loss: 0.021288999782076903\nSEED: 6, FOLD: 3, EPOCH: 24,train_loss: 0.005962854585326884, valid_loss: 0.021289083042315075\nFOLD: 4, EPOCH: 0,train_loss: 0.7319533570089202, valid_loss: 0.7072260747937595\nSEED: 6, FOLD: 4, EPOCH: 0,train_loss: 0.4693480843705112, valid_loss: 0.02431828123243416\nSEED: 6, FOLD: 4, EPOCH: 1,train_loss: 0.021602715379086094, valid_loss: 0.020333225126652157\nSEED: 6, FOLD: 4, EPOCH: 2,train_loss: 0.020032855209665024, valid_loss: 0.018665130633641693\nSEED: 6, FOLD: 4, EPOCH: 3,train_loss: 0.018787189845697605, valid_loss: 0.01822611182818518\nSEED: 6, FOLD: 4, EPOCH: 4,train_loss: 0.018046164662455736, valid_loss: 0.017935442765626836\nSEED: 6, FOLD: 4, EPOCH: 5,train_loss: 0.017571004134589348, valid_loss: 0.06520132693078588\nSEED: 6, FOLD: 4, EPOCH: 6,train_loss: 0.01721115831447684, valid_loss: 0.0178772789590499\nSEED: 6, FOLD: 4, EPOCH: 7,train_loss: 0.01687620964873096, valid_loss: 0.04427093692014322\nSEED: 6, FOLD: 4, EPOCH: 8,train_loss: 0.016738018554135942, valid_loss: 0.017938490190050182\nSEED: 6, FOLD: 4, EPOCH: 9,train_loss: 0.016605857361539984, valid_loss: 0.01798585443483556\nSEED: 6, FOLD: 4, EPOCH: 10,train_loss: 0.01644258832127072, valid_loss: 0.13846968774519422\nSEED: 6, FOLD: 4, EPOCH: 11,train_loss: 0.016227800129116444, valid_loss: 0.06524656461003948\nSEED: 6, FOLD: 4, EPOCH: 12,train_loss: 0.015939186846810408, valid_loss: 0.01849186494398643\nSEED: 6, FOLD: 4, EPOCH: 13,train_loss: 0.01552374841834324, valid_loss: 0.018357151352307376\nSEED: 6, FOLD: 4, EPOCH: 14,train_loss: 0.014915956737662571, valid_loss: 0.018808028414188063\nSEED: 6, FOLD: 4, EPOCH: 15,train_loss: 0.014176162465920916, valid_loss: 0.018892564783420634\nSEED: 6, FOLD: 4, EPOCH: 16,train_loss: 0.01319336143416771, valid_loss: 0.0194040513049592\nSEED: 6, FOLD: 4, EPOCH: 17,train_loss: 0.011912278358595095, valid_loss: 0.026426634312990832\nSEED: 6, FOLD: 4, EPOCH: 18,train_loss: 0.010411129508545433, valid_loss: 0.020435787737369537\nSEED: 6, FOLD: 4, EPOCH: 19,train_loss: 0.008820853320935714, valid_loss: 0.02067380557384561\nSEED: 6, FOLD: 4, EPOCH: 20,train_loss: 0.007398846842672514, valid_loss: 0.020681155297686073\nSEED: 6, FOLD: 4, EPOCH: 21,train_loss: 0.006440681186032252, valid_loss: 0.02219378241502187\nSEED: 6, FOLD: 4, EPOCH: 22,train_loss: 0.005888562841826807, valid_loss: 0.020928922766710028\nSEED: 6, FOLD: 4, EPOCH: 23,train_loss: 0.005611925146313033, valid_loss: 0.021178069688818035\nSEED: 6, FOLD: 4, EPOCH: 24,train_loss: 0.005527574798443179, valid_loss: 0.021090771783800685\nFOLD: 0, EPOCH: 0,train_loss: 0.7337006758088651, valid_loss: 0.7011374286242894\nSEED: 7, FOLD: 0, EPOCH: 0,train_loss: 0.4707180483239716, valid_loss: 0.02339033005493028\nSEED: 7, FOLD: 0, EPOCH: 1,train_loss: 0.021635148147849934, valid_loss: 0.02129003740847111\nSEED: 7, FOLD: 0, EPOCH: 2,train_loss: 0.020193981600628384, valid_loss: 0.018894486874341965\nSEED: 7, FOLD: 0, EPOCH: 3,train_loss: 0.018921010277193527, valid_loss: 0.01831011955759355\nSEED: 7, FOLD: 0, EPOCH: 4,train_loss: 0.018102715109083532, valid_loss: 0.018093429638871124\nSEED: 7, FOLD: 0, EPOCH: 5,train_loss: 0.017658051467784073, valid_loss: 0.017807011492550373\nSEED: 7, FOLD: 0, EPOCH: 6,train_loss: 0.01728996561597223, valid_loss: 0.017649641446769237\nSEED: 7, FOLD: 0, EPOCH: 7,train_loss: 0.01705009242573726, valid_loss: 0.017538123258522578\nSEED: 7, FOLD: 0, EPOCH: 8,train_loss: 0.016734428238123655, valid_loss: 0.026059992504971367\nSEED: 7, FOLD: 0, EPOCH: 9,train_loss: 0.01661613446565858, valid_loss: 0.018222552644354958\nSEED: 7, FOLD: 0, EPOCH: 10,train_loss: 0.016377942380157932, valid_loss: 0.018121333846024105\nSEED: 7, FOLD: 0, EPOCH: 11,train_loss: 0.016146259983002707, valid_loss: 0.01789982747286558\nSEED: 7, FOLD: 0, EPOCH: 12,train_loss: 0.015834219247588644, valid_loss: 0.017795483129365103\nSEED: 7, FOLD: 0, EPOCH: 13,train_loss: 0.015445753095158632, valid_loss: 0.018411369009741715\nSEED: 7, FOLD: 0, EPOCH: 14,train_loss: 0.015042471557693638, valid_loss: 0.018916316836008005\nSEED: 7, FOLD: 0, EPOCH: 15,train_loss: 0.014106530534184498, valid_loss: 0.01888707514320101\nSEED: 7, FOLD: 0, EPOCH: 16,train_loss: 0.013106509692211082, valid_loss: 0.01974968822406871\nSEED: 7, FOLD: 0, EPOCH: 17,train_loss: 0.011917857122540043, valid_loss: 0.028746110812893935\nSEED: 7, FOLD: 0, EPOCH: 18,train_loss: 0.010441139434882696, valid_loss: 0.02030593454837799\nSEED: 7, FOLD: 0, EPOCH: 19,train_loss: 0.008964614507377795, valid_loss: 0.020727874365236078\nSEED: 7, FOLD: 0, EPOCH: 20,train_loss: 0.007620255294107441, valid_loss: 0.020856140820043428\nSEED: 7, FOLD: 0, EPOCH: 21,train_loss: 0.006679115142079367, valid_loss: 0.02093849876629455\nSEED: 7, FOLD: 0, EPOCH: 22,train_loss: 0.0060742590306461725, valid_loss: 0.020971546029405933\nSEED: 7, FOLD: 0, EPOCH: 23,train_loss: 0.005791972624137998, valid_loss: 0.020989740613315787\nSEED: 7, FOLD: 0, EPOCH: 24,train_loss: 0.005678386795267031, valid_loss: 0.020999683067202568\nFOLD: 1, EPOCH: 0,train_loss: 0.7341036140054896, valid_loss: 0.7045296651976449\nSEED: 7, FOLD: 1, EPOCH: 0,train_loss: 0.46897763945162296, valid_loss: 0.02301838845014572\nSEED: 7, FOLD: 1, EPOCH: 1,train_loss: 0.0215387890736262, valid_loss: 0.021160980154361044\nSEED: 7, FOLD: 1, EPOCH: 2,train_loss: 0.020197086576102436, valid_loss: 0.01941914074122906\nSEED: 7, FOLD: 1, EPOCH: 3,train_loss: 0.018870418688849262, valid_loss: 0.42858312811170307\nSEED: 7, FOLD: 1, EPOCH: 4,train_loss: 0.018157815628185654, valid_loss: 0.018178373495382923\nSEED: 7, FOLD: 1, EPOCH: 5,train_loss: 0.017658779890262995, valid_loss: 0.06837576340351786\nSEED: 7, FOLD: 1, EPOCH: 6,train_loss: 0.017302590327850288, valid_loss: 0.27908250875771046\nSEED: 7, FOLD: 1, EPOCH: 7,train_loss: 0.016996953892858997, valid_loss: 1.7236911978040423\nSEED: 7, FOLD: 1, EPOCH: 8,train_loss: 0.016757958231196888, valid_loss: 0.01835270438875471\nSEED: 7, FOLD: 1, EPOCH: 9,train_loss: 0.016551946735252506, valid_loss: 0.019230656804783003\nSEED: 7, FOLD: 1, EPOCH: 10,train_loss: 0.016290113019446533, valid_loss: 0.03939223209662097\nSEED: 7, FOLD: 1, EPOCH: 11,train_loss: 0.0160015054937938, valid_loss: 0.01882015402827944\nSEED: 7, FOLD: 1, EPOCH: 12,train_loss: 0.015623265135007492, valid_loss: 0.018875702044793538\nSEED: 7, FOLD: 1, EPOCH: 13,train_loss: 0.01506245637015588, valid_loss: 0.019753743069512504\nSEED: 7, FOLD: 1, EPOCH: 14,train_loss: 0.014303497916114504, valid_loss: 0.0562920339937721\nSEED: 7, FOLD: 1, EPOCH: 15,train_loss: 0.013417296077840138, valid_loss: 0.020189644076994487\nSEED: 7, FOLD: 1, EPOCH: 16,train_loss: 0.01226492600677454, valid_loss: 0.02058866157063416\nSEED: 7, FOLD: 1, EPOCH: 17,train_loss: 0.01088362905210343, valid_loss: 0.021256957788552557\nSEED: 7, FOLD: 1, EPOCH: 18,train_loss: 0.009531995342315538, valid_loss: 0.02153916188648769\nSEED: 7, FOLD: 1, EPOCH: 19,train_loss: 0.008151563481711175, valid_loss: 0.021948126756719182\nSEED: 7, FOLD: 1, EPOCH: 20,train_loss: 0.007019044622185005, valid_loss: 0.022176983367119516\nSEED: 7, FOLD: 1, EPOCH: 21,train_loss: 0.006266643380935209, valid_loss: 0.021890898421406745\nSEED: 7, FOLD: 1, EPOCH: 22,train_loss: 0.0058036502889371, valid_loss: 0.021977321484259196\nSEED: 7, FOLD: 1, EPOCH: 23,train_loss: 0.005559918005019426, valid_loss: 0.021922722086310388\nSEED: 7, FOLD: 1, EPOCH: 24,train_loss: 0.005476102607486689, valid_loss: 0.022000546806624957\nFOLD: 2, EPOCH: 0,train_loss: 0.7337914955788765, valid_loss: 0.7040419902120317\nSEED: 7, FOLD: 2, EPOCH: 0,train_loss: 0.4689985969360324, valid_loss: 0.023560078495315145\nSEED: 7, FOLD: 2, EPOCH: 1,train_loss: 0.021574514364634735, valid_loss: 0.02034048315669809\nSEED: 7, FOLD: 2, EPOCH: 2,train_loss: 0.02039256752671107, valid_loss: 0.032037453353405\nSEED: 7, FOLD: 2, EPOCH: 3,train_loss: 0.019084073886599228, valid_loss: 0.01831898566867624\nSEED: 7, FOLD: 2, EPOCH: 4,train_loss: 0.018512273902424436, valid_loss: 0.0178861139608281\nSEED: 7, FOLD: 2, EPOCH: 5,train_loss: 0.01798800980348302, valid_loss: 0.017897600600762027\nSEED: 7, FOLD: 2, EPOCH: 6,train_loss: 0.017594963278405477, valid_loss: 0.017887648940086365\nSEED: 7, FOLD: 2, EPOCH: 7,train_loss: 0.017348021835736607, valid_loss: 0.01802259978971311\nSEED: 7, FOLD: 2, EPOCH: 8,train_loss: 0.017122537275587303, valid_loss: 0.018087363136666163\nSEED: 7, FOLD: 2, EPOCH: 9,train_loss: 0.016997824281292116, valid_loss: 0.01787088593201978\nSEED: 7, FOLD: 2, EPOCH: 10,train_loss: 0.016758538904073444, valid_loss: 0.018076670143221105\nSEED: 7, FOLD: 2, EPOCH: 11,train_loss: 0.016603372241977766, valid_loss: 0.017972267286053726\nSEED: 7, FOLD: 2, EPOCH: 12,train_loss: 0.016200764820087647, valid_loss: 0.018030867113598754\nSEED: 7, FOLD: 2, EPOCH: 13,train_loss: 0.015879607961877533, valid_loss: 0.01835903802088329\nSEED: 7, FOLD: 2, EPOCH: 14,train_loss: 0.015376913685189642, valid_loss: 0.018956780433654785\nSEED: 7, FOLD: 2, EPOCH: 15,train_loss: 0.01467038776077654, valid_loss: 0.0185434185766748\nSEED: 7, FOLD: 2, EPOCH: 16,train_loss: 0.013682457247236069, valid_loss: 0.01909744947084359\nSEED: 7, FOLD: 2, EPOCH: 17,train_loss: 0.01258834118725381, valid_loss: 0.02027033700474671\nSEED: 7, FOLD: 2, EPOCH: 18,train_loss: 0.011173530542494162, valid_loss: 0.020113856505070415\nSEED: 7, FOLD: 2, EPOCH: 19,train_loss: 0.009515917293079521, valid_loss: 0.020602853915521076\nSEED: 7, FOLD: 2, EPOCH: 20,train_loss: 0.008108499480168457, valid_loss: 0.020680628504071916\nSEED: 7, FOLD: 2, EPOCH: 21,train_loss: 0.007075690360658843, valid_loss: 0.020610698631831577\nSEED: 7, FOLD: 2, EPOCH: 22,train_loss: 0.006409292976520415, valid_loss: 0.020832527907831327\nSEED: 7, FOLD: 2, EPOCH: 23,train_loss: 0.006080081716746739, valid_loss: 0.020827726806913104\nSEED: 7, FOLD: 2, EPOCH: 24,train_loss: 0.005958399813001354, valid_loss: 0.020769333520105907\nFOLD: 3, EPOCH: 0,train_loss: 0.7338573588942089, valid_loss: 0.701973603452955\nSEED: 7, FOLD: 3, EPOCH: 0,train_loss: 0.470193067116894, valid_loss: 0.02442616666001933\nSEED: 7, FOLD: 3, EPOCH: 1,train_loss: 0.021560026060817014, valid_loss: 0.02090989761054516\nSEED: 7, FOLD: 3, EPOCH: 2,train_loss: 0.020074764443357495, valid_loss: 0.019344396410243853\nSEED: 7, FOLD: 3, EPOCH: 3,train_loss: 0.018801651895046234, valid_loss: 0.3037201961768525\nSEED: 7, FOLD: 3, EPOCH: 4,train_loss: 0.018020474793810914, valid_loss: 0.01850510181060859\nSEED: 7, FOLD: 3, EPOCH: 5,train_loss: 0.01757936955286856, valid_loss: 0.018366890693349496\nSEED: 7, FOLD: 3, EPOCH: 6,train_loss: 0.017202143910864408, valid_loss: 0.018382235722882407\nSEED: 7, FOLD: 3, EPOCH: 7,train_loss: 0.016977218333223874, valid_loss: 0.018479365270052638\nSEED: 7, FOLD: 3, EPOCH: 8,train_loss: 0.01680547283133016, valid_loss: 0.01853265416409288\nSEED: 7, FOLD: 3, EPOCH: 9,train_loss: 0.0165634153505964, valid_loss: 0.020900289873991694\nSEED: 7, FOLD: 3, EPOCH: 10,train_loss: 0.016359825237878482, valid_loss: 0.018517398408481052\nSEED: 7, FOLD: 3, EPOCH: 11,train_loss: 0.016082643476879075, valid_loss: 0.018639907480350562\nSEED: 7, FOLD: 3, EPOCH: 12,train_loss: 0.015893207543468388, valid_loss: 0.018883604955460345\nSEED: 7, FOLD: 3, EPOCH: 13,train_loss: 0.015450698119608591, valid_loss: 0.019019157492688725\nSEED: 7, FOLD: 3, EPOCH: 14,train_loss: 0.014898435865277357, valid_loss: 0.019536012783646584\nSEED: 7, FOLD: 3, EPOCH: 15,train_loss: 0.014080465805247753, valid_loss: 0.01974478236266545\nSEED: 7, FOLD: 3, EPOCH: 16,train_loss: 0.012941018943368953, valid_loss: 0.020094170634235655\nSEED: 7, FOLD: 3, EPOCH: 17,train_loss: 0.011653181886042122, valid_loss: 0.020639741527182714\nSEED: 7, FOLD: 3, EPOCH: 18,train_loss: 0.010235549718902929, valid_loss: 0.020725143008998463\nSEED: 7, FOLD: 3, EPOCH: 19,train_loss: 0.008663524778383056, valid_loss: 0.021002527698874472\nSEED: 7, FOLD: 3, EPOCH: 20,train_loss: 0.007321883659184414, valid_loss: 0.021300058013626506\nSEED: 7, FOLD: 3, EPOCH: 21,train_loss: 0.006410903932975374, valid_loss: 0.02145302136029516\nSEED: 7, FOLD: 3, EPOCH: 22,train_loss: 0.005874100518514858, valid_loss: 0.021609586104750632\nSEED: 7, FOLD: 3, EPOCH: 23,train_loss: 0.005630983148504348, valid_loss: 0.021613215282559394\nSEED: 7, FOLD: 3, EPOCH: 24,train_loss: 0.0055417039730742464, valid_loss: 0.021625515339629992\nFOLD: 4, EPOCH: 0,train_loss: 0.734135155228601, valid_loss: 0.7041685376848493\nSEED: 7, FOLD: 4, EPOCH: 0,train_loss: 0.46818428933350503, valid_loss: 0.024481414152043208\nSEED: 7, FOLD: 4, EPOCH: 1,train_loss: 0.021622375612133655, valid_loss: 0.021242205000349453\nSEED: 7, FOLD: 4, EPOCH: 2,train_loss: 0.02009788876318413, valid_loss: 0.02946147107120071\nSEED: 7, FOLD: 4, EPOCH: 3,train_loss: 0.01885761455565259, valid_loss: 0.01825092998998506\nSEED: 7, FOLD: 4, EPOCH: 4,train_loss: 0.018098138232270012, valid_loss: 0.018118777525212085\nSEED: 7, FOLD: 4, EPOCH: 5,train_loss: 0.017604828636715378, valid_loss: 0.018062612786889077\nSEED: 7, FOLD: 4, EPOCH: 6,train_loss: 0.01733550919300836, valid_loss: 0.017990929633378984\nSEED: 7, FOLD: 4, EPOCH: 7,train_loss: 0.017070088468060112, valid_loss: 0.018123280789170946\nSEED: 7, FOLD: 4, EPOCH: 8,train_loss: 0.016906869145569162, valid_loss: 0.01824248725814479\nSEED: 7, FOLD: 4, EPOCH: 9,train_loss: 0.016804652126586956, valid_loss: 0.018103283271193503\nSEED: 7, FOLD: 4, EPOCH: 10,train_loss: 0.016665279743788036, valid_loss: 0.018283094838261606\nSEED: 7, FOLD: 4, EPOCH: 11,train_loss: 0.016451649853716725, valid_loss: 0.018619193801922458\nSEED: 7, FOLD: 4, EPOCH: 12,train_loss: 0.016274472786302584, valid_loss: 0.01843298835945981\nSEED: 7, FOLD: 4, EPOCH: 13,train_loss: 0.015952923402622127, valid_loss: 0.018607563711702822\nSEED: 7, FOLD: 4, EPOCH: 14,train_loss: 0.015535637000710636, valid_loss: 0.018478042632341384\nSEED: 7, FOLD: 4, EPOCH: 15,train_loss: 0.014914771393481373, valid_loss: 0.019250128657690116\nSEED: 7, FOLD: 4, EPOCH: 16,train_loss: 0.014241024480619724, valid_loss: 0.019436087991510118\nSEED: 7, FOLD: 4, EPOCH: 17,train_loss: 0.012995393764551567, valid_loss: 0.024298852602285998\nSEED: 7, FOLD: 4, EPOCH: 18,train_loss: 0.01151817598366651, valid_loss: 0.020221743785909244\nSEED: 7, FOLD: 4, EPOCH: 19,train_loss: 0.009957525008560522, valid_loss: 0.021045853942632677\nSEED: 7, FOLD: 4, EPOCH: 20,train_loss: 0.008388241827217997, valid_loss: 0.020834049795355115\nSEED: 7, FOLD: 4, EPOCH: 21,train_loss: 0.00718035476376721, valid_loss: 0.021206871340317384\nSEED: 7, FOLD: 4, EPOCH: 22,train_loss: 0.006421545942219487, valid_loss: 0.021289380320480892\nSEED: 7, FOLD: 4, EPOCH: 23,train_loss: 0.006056887759030729, valid_loss: 0.02123273318367345\nSEED: 7, FOLD: 4, EPOCH: 24,train_loss: 0.005930098212337581, valid_loss: 0.02123358872319971\nFOLD: 0, EPOCH: 0,train_loss: 0.7306096327565882, valid_loss: 0.6923474754605975\nSEED: 8, FOLD: 0, EPOCH: 0,train_loss: 0.4700183246121572, valid_loss: 0.023801594280770846\nSEED: 8, FOLD: 0, EPOCH: 1,train_loss: 0.021675159135004028, valid_loss: 0.057212640345096585\nSEED: 8, FOLD: 0, EPOCH: 2,train_loss: 0.020182760364382806, valid_loss: 0.01914679887039321\nSEED: 8, FOLD: 0, EPOCH: 3,train_loss: 0.018763569734283607, valid_loss: 0.023656717368534634\nSEED: 8, FOLD: 0, EPOCH: 4,train_loss: 0.018035617276319187, valid_loss: 0.018404515486742767\nSEED: 8, FOLD: 0, EPOCH: 5,train_loss: 0.01759875966847813, valid_loss: 0.01844058952161244\nSEED: 8, FOLD: 0, EPOCH: 6,train_loss: 0.017211641123803863, valid_loss: 0.018240269220301083\nSEED: 8, FOLD: 0, EPOCH: 7,train_loss: 0.016860001312609573, valid_loss: 0.018479362316429614\nSEED: 8, FOLD: 0, EPOCH: 8,train_loss: 0.016611615848475998, valid_loss: 0.018215169730995382\nSEED: 8, FOLD: 0, EPOCH: 9,train_loss: 0.01635376851407498, valid_loss: 0.01815471885991948\nSEED: 8, FOLD: 0, EPOCH: 10,train_loss: 0.016130929010627914, valid_loss: 0.01828052295105798\nSEED: 8, FOLD: 0, EPOCH: 11,train_loss: 0.01574982912109716, valid_loss: 0.018608440033027102\nSEED: 8, FOLD: 0, EPOCH: 12,train_loss: 0.015368470038375714, valid_loss: 0.019575277396610805\nSEED: 8, FOLD: 0, EPOCH: 13,train_loss: 0.014855201927142857, valid_loss: 0.01912369786628655\nSEED: 8, FOLD: 0, EPOCH: 14,train_loss: 0.014194343782906984, valid_loss: 0.019190174607293945\nSEED: 8, FOLD: 0, EPOCH: 15,train_loss: 0.013316173201603611, valid_loss: 0.01996762262923377\nSEED: 8, FOLD: 0, EPOCH: 16,train_loss: 0.012202552601314373, valid_loss: 0.020286432174699647\nSEED: 8, FOLD: 0, EPOCH: 17,train_loss: 0.01094385707601361, valid_loss: 0.02109669399048601\nSEED: 8, FOLD: 0, EPOCH: 18,train_loss: 0.009499923638781927, valid_loss: 0.021766809693404606\nSEED: 8, FOLD: 0, EPOCH: 19,train_loss: 0.00814606329548533, valid_loss: 0.021810507348605564\nSEED: 8, FOLD: 0, EPOCH: 20,train_loss: 0.0070044272749202096, valid_loss: 0.021769955434969495\nSEED: 8, FOLD: 0, EPOCH: 21,train_loss: 0.006251560663464513, valid_loss: 0.021600756315248354\nSEED: 8, FOLD: 0, EPOCH: 22,train_loss: 0.005790368103197891, valid_loss: 0.021770424768328668\nSEED: 8, FOLD: 0, EPOCH: 23,train_loss: 0.005569709226978521, valid_loss: 0.02176419475248882\nSEED: 8, FOLD: 0, EPOCH: 24,train_loss: 0.00548604510071939, valid_loss: 0.021830519288778306\nFOLD: 1, EPOCH: 0,train_loss: 0.7310804547607035, valid_loss: 0.6914794870785305\nSEED: 8, FOLD: 1, EPOCH: 0,train_loss: 0.46882100636814383, valid_loss: 0.023590992125017304\nSEED: 8, FOLD: 1, EPOCH: 1,train_loss: 0.021541630916729355, valid_loss: 181.78523769181754\nSEED: 8, FOLD: 1, EPOCH: 2,train_loss: 0.020250112533677315, valid_loss: 0.018975408508309297\nSEED: 8, FOLD: 1, EPOCH: 3,train_loss: 0.018967023038345833, valid_loss: 0.01848949193954468\nSEED: 8, FOLD: 1, EPOCH: 4,train_loss: 0.018224836597084137, valid_loss: 0.018431089286293303\nSEED: 8, FOLD: 1, EPOCH: 5,train_loss: 0.017688299043347008, valid_loss: 0.10472598341958864\nSEED: 8, FOLD: 1, EPOCH: 6,train_loss: 0.017239016258036314, valid_loss: 0.018868633093578474\nSEED: 8, FOLD: 1, EPOCH: 7,train_loss: 0.01695998170264605, valid_loss: 0.018935303310198444\nSEED: 8, FOLD: 1, EPOCH: 8,train_loss: 0.01658298347847185, valid_loss: 0.01861560602805444\nSEED: 8, FOLD: 1, EPOCH: 9,train_loss: 0.016228030854161236, valid_loss: 0.01855399307927915\nSEED: 8, FOLD: 1, EPOCH: 10,train_loss: 0.015950406233415655, valid_loss: 0.019134574569761753\nSEED: 8, FOLD: 1, EPOCH: 11,train_loss: 0.015599013353441504, valid_loss: 0.019176622693027768\nSEED: 8, FOLD: 1, EPOCH: 12,train_loss: 0.015173679818331764, valid_loss: 0.020046247541904448\nSEED: 8, FOLD: 1, EPOCH: 13,train_loss: 0.014658044645751732, valid_loss: 0.02023345200078828\nSEED: 8, FOLD: 1, EPOCH: 14,train_loss: 0.013948490748694841, valid_loss: 0.020316093973815442\nSEED: 8, FOLD: 1, EPOCH: 15,train_loss: 0.013040991695732742, valid_loss: 0.020861271609153065\nSEED: 8, FOLD: 1, EPOCH: 16,train_loss: 0.012126118646583695, valid_loss: 0.021462043055466243\nSEED: 8, FOLD: 1, EPOCH: 17,train_loss: 0.011025732578844696, valid_loss: 0.022541650065353937\nSEED: 8, FOLD: 1, EPOCH: 18,train_loss: 0.009571469510379045, valid_loss: 0.022583184178386416\nSEED: 8, FOLD: 1, EPOCH: 19,train_loss: 0.008346002829004672, valid_loss: 0.022803336807659693\nSEED: 8, FOLD: 1, EPOCH: 20,train_loss: 0.007185536912520943, valid_loss: 0.02251876736325877\nSEED: 8, FOLD: 1, EPOCH: 21,train_loss: 0.006405529738201395, valid_loss: 0.02261170047734465\nSEED: 8, FOLD: 1, EPOCH: 22,train_loss: 0.0059456132433336716, valid_loss: 0.022574637351291522\nSEED: 8, FOLD: 1, EPOCH: 23,train_loss: 0.005733703634283249, valid_loss: 0.02253499712262835\nSEED: 8, FOLD: 1, EPOCH: 24,train_loss: 0.005636501274463059, valid_loss: 0.02248940835041659\nFOLD: 2, EPOCH: 0,train_loss: 0.730750533549682, valid_loss: 0.6923060468264989\nSEED: 8, FOLD: 2, EPOCH: 0,train_loss: 0.4696597773581743, valid_loss: 0.02366598727447646\nSEED: 8, FOLD: 2, EPOCH: 1,train_loss: 0.021670325794189736, valid_loss: 0.020581410612378802\nSEED: 8, FOLD: 2, EPOCH: 2,train_loss: 0.020378257755352104, valid_loss: 0.019025650673678944\nSEED: 8, FOLD: 2, EPOCH: 3,train_loss: 0.01901459668263577, valid_loss: 0.01833349099116666\nSEED: 8, FOLD: 2, EPOCH: 4,train_loss: 0.018225456412503685, valid_loss: 0.018615846947899885\nSEED: 8, FOLD: 2, EPOCH: 5,train_loss: 0.017729044298007004, valid_loss: 0.018550490029156208\nSEED: 8, FOLD: 2, EPOCH: 6,train_loss: 0.01733103980296764, valid_loss: 0.01831056590058974\nSEED: 8, FOLD: 2, EPOCH: 7,train_loss: 0.016978583541577278, valid_loss: 0.05525681637227535\nSEED: 8, FOLD: 2, EPOCH: 8,train_loss: 0.01682992894337445, valid_loss: 0.01845882170434509\nSEED: 8, FOLD: 2, EPOCH: 9,train_loss: 0.01663006572862682, valid_loss: 0.018301613043461527\nSEED: 8, FOLD: 2, EPOCH: 10,train_loss: 0.01644201995804906, valid_loss: 0.018164383247494698\nSEED: 8, FOLD: 2, EPOCH: 11,train_loss: 0.0161306276930955, valid_loss: 0.018468969315290452\nSEED: 8, FOLD: 2, EPOCH: 12,train_loss: 0.01583642194695447, valid_loss: 0.018394593096205166\nSEED: 8, FOLD: 2, EPOCH: 13,train_loss: 0.01548132423878364, valid_loss: 0.018910140597394536\nSEED: 8, FOLD: 2, EPOCH: 14,train_loss: 0.01484028133901133, valid_loss: 0.018870619551411696\nSEED: 8, FOLD: 2, EPOCH: 15,train_loss: 0.014020340496917133, valid_loss: 0.019179527780839374\nSEED: 8, FOLD: 2, EPOCH: 16,train_loss: 0.012808544372302898, valid_loss: 0.02002249506435224\nSEED: 8, FOLD: 2, EPOCH: 17,train_loss: 0.011475202681469744, valid_loss: 0.020344798054013933\nSEED: 8, FOLD: 2, EPOCH: 18,train_loss: 0.010034638787687256, valid_loss: 0.020395485205309732\nSEED: 8, FOLD: 2, EPOCH: 19,train_loss: 0.008463149249175753, valid_loss: 0.020917828460889205\nSEED: 8, FOLD: 2, EPOCH: 20,train_loss: 0.007196548911135482, valid_loss: 0.021187736626182285\nSEED: 8, FOLD: 2, EPOCH: 21,train_loss: 0.006354483104297432, valid_loss: 0.02255842217377254\nSEED: 8, FOLD: 2, EPOCH: 22,train_loss: 0.005869515790212629, valid_loss: 0.021261151454278402\nSEED: 8, FOLD: 2, EPOCH: 23,train_loss: 0.005634479720712356, valid_loss: 0.021499428365911757\nSEED: 8, FOLD: 2, EPOCH: 24,train_loss: 0.005550531140677091, valid_loss: 0.025609265001756806\nFOLD: 3, EPOCH: 0,train_loss: 0.7309795125671055, valid_loss: 0.6903187547411237\nSEED: 8, FOLD: 3, EPOCH: 0,train_loss: 0.46896703313172294, valid_loss: 0.023352397925087382\nSEED: 8, FOLD: 3, EPOCH: 1,train_loss: 0.021911564795975235, valid_loss: 0.02105848980801446\nSEED: 8, FOLD: 3, EPOCH: 2,train_loss: 0.020346184598578922, valid_loss: 0.01933052558451891\nSEED: 8, FOLD: 3, EPOCH: 3,train_loss: 0.018968497720155596, valid_loss: 0.018470052549881596\nSEED: 8, FOLD: 3, EPOCH: 4,train_loss: 0.01824308154375657, valid_loss: 0.018060775074575628\nSEED: 8, FOLD: 3, EPOCH: 5,train_loss: 0.01778800657990834, valid_loss: 0.01783548974032913\nSEED: 8, FOLD: 3, EPOCH: 6,train_loss: 0.01736042797025563, valid_loss: 0.017786810281021255\nSEED: 8, FOLD: 3, EPOCH: 7,train_loss: 0.01709267169075168, valid_loss: 0.575573092832097\nSEED: 8, FOLD: 3, EPOCH: 8,train_loss: 0.0168788961701743, valid_loss: 0.0419460190726178\nSEED: 8, FOLD: 3, EPOCH: 9,train_loss: 0.016831915535410677, valid_loss: 0.023463400506547518\nSEED: 8, FOLD: 3, EPOCH: 10,train_loss: 0.016569127706621868, valid_loss: 0.017823132340397153\nSEED: 8, FOLD: 3, EPOCH: 11,train_loss: 0.016484730445064495, valid_loss: 0.017788484186998434\nSEED: 8, FOLD: 3, EPOCH: 12,train_loss: 0.016336502750282703, valid_loss: 0.018301723684583392\nSEED: 8, FOLD: 3, EPOCH: 13,train_loss: 0.01592941673985426, valid_loss: 0.017977413535118104\nSEED: 8, FOLD: 3, EPOCH: 14,train_loss: 0.015407589999823898, valid_loss: 0.018247967266610692\nSEED: 8, FOLD: 3, EPOCH: 15,train_loss: 0.014673063936440842, valid_loss: 0.019176464527845383\nSEED: 8, FOLD: 3, EPOCH: 16,train_loss: 0.013750501726146626, valid_loss: 0.01919604486652783\nSEED: 8, FOLD: 3, EPOCH: 17,train_loss: 0.01252649456559532, valid_loss: 0.019808670399444443\nSEED: 8, FOLD: 3, EPOCH: 18,train_loss: 0.010993989960600933, valid_loss: 0.020574358238705567\nSEED: 8, FOLD: 3, EPOCH: 19,train_loss: 0.009327472099845392, valid_loss: 0.02068169760916914\nSEED: 8, FOLD: 3, EPOCH: 20,train_loss: 0.00778153851169391, valid_loss: 0.02089460516082389\nSEED: 8, FOLD: 3, EPOCH: 21,train_loss: 0.0067356283256811075, valid_loss: 0.021031451278499196\nSEED: 8, FOLD: 3, EPOCH: 22,train_loss: 0.006119136438718525, valid_loss: 0.021596804474081313\nSEED: 8, FOLD: 3, EPOCH: 23,train_loss: 0.005823987968050052, valid_loss: 0.02135032516505037\nSEED: 8, FOLD: 3, EPOCH: 24,train_loss: 0.0057143589339988385, valid_loss: 0.021658358084303993\nFOLD: 4, EPOCH: 0,train_loss: 0.7312814087971397, valid_loss: 0.6904568484851292\nSEED: 8, FOLD: 4, EPOCH: 0,train_loss: 0.4698245622271645, valid_loss: 0.024060887630496706\nSEED: 8, FOLD: 4, EPOCH: 1,train_loss: 0.021748772552371887, valid_loss: 0.022520185368401665\nSEED: 8, FOLD: 4, EPOCH: 2,train_loss: 0.020468469182758228, valid_loss: 0.019353211032492774\nSEED: 8, FOLD: 4, EPOCH: 3,train_loss: 0.01915291708934566, valid_loss: 0.01938669764037643\nSEED: 8, FOLD: 4, EPOCH: 4,train_loss: 0.01842749357034547, valid_loss: 0.018424982843654496\nSEED: 8, FOLD: 4, EPOCH: 5,train_loss: 0.017953957147572353, valid_loss: 0.018217420844095094\nSEED: 8, FOLD: 4, EPOCH: 6,train_loss: 0.017602300028438152, valid_loss: 0.017995222391826767\nSEED: 8, FOLD: 4, EPOCH: 7,train_loss: 0.017334590868457504, valid_loss: 0.01831604064043079\nSEED: 8, FOLD: 4, EPOCH: 8,train_loss: 0.01710959274213815, valid_loss: 0.018803761340677738\nSEED: 8, FOLD: 4, EPOCH: 9,train_loss: 0.01690498358853485, valid_loss: 0.018232336321047374\nSEED: 8, FOLD: 4, EPOCH: 10,train_loss: 0.01666554048711407, valid_loss: 0.018008070279444968\nSEED: 8, FOLD: 4, EPOCH: 11,train_loss: 0.0164947343274843, valid_loss: 0.01887465217815978\nSEED: 8, FOLD: 4, EPOCH: 12,train_loss: 0.01611559674737678, valid_loss: 0.01821961442806891\nSEED: 8, FOLD: 4, EPOCH: 13,train_loss: 0.015800259271771578, valid_loss: 0.01902243106492928\nSEED: 8, FOLD: 4, EPOCH: 14,train_loss: 0.015369437317755343, valid_loss: 0.041666000549282343\nSEED: 8, FOLD: 4, EPOCH: 15,train_loss: 0.014926030314055042, valid_loss: 0.018535755654530865\nSEED: 8, FOLD: 4, EPOCH: 16,train_loss: 0.013737947221143522, valid_loss: 0.019337147288024426\nSEED: 8, FOLD: 4, EPOCH: 17,train_loss: 0.012666066406645637, valid_loss: 0.019965597135680063\nSEED: 8, FOLD: 4, EPOCH: 18,train_loss: 0.011280430561822393, valid_loss: 0.020340703135090215\nSEED: 8, FOLD: 4, EPOCH: 19,train_loss: 0.009644797071814537, valid_loss: 0.020729640711631095\nSEED: 8, FOLD: 4, EPOCH: 20,train_loss: 0.008265261157024383, valid_loss: 0.02094964821423803\nSEED: 8, FOLD: 4, EPOCH: 21,train_loss: 0.007215962623772414, valid_loss: 0.021175804255264146\nSEED: 8, FOLD: 4, EPOCH: 22,train_loss: 0.006560904682492433, valid_loss: 0.021371740847826004\nSEED: 8, FOLD: 4, EPOCH: 23,train_loss: 0.006197489389771785, valid_loss: 0.021429688057729174\nSEED: 8, FOLD: 4, EPOCH: 24,train_loss: 0.006066255716849928, valid_loss: 0.021417633284415517\nFOLD: 0, EPOCH: 0,train_loss: 0.7298235323118127, valid_loss: 0.6953397239957537\nSEED: 9, FOLD: 0, EPOCH: 0,train_loss: 0.4696880573325831, valid_loss: 0.02369929983147553\nSEED: 9, FOLD: 0, EPOCH: 1,train_loss: 0.021841571760782295, valid_loss: 0.020574302545615604\nSEED: 9, FOLD: 0, EPOCH: 2,train_loss: 0.0200845529122845, valid_loss: 0.01851718079830919\nSEED: 9, FOLD: 0, EPOCH: 3,train_loss: 0.018672257297388885, valid_loss: 0.0177552105858922\nSEED: 9, FOLD: 0, EPOCH: 4,train_loss: 0.018137712288054005, valid_loss: 0.017973983021719115\nSEED: 9, FOLD: 0, EPOCH: 5,train_loss: 0.017581538472702538, valid_loss: 0.017968495110315934\nSEED: 9, FOLD: 0, EPOCH: 6,train_loss: 0.017181172474300947, valid_loss: 0.01810578192983355\nSEED: 9, FOLD: 0, EPOCH: 7,train_loss: 0.01694331438942016, valid_loss: 0.0180694278595703\nSEED: 9, FOLD: 0, EPOCH: 8,train_loss: 0.016710341084694515, valid_loss: 0.018947577183800083\nSEED: 9, FOLD: 0, EPOCH: 9,train_loss: 0.016585649301608402, valid_loss: 0.018166639309908663\nSEED: 9, FOLD: 0, EPOCH: 10,train_loss: 0.016437975608784218, valid_loss: 0.019103934429585932\nSEED: 9, FOLD: 0, EPOCH: 11,train_loss: 0.01635495302658798, valid_loss: 0.018319115069295677\nSEED: 9, FOLD: 0, EPOCH: 12,train_loss: 0.015999874808704077, valid_loss: 0.018520357699266504\nSEED: 9, FOLD: 0, EPOCH: 13,train_loss: 0.015492983884515537, valid_loss: 0.018553578268204418\nSEED: 9, FOLD: 0, EPOCH: 14,train_loss: 0.0149594332712392, valid_loss: 0.01891991655741419\nSEED: 9, FOLD: 0, EPOCH: 15,train_loss: 0.014255797321759705, valid_loss: 0.019332244726164\nSEED: 9, FOLD: 0, EPOCH: 16,train_loss: 0.013305933450929064, valid_loss: 0.020376187775816235\nSEED: 9, FOLD: 0, EPOCH: 17,train_loss: 0.012091260626102272, valid_loss: 0.020467642109308924\nSEED: 9, FOLD: 0, EPOCH: 18,train_loss: 0.010682025208961273, valid_loss: 0.020527803099581174\nSEED: 9, FOLD: 0, EPOCH: 19,train_loss: 0.009170092365609995, valid_loss: 0.020898957390870367\nSEED: 9, FOLD: 0, EPOCH: 20,train_loss: 0.007791598074381118, valid_loss: 0.021203512219446045\nSEED: 9, FOLD: 0, EPOCH: 21,train_loss: 0.006780024779879529, valid_loss: 0.021204817295074462\nSEED: 9, FOLD: 0, EPOCH: 22,train_loss: 0.006180217773046183, valid_loss: 0.021288467198610307\nSEED: 9, FOLD: 0, EPOCH: 23,train_loss: 0.005890057010549134, valid_loss: 0.021250439382025175\nSEED: 9, FOLD: 0, EPOCH: 24,train_loss: 0.005786542922420346, valid_loss: 0.0212618530860969\nFOLD: 1, EPOCH: 0,train_loss: 0.7298464435730537, valid_loss: 0.692102655342647\nSEED: 9, FOLD: 1, EPOCH: 0,train_loss: 0.470149816455741, valid_loss: 0.023664194984095437\nSEED: 9, FOLD: 1, EPOCH: 1,train_loss: 0.02191091821032719, valid_loss: 0.027138083960328782\nSEED: 9, FOLD: 1, EPOCH: 2,train_loss: 0.02017670007844041, valid_loss: 0.019231354924184936\nSEED: 9, FOLD: 1, EPOCH: 3,train_loss: 0.01891328932812614, valid_loss: 0.01826022049146039\nSEED: 9, FOLD: 1, EPOCH: 4,train_loss: 0.01808756503555244, valid_loss: 0.01790019204573972\nSEED: 9, FOLD: 1, EPOCH: 5,train_loss: 0.01755647431977474, valid_loss: 0.018107156003160135\nSEED: 9, FOLD: 1, EPOCH: 6,train_loss: 0.017274989413410206, valid_loss: 0.01819518195199115\nSEED: 9, FOLD: 1, EPOCH: 7,train_loss: 0.017047284551671822, valid_loss: 0.018058297969400883\nSEED: 9, FOLD: 1, EPOCH: 8,train_loss: 0.016776699430044114, valid_loss: 0.01811961904168129\nSEED: 9, FOLD: 1, EPOCH: 9,train_loss: 0.01667883727753902, valid_loss: 0.018207669497600623\nSEED: 9, FOLD: 1, EPOCH: 10,train_loss: 0.016574846220331906, valid_loss: 0.01814978439360857\nSEED: 9, FOLD: 1, EPOCH: 11,train_loss: 0.016226616531719258, valid_loss: 0.018325314112007617\nSEED: 9, FOLD: 1, EPOCH: 12,train_loss: 0.016030363521001637, valid_loss: 0.018209330524717057\nSEED: 9, FOLD: 1, EPOCH: 13,train_loss: 0.015594517574203711, valid_loss: 0.018622379723404137\nSEED: 9, FOLD: 1, EPOCH: 14,train_loss: 0.015037002592571895, valid_loss: 0.018820515647530556\nSEED: 9, FOLD: 1, EPOCH: 15,train_loss: 0.014219686572514746, valid_loss: 0.018816407423998628\nSEED: 9, FOLD: 1, EPOCH: 16,train_loss: 0.01326888471325166, valid_loss: 0.019428435393742154\nSEED: 9, FOLD: 1, EPOCH: 17,train_loss: 0.011874140002322894, valid_loss: 0.019782784740839686\nSEED: 9, FOLD: 1, EPOCH: 18,train_loss: 0.010359050121403089, valid_loss: 0.020597419887781142\nSEED: 9, FOLD: 1, EPOCH: 19,train_loss: 0.008828112828361727, valid_loss: 0.020894984528422356\nSEED: 9, FOLD: 1, EPOCH: 20,train_loss: 0.007501500709675742, valid_loss: 0.021135284219469343\nSEED: 9, FOLD: 1, EPOCH: 21,train_loss: 0.006524844893872956, valid_loss: 0.021202697711331504\nSEED: 9, FOLD: 1, EPOCH: 22,train_loss: 0.005965128428826149, valid_loss: 0.021214001306465693\nSEED: 9, FOLD: 1, EPOCH: 23,train_loss: 0.005690467346758738, valid_loss: 0.02129104488662311\nSEED: 9, FOLD: 1, EPOCH: 24,train_loss: 0.005593993011046282, valid_loss: 0.021321870014071466\nFOLD: 2, EPOCH: 0,train_loss: 0.7294595353845237, valid_loss: 0.6940509864262172\nSEED: 9, FOLD: 2, EPOCH: 0,train_loss: 0.4704100347758419, valid_loss: 0.024338094517588615\nSEED: 9, FOLD: 2, EPOCH: 1,train_loss: 0.0214267760326249, valid_loss: 0.02353732106941087\nSEED: 9, FOLD: 2, EPOCH: 2,train_loss: 0.02013582458206709, valid_loss: 0.019548556261828966\nSEED: 9, FOLD: 2, EPOCH: 3,train_loss: 0.018814261732757954, valid_loss: 0.019733909783618792\nSEED: 9, FOLD: 2, EPOCH: 4,train_loss: 0.01811124302068914, valid_loss: 0.02065189065677779\nSEED: 9, FOLD: 2, EPOCH: 5,train_loss: 0.017649262218965567, valid_loss: 0.018306814879179\nSEED: 9, FOLD: 2, EPOCH: 6,train_loss: 0.017339418129320595, valid_loss: 0.2986215802175658\nSEED: 9, FOLD: 2, EPOCH: 7,train_loss: 0.017110945299213778, valid_loss: 0.018226529977151327\nSEED: 9, FOLD: 2, EPOCH: 8,train_loss: 0.016985536627201498, valid_loss: 0.018799183304820742\nSEED: 9, FOLD: 2, EPOCH: 9,train_loss: 0.016839448065645454, valid_loss: 0.01813538864787136\nSEED: 9, FOLD: 2, EPOCH: 10,train_loss: 0.01675459411184209, valid_loss: 0.018265145511499475\nSEED: 9, FOLD: 2, EPOCH: 11,train_loss: 0.016526854131370783, valid_loss: 0.01862716509827546\nSEED: 9, FOLD: 2, EPOCH: 12,train_loss: 0.01625643737371201, valid_loss: 0.01830516925879887\nSEED: 9, FOLD: 2, EPOCH: 13,train_loss: 0.015874118253966604, valid_loss: 0.01803331750312022\nSEED: 9, FOLD: 2, EPOCH: 14,train_loss: 0.015333396477111872, valid_loss: 0.019205655104347637\nSEED: 9, FOLD: 2, EPOCH: 15,train_loss: 0.014836447239192068, valid_loss: 0.01876040186200823\nSEED: 9, FOLD: 2, EPOCH: 16,train_loss: 0.014164057398295921, valid_loss: 0.019513979820268496\nSEED: 9, FOLD: 2, EPOCH: 17,train_loss: 0.01285371638537533, valid_loss: 0.02012450248003006\nSEED: 9, FOLD: 2, EPOCH: 18,train_loss: 0.011466106075955473, valid_loss: 0.020068635631884848\nSEED: 9, FOLD: 2, EPOCH: 19,train_loss: 0.009883186037557713, valid_loss: 0.020530158387763158\nSEED: 9, FOLD: 2, EPOCH: 20,train_loss: 0.008399383195311479, valid_loss: 0.02087169225726809\nSEED: 9, FOLD: 2, EPOCH: 21,train_loss: 0.007302068018664916, valid_loss: 0.021186998805829457\nSEED: 9, FOLD: 2, EPOCH: 22,train_loss: 0.0065752634630147095, valid_loss: 0.021128369069525175\nSEED: 9, FOLD: 2, EPOCH: 23,train_loss: 0.0062323324382305145, valid_loss: 0.02124350629746914\nSEED: 9, FOLD: 2, EPOCH: 24,train_loss: 0.006072622443805786, valid_loss: 0.02123940975538322\nFOLD: 3, EPOCH: 0,train_loss: 0.7300600863021353, valid_loss: 0.6951032719191383\nSEED: 9, FOLD: 3, EPOCH: 0,train_loss: 0.46843790794736234, valid_loss: 0.025237484451602486\nSEED: 9, FOLD: 3, EPOCH: 1,train_loss: 0.021783053362067196, valid_loss: 0.021289541824337316\nSEED: 9, FOLD: 3, EPOCH: 2,train_loss: 0.020234229839474396, valid_loss: 0.01924243163974846\nSEED: 9, FOLD: 3, EPOCH: 3,train_loss: 0.018763941186277763, valid_loss: 0.0184979943339439\nSEED: 9, FOLD: 3, EPOCH: 4,train_loss: 0.01792574601004953, valid_loss: 0.01857918846037458\nSEED: 9, FOLD: 3, EPOCH: 5,train_loss: 0.017437777974629316, valid_loss: 0.018286554279791957\nSEED: 9, FOLD: 3, EPOCH: 6,train_loss: 0.01713524150081735, valid_loss: 0.01848206466392559\nSEED: 9, FOLD: 3, EPOCH: 7,train_loss: 0.016896749367478533, valid_loss: 0.01849185795906712\nSEED: 9, FOLD: 3, EPOCH: 8,train_loss: 0.016704081847885813, valid_loss: 0.01862958336577696\nSEED: 9, FOLD: 3, EPOCH: 9,train_loss: 0.016478934622221234, valid_loss: 0.018587883808376157\nSEED: 9, FOLD: 3, EPOCH: 10,train_loss: 0.016341391080261572, valid_loss: 0.01884165871888399\nSEED: 9, FOLD: 3, EPOCH: 11,train_loss: 0.0160987153581843, valid_loss: 0.019138213904464945\nSEED: 9, FOLD: 3, EPOCH: 12,train_loss: 0.01577797093415174, valid_loss: 0.0187430729103439\nSEED: 9, FOLD: 3, EPOCH: 13,train_loss: 0.015341310768617668, valid_loss: 0.01926663956221412\nSEED: 9, FOLD: 3, EPOCH: 14,train_loss: 0.014781319036863852, valid_loss: 0.019415266811847687\nSEED: 9, FOLD: 3, EPOCH: 15,train_loss: 0.014071756400221931, valid_loss: 0.0195075316245065\nSEED: 9, FOLD: 3, EPOCH: 16,train_loss: 0.013023752354733322, valid_loss: 0.020395992104621494\nSEED: 9, FOLD: 3, EPOCH: 17,train_loss: 0.011788333489465109, valid_loss: 0.021334484274334767\nSEED: 9, FOLD: 3, EPOCH: 18,train_loss: 0.010359062684996836, valid_loss: 0.021445900585283253\nSEED: 9, FOLD: 3, EPOCH: 19,train_loss: 0.00884604192527848, valid_loss: 0.021480963291490778\nSEED: 9, FOLD: 3, EPOCH: 20,train_loss: 0.007513181633734401, valid_loss: 0.021785736850955906\nSEED: 9, FOLD: 3, EPOCH: 21,train_loss: 0.006580499861308414, valid_loss: 0.021718123325091952\nSEED: 9, FOLD: 3, EPOCH: 22,train_loss: 0.006021758983505593, valid_loss: 0.02189025129465496\nSEED: 9, FOLD: 3, EPOCH: 23,train_loss: 0.005767686241913749, valid_loss: 0.02189159590531798\nSEED: 9, FOLD: 3, EPOCH: 24,train_loss: 0.005641926306070409, valid_loss: 0.021944271181436145\nFOLD: 4, EPOCH: 0,train_loss: 0.7298861994360485, valid_loss: 0.6939903974533081\nSEED: 9, FOLD: 4, EPOCH: 0,train_loss: 0.4713687039503868, valid_loss: 0.023873851288642202\nSEED: 9, FOLD: 4, EPOCH: 1,train_loss: 0.0220517360190623, valid_loss: 0.02103973834642342\nSEED: 9, FOLD: 4, EPOCH: 2,train_loss: 0.020642928072135813, valid_loss: 0.019261914544871875\nSEED: 9, FOLD: 4, EPOCH: 3,train_loss: 0.019295677610666213, valid_loss: 0.10022721370416028\nSEED: 9, FOLD: 4, EPOCH: 4,train_loss: 0.0186162133612772, valid_loss: 0.018406581399696215\nSEED: 9, FOLD: 4, EPOCH: 5,train_loss: 0.018113917623558184, valid_loss: 0.01821636429854802\nSEED: 9, FOLD: 4, EPOCH: 6,train_loss: 0.017753919640923068, valid_loss: 0.018011532511029923\nSEED: 9, FOLD: 4, EPOCH: 7,train_loss: 0.017463628936858072, valid_loss: 0.017918872833251952\nSEED: 9, FOLD: 4, EPOCH: 8,train_loss: 0.017202486107329818, valid_loss: 0.01826520971953869\nSEED: 9, FOLD: 4, EPOCH: 9,train_loss: 0.017039699649886927, valid_loss: 0.01798259248690946\nSEED: 9, FOLD: 4, EPOCH: 10,train_loss: 0.016757307982031445, valid_loss: 0.018067850704704014\nSEED: 9, FOLD: 4, EPOCH: 11,train_loss: 0.016532218790728682, valid_loss: 0.017872664518654345\nSEED: 9, FOLD: 4, EPOCH: 12,train_loss: 0.016203465252897165, valid_loss: 0.018272313502218043\nSEED: 9, FOLD: 4, EPOCH: 13,train_loss: 0.015849837156379745, valid_loss: 0.01852569675871304\nSEED: 9, FOLD: 4, EPOCH: 14,train_loss: 0.015311444307385135, valid_loss: 0.018608941776411873\nSEED: 9, FOLD: 4, EPOCH: 15,train_loss: 0.014599410504320242, valid_loss: 0.01927064433693886\nSEED: 9, FOLD: 4, EPOCH: 16,train_loss: 0.013656485771393254, valid_loss: 0.019738510996103287\nSEED: 9, FOLD: 4, EPOCH: 17,train_loss: 0.012557593249056462, valid_loss: 0.02040035602237497\nSEED: 9, FOLD: 4, EPOCH: 18,train_loss: 0.011198586308444938, valid_loss: 0.02018579249935491\nSEED: 9, FOLD: 4, EPOCH: 19,train_loss: 0.009644148776130955, valid_loss: 0.02057936420398099\nSEED: 9, FOLD: 4, EPOCH: 20,train_loss: 0.00825854167886024, valid_loss: 0.02072101411010538\nSEED: 9, FOLD: 4, EPOCH: 21,train_loss: 0.007187794054430114, valid_loss: 0.020908154440777642\nSEED: 9, FOLD: 4, EPOCH: 22,train_loss: 0.006524722530323006, valid_loss: 0.021013062660183227\nSEED: 9, FOLD: 4, EPOCH: 23,train_loss: 0.006226242791834103, valid_loss: 0.02106277367898396\nSEED: 9, FOLD: 4, EPOCH: 24,train_loss: 0.0060892417265550934, valid_loss: 0.02105779248688902\nFOLD: 0, EPOCH: 0,train_loss: 0.7320895911990732, valid_loss: 0.6918745689532336\nSEED: 10, FOLD: 0, EPOCH: 0,train_loss: 0.46836719953495526, valid_loss: 0.025031865793554223\nSEED: 10, FOLD: 0, EPOCH: 1,train_loss: 0.02182803334047397, valid_loss: 0.02140820015440969\nSEED: 10, FOLD: 0, EPOCH: 2,train_loss: 0.020174685703671497, valid_loss: 0.019221676513552666\nSEED: 10, FOLD: 0, EPOCH: 3,train_loss: 0.018967507231602634, valid_loss: 0.01858788709539701\nSEED: 10, FOLD: 0, EPOCH: 4,train_loss: 0.018253560380443283, valid_loss: 0.018525591695352513\nSEED: 10, FOLD: 0, EPOCH: 5,train_loss: 0.017670082927182102, valid_loss: 0.01838855946655659\nSEED: 10, FOLD: 0, EPOCH: 6,train_loss: 0.017495770857709904, valid_loss: 0.018234746996313334\nSEED: 10, FOLD: 0, EPOCH: 7,train_loss: 0.017125530546342117, valid_loss: 0.01816728481036775\nSEED: 10, FOLD: 0, EPOCH: 8,train_loss: 0.016906742343976013, valid_loss: 0.01832772561294191\nSEED: 10, FOLD: 0, EPOCH: 9,train_loss: 0.016836698436974617, valid_loss: 0.018344975898371023\nSEED: 10, FOLD: 0, EPOCH: 10,train_loss: 0.0166537513875443, valid_loss: 0.0184744569911238\nSEED: 10, FOLD: 0, EPOCH: 11,train_loss: 0.016541097306416952, valid_loss: 0.01851943926885724\nSEED: 10, FOLD: 0, EPOCH: 12,train_loss: 0.016218152686791575, valid_loss: 0.018539124469765845\nSEED: 10, FOLD: 0, EPOCH: 13,train_loss: 0.01590621002369385, valid_loss: 0.018503077711690876\nSEED: 10, FOLD: 0, EPOCH: 14,train_loss: 0.015527295691055664, valid_loss: 0.018744662650586927\nSEED: 10, FOLD: 0, EPOCH: 15,train_loss: 0.014862481700391441, valid_loss: 0.01908346835304709\nSEED: 10, FOLD: 0, EPOCH: 16,train_loss: 0.014128285628891941, valid_loss: 0.019481681835125473\nSEED: 10, FOLD: 0, EPOCH: 17,train_loss: 0.012997088798632225, valid_loss: 0.31070403053480034\nSEED: 10, FOLD: 0, EPOCH: 18,train_loss: 0.011446465387184551, valid_loss: 0.021048474618617224\nSEED: 10, FOLD: 0, EPOCH: 19,train_loss: 0.009796160381233347, valid_loss: 0.021276668426306808\nSEED: 10, FOLD: 0, EPOCH: 20,train_loss: 0.00824908730978875, valid_loss: 0.02136135506717598\nSEED: 10, FOLD: 0, EPOCH: 21,train_loss: 0.007063966770858869, valid_loss: 0.02168230986332192\nSEED: 10, FOLD: 0, EPOCH: 22,train_loss: 0.0063801540864928475, valid_loss: 0.021764820770305747\nSEED: 10, FOLD: 0, EPOCH: 23,train_loss: 0.006021973150579825, valid_loss: 0.021778551313806984\nSEED: 10, FOLD: 0, EPOCH: 24,train_loss: 0.005885639342654875, valid_loss: 0.02182054497739848\nFOLD: 1, EPOCH: 0,train_loss: 0.7319386866841003, valid_loss: 0.6891461494896147\nSEED: 10, FOLD: 1, EPOCH: 0,train_loss: 0.47022931536074974, valid_loss: 0.02380241531257828\nSEED: 10, FOLD: 1, EPOCH: 1,train_loss: 0.021825238192168465, valid_loss: 0.020765245167745486\nSEED: 10, FOLD: 1, EPOCH: 2,train_loss: 0.02002117943263402, valid_loss: 0.01895011852805813\nSEED: 10, FOLD: 1, EPOCH: 3,train_loss: 0.018787762687208442, valid_loss: 0.01862004642478294\nSEED: 10, FOLD: 1, EPOCH: 4,train_loss: 0.018105782337323593, valid_loss: 0.018162167579349544\nSEED: 10, FOLD: 1, EPOCH: 5,train_loss: 0.017516885292682336, valid_loss: 0.018228673013961978\nSEED: 10, FOLD: 1, EPOCH: 6,train_loss: 0.017263509543870924, valid_loss: 0.02245190294666423\nSEED: 10, FOLD: 1, EPOCH: 7,train_loss: 0.017000730917619094, valid_loss: 0.018016431118465133\nSEED: 10, FOLD: 1, EPOCH: 8,train_loss: 0.016970795334527528, valid_loss: 0.017805197120954592\nSEED: 10, FOLD: 1, EPOCH: 9,train_loss: 0.01687019662999541, valid_loss: 0.017944246866843767\nSEED: 10, FOLD: 1, EPOCH: 10,train_loss: 0.016681484993628776, valid_loss: 0.01824994685335292\nSEED: 10, FOLD: 1, EPOCH: 11,train_loss: 0.016499451150859358, valid_loss: 0.01828765871727632\nSEED: 10, FOLD: 1, EPOCH: 12,train_loss: 0.016242937225658092, valid_loss: 0.01898731731085314\nSEED: 10, FOLD: 1, EPOCH: 13,train_loss: 0.015865965243292986, valid_loss: 0.018375980098628335\nSEED: 10, FOLD: 1, EPOCH: 14,train_loss: 0.015373504292355837, valid_loss: 0.01896870539834102\nSEED: 10, FOLD: 1, EPOCH: 15,train_loss: 0.014693888944376558, valid_loss: 0.01900369172087974\nSEED: 10, FOLD: 1, EPOCH: 16,train_loss: 0.013700687040975929, valid_loss: 0.01964888468177782\nSEED: 10, FOLD: 1, EPOCH: 17,train_loss: 0.01247095912151093, valid_loss: 0.019919351157214906\nSEED: 10, FOLD: 1, EPOCH: 18,train_loss: 0.011046062733461388, valid_loss: 0.020822850935575034\nSEED: 10, FOLD: 1, EPOCH: 19,train_loss: 0.00939489901745624, valid_loss: 0.02068304777559307\nSEED: 10, FOLD: 1, EPOCH: 20,train_loss: 0.007893396779405374, valid_loss: 0.020894275202105444\nSEED: 10, FOLD: 1, EPOCH: 21,train_loss: 0.00679711339465023, valid_loss: 0.021252051047566865\nSEED: 10, FOLD: 1, EPOCH: 22,train_loss: 0.006170239472884114, valid_loss: 0.02117034068538083\nSEED: 10, FOLD: 1, EPOCH: 23,train_loss: 0.005861308734972764, valid_loss: 0.021255151368677616\nSEED: 10, FOLD: 1, EPOCH: 24,train_loss: 0.005762271154807867, valid_loss: 0.021315231246666774\nFOLD: 2, EPOCH: 0,train_loss: 0.7319194367830304, valid_loss: 0.6909674371991839\nSEED: 10, FOLD: 2, EPOCH: 0,train_loss: 0.46892044736423355, valid_loss: 0.024354436727506774\nSEED: 10, FOLD: 2, EPOCH: 1,train_loss: 0.021667102635230705, valid_loss: 0.02300115664090429\nSEED: 10, FOLD: 2, EPOCH: 2,train_loss: 0.020108854141680226, valid_loss: 0.01952984082911696\nSEED: 10, FOLD: 2, EPOCH: 3,train_loss: 0.01882257328733154, valid_loss: 0.018474002342138973\nSEED: 10, FOLD: 2, EPOCH: 4,train_loss: 0.018066321384917566, valid_loss: 0.018139941724283355\nSEED: 10, FOLD: 2, EPOCH: 5,train_loss: 0.017505610699131004, valid_loss: 0.018207119325441973\nSEED: 10, FOLD: 2, EPOCH: 6,train_loss: 0.017060937596134085, valid_loss: 0.0183016228888716\nSEED: 10, FOLD: 2, EPOCH: 7,train_loss: 0.016780830946737442, valid_loss: 0.019257623116884913\nSEED: 10, FOLD: 2, EPOCH: 8,train_loss: 0.016634158047752968, valid_loss: 0.01838420033454895\nSEED: 10, FOLD: 2, EPOCH: 9,train_loss: 0.016465067600264498, valid_loss: 0.01845837788922446\nSEED: 10, FOLD: 2, EPOCH: 10,train_loss: 0.016265408736586138, valid_loss: 0.01851032706243651\nSEED: 10, FOLD: 2, EPOCH: 11,train_loss: 0.016112401258146416, valid_loss: 0.018966570336903844\nSEED: 10, FOLD: 2, EPOCH: 12,train_loss: 0.01577588035117673, valid_loss: 0.019210032267229896\nSEED: 10, FOLD: 2, EPOCH: 13,train_loss: 0.015381675341800936, valid_loss: 0.01926230059138366\nSEED: 10, FOLD: 2, EPOCH: 14,train_loss: 0.014919041669455128, valid_loss: 0.019494873657822608\nSEED: 10, FOLD: 2, EPOCH: 15,train_loss: 0.01403155088748621, valid_loss: 0.02000785619020462\nSEED: 10, FOLD: 2, EPOCH: 16,train_loss: 0.01291755442440078, valid_loss: 0.020286071673035623\nSEED: 10, FOLD: 2, EPOCH: 17,train_loss: 0.011490017506361439, valid_loss: 0.020624160660164696\nSEED: 10, FOLD: 2, EPOCH: 18,train_loss: 0.009999463888074177, valid_loss: 0.021928963969860757\nSEED: 10, FOLD: 2, EPOCH: 19,train_loss: 0.008466470102523115, valid_loss: 0.028800392523407936\nSEED: 10, FOLD: 2, EPOCH: 20,train_loss: 0.007168030194209322, valid_loss: 0.02187942388866629\nSEED: 10, FOLD: 2, EPOCH: 21,train_loss: 0.006313288786812969, valid_loss: 0.02191230186394283\nSEED: 10, FOLD: 2, EPOCH: 22,train_loss: 0.005808443202218716, valid_loss: 0.02201137500149863\nSEED: 10, FOLD: 2, EPOCH: 23,train_loss: 0.005555208488974882, valid_loss: 0.02203961626759597\nSEED: 10, FOLD: 2, EPOCH: 24,train_loss: 0.005482743959873915, valid_loss: 0.022071321202175958\nFOLD: 3, EPOCH: 0,train_loss: 0.7319367700728817, valid_loss: 0.6907807963235038\nSEED: 10, FOLD: 3, EPOCH: 0,train_loss: 0.4688085345281423, valid_loss: 0.02339653064097677\nSEED: 10, FOLD: 3, EPOCH: 1,train_loss: 0.021627184327529823, valid_loss: 0.0204602879605123\nSEED: 10, FOLD: 3, EPOCH: 2,train_loss: 0.0202891419277243, valid_loss: 0.019516530366880554\nSEED: 10, FOLD: 3, EPOCH: 3,train_loss: 0.019079238365309826, valid_loss: 0.01887387436415468\nSEED: 10, FOLD: 3, EPOCH: 4,train_loss: 0.018404226581417563, valid_loss: 0.020629481332642693\nSEED: 10, FOLD: 3, EPOCH: 5,train_loss: 0.017850287002173885, valid_loss: 0.018155221215316226\nSEED: 10, FOLD: 3, EPOCH: 6,train_loss: 0.01745043059244104, valid_loss: 0.43348488568195276\nSEED: 10, FOLD: 3, EPOCH: 7,train_loss: 0.017160389194453972, valid_loss: 0.02646398033414568\nSEED: 10, FOLD: 3, EPOCH: 8,train_loss: 0.0170136078166357, valid_loss: 0.018150771568928446\nSEED: 10, FOLD: 3, EPOCH: 9,train_loss: 0.01687044059128865, valid_loss: 2.4200586458402022\nSEED: 10, FOLD: 3, EPOCH: 10,train_loss: 0.01674862064934079, valid_loss: 0.018243041687778065\nSEED: 10, FOLD: 3, EPOCH: 11,train_loss: 0.016553490611630074, valid_loss: 0.018111364490219526\nSEED: 10, FOLD: 3, EPOCH: 12,train_loss: 0.016352101168392794, valid_loss: 0.018130741960236004\nSEED: 10, FOLD: 3, EPOCH: 13,train_loss: 0.015984729573508535, valid_loss: 0.0256855167980705\nSEED: 10, FOLD: 3, EPOCH: 14,train_loss: 0.015425001831212337, valid_loss: 0.10815905875393322\nSEED: 10, FOLD: 3, EPOCH: 15,train_loss: 0.01480436440476257, valid_loss: 0.019209315414939608\nSEED: 10, FOLD: 3, EPOCH: 16,train_loss: 0.01390505079989848, valid_loss: 0.01950964980891773\nSEED: 10, FOLD: 3, EPOCH: 17,train_loss: 0.012728353645112635, valid_loss: 0.019813886071954456\nSEED: 10, FOLD: 3, EPOCH: 18,train_loss: 0.011325553106818941, valid_loss: 0.020214548973100526\nSEED: 10, FOLD: 3, EPOCH: 19,train_loss: 0.009695688519032969, valid_loss: 0.020900262892246245\nSEED: 10, FOLD: 3, EPOCH: 20,train_loss: 0.008236409040113938, valid_loss: 0.020850968999522074\nSEED: 10, FOLD: 3, EPOCH: 21,train_loss: 0.007094730913261141, valid_loss: 0.020965505923543657\nSEED: 10, FOLD: 3, EPOCH: 22,train_loss: 0.006427572105430822, valid_loss: 0.021064599816288266\nSEED: 10, FOLD: 3, EPOCH: 23,train_loss: 0.00607524064126546, valid_loss: 0.021132444377456393\nSEED: 10, FOLD: 3, EPOCH: 24,train_loss: 0.005962256929310767, valid_loss: 0.02113147665347372\nFOLD: 4, EPOCH: 0,train_loss: 0.7321140157139819, valid_loss: 0.6911177958760942\nSEED: 10, FOLD: 4, EPOCH: 0,train_loss: 0.468324627659783, valid_loss: 0.024455332489950316\nSEED: 10, FOLD: 4, EPOCH: 1,train_loss: 0.02160088173991096, valid_loss: 0.021138492758784974\nSEED: 10, FOLD: 4, EPOCH: 2,train_loss: 0.02023946057897115, valid_loss: 0.019099836024854863\nSEED: 10, FOLD: 4, EPOCH: 3,train_loss: 0.019048569359533165, valid_loss: 0.018473732258592335\nSEED: 10, FOLD: 4, EPOCH: 4,train_loss: 0.018208897551116737, valid_loss: 0.01808894273958036\nSEED: 10, FOLD: 4, EPOCH: 5,train_loss: 0.01773781651981931, valid_loss: 0.018386193364858628\nSEED: 10, FOLD: 4, EPOCH: 6,train_loss: 0.017316709569506886, valid_loss: 0.01798861250281334\nSEED: 10, FOLD: 4, EPOCH: 7,train_loss: 0.017110263172915016, valid_loss: 0.01885288522711822\nSEED: 10, FOLD: 4, EPOCH: 8,train_loss: 0.01698379803016998, valid_loss: 0.017783933877944948\nSEED: 10, FOLD: 4, EPOCH: 9,train_loss: 0.016803430339348488, valid_loss: 0.018097484138395105\nSEED: 10, FOLD: 4, EPOCH: 10,train_loss: 0.0166346221635847, valid_loss: 0.02844576734517302\nSEED: 10, FOLD: 4, EPOCH: 11,train_loss: 0.016492618254615343, valid_loss: 0.01818209146814687\nSEED: 10, FOLD: 4, EPOCH: 12,train_loss: 0.016253629031226687, valid_loss: 0.01813116084252085\nSEED: 10, FOLD: 4, EPOCH: 13,train_loss: 0.015834956895560026, valid_loss: 0.018730901128479412\nSEED: 10, FOLD: 4, EPOCH: 14,train_loss: 0.015341873321196308, valid_loss: 0.01860498703484024\nSEED: 10, FOLD: 4, EPOCH: 15,train_loss: 0.014611538270137447, valid_loss: 0.01920251159795693\nSEED: 10, FOLD: 4, EPOCH: 16,train_loss: 0.013746174119844816, valid_loss: 0.019631472575877395\nSEED: 10, FOLD: 4, EPOCH: 17,train_loss: 0.012473714578410854, valid_loss: 0.01983716796551432\nSEED: 10, FOLD: 4, EPOCH: 18,train_loss: 0.010908028920707495, valid_loss: 0.020260883229119436\nSEED: 10, FOLD: 4, EPOCH: 19,train_loss: 0.009318428019574587, valid_loss: 0.020998640943850788\nSEED: 10, FOLD: 4, EPOCH: 20,train_loss: 0.007903690851441976, valid_loss: 0.021143393431391034\nSEED: 10, FOLD: 4, EPOCH: 21,train_loss: 0.006812328358005354, valid_loss: 0.021049179030316216\nSEED: 10, FOLD: 4, EPOCH: 22,train_loss: 0.006193678120853028, valid_loss: 0.021160324769360677\nSEED: 10, FOLD: 4, EPOCH: 23,train_loss: 0.0058832317050816355, valid_loss: 0.021278483580265725\nSEED: 10, FOLD: 4, EPOCH: 24,train_loss: 0.005773693154417519, valid_loss: 0.021271526121667453\nFOLD: 0, EPOCH: 0,train_loss: 0.7314926541369894, valid_loss: 0.6931930933679853\nSEED: 11, FOLD: 0, EPOCH: 0,train_loss: 0.4706524756561587, valid_loss: 0.02495684927063329\nSEED: 11, FOLD: 0, EPOCH: 1,train_loss: 0.021829554514176605, valid_loss: 0.021823797853929655\nSEED: 11, FOLD: 0, EPOCH: 2,train_loss: 0.020731294676121594, valid_loss: 0.019580542721918653\nSEED: 11, FOLD: 0, EPOCH: 3,train_loss: 0.01940438757394103, valid_loss: 0.018793478395257676\nSEED: 11, FOLD: 0, EPOCH: 4,train_loss: 0.018628876318858154, valid_loss: 0.01817823794803449\nSEED: 11, FOLD: 0, EPOCH: 5,train_loss: 0.018126935232430696, valid_loss: 0.01841363784457956\nSEED: 11, FOLD: 0, EPOCH: 6,train_loss: 0.01776339214268154, valid_loss: 0.018040926887520722\nSEED: 11, FOLD: 0, EPOCH: 7,train_loss: 0.017450955028281263, valid_loss: 0.018209843151271343\nSEED: 11, FOLD: 0, EPOCH: 8,train_loss: 0.017238473492688026, valid_loss: 0.018214094558996814\nSEED: 11, FOLD: 0, EPOCH: 9,train_loss: 0.01699633561614631, valid_loss: 0.018553647824696134\nSEED: 11, FOLD: 0, EPOCH: 10,train_loss: 0.01695125977225278, valid_loss: 0.01798933869493859\nSEED: 11, FOLD: 0, EPOCH: 11,train_loss: 0.016745353340292753, valid_loss: 0.0486322744084256\nSEED: 11, FOLD: 0, EPOCH: 12,train_loss: 0.01651872180915181, valid_loss: 0.018415648117661478\nSEED: 11, FOLD: 0, EPOCH: 13,train_loss: 0.016260346485490816, valid_loss: 0.017830539867281912\nSEED: 11, FOLD: 0, EPOCH: 14,train_loss: 0.01576395048017519, valid_loss: 0.018646358512341976\nSEED: 11, FOLD: 0, EPOCH: 15,train_loss: 0.015108602911071934, valid_loss: 0.018500244644071375\nSEED: 11, FOLD: 0, EPOCH: 16,train_loss: 0.014457773396988277, valid_loss: 0.019361485806959015\nSEED: 11, FOLD: 0, EPOCH: 17,train_loss: 0.014054553448290064, valid_loss: 0.02006099516791957\nSEED: 11, FOLD: 0, EPOCH: 18,train_loss: 0.012410614922966646, valid_loss: 0.019580701552331447\nSEED: 11, FOLD: 0, EPOCH: 19,train_loss: 0.01100989728761108, valid_loss: 0.020138082333973475\nSEED: 11, FOLD: 0, EPOCH: 20,train_loss: 0.010585852217037176, valid_loss: 0.020335248644862858\nSEED: 11, FOLD: 0, EPOCH: 21,train_loss: 0.008915672328431105, valid_loss: 0.020352704663361823\nSEED: 11, FOLD: 0, EPOCH: 22,train_loss: 0.007808416700530527, valid_loss: 0.020473737642168997\nSEED: 11, FOLD: 0, EPOCH: 23,train_loss: 0.0072810541791166515, valid_loss: 0.020498821804566043\nSEED: 11, FOLD: 0, EPOCH: 24,train_loss: 0.007102840414702677, valid_loss: 0.020525741231228623\nFOLD: 1, EPOCH: 0,train_loss: 0.7315744239351024, valid_loss: 0.6948479567255292\nSEED: 11, FOLD: 1, EPOCH: 0,train_loss: 0.46921141065009264, valid_loss: 0.024114177003502844\nSEED: 11, FOLD: 1, EPOCH: 1,train_loss: 0.021762344986200333, valid_loss: 0.0220843819635255\nSEED: 11, FOLD: 1, EPOCH: 2,train_loss: 0.020464558208334274, valid_loss: 0.019885213992425373\nSEED: 11, FOLD: 1, EPOCH: 3,train_loss: 0.01914125630982976, valid_loss: 0.018410621796335493\nSEED: 11, FOLD: 1, EPOCH: 4,train_loss: 0.018362470801271822, valid_loss: 0.01865968523280961\nSEED: 11, FOLD: 1, EPOCH: 5,train_loss: 0.017838130529592003, valid_loss: 0.018541280126997402\nSEED: 11, FOLD: 1, EPOCH: 6,train_loss: 0.017267853912451992, valid_loss: 0.01850192765040057\nSEED: 11, FOLD: 1, EPOCH: 7,train_loss: 0.01697991023083096, valid_loss: 0.018500592479748387\nSEED: 11, FOLD: 1, EPOCH: 8,train_loss: 0.01662499330047032, valid_loss: 0.01863124668598175\nSEED: 11, FOLD: 1, EPOCH: 9,train_loss: 0.0163563236432231, valid_loss: 0.01864748549248491\nSEED: 11, FOLD: 1, EPOCH: 10,train_loss: 0.015999632131686245, valid_loss: 0.01935987195798329\nSEED: 11, FOLD: 1, EPOCH: 11,train_loss: 0.015498281753473524, valid_loss: 0.019095437441553387\nSEED: 11, FOLD: 1, EPOCH: 12,train_loss: 0.015180061618541029, valid_loss: 0.019661694977964675\nSEED: 11, FOLD: 1, EPOCH: 13,train_loss: 0.014907675012406231, valid_loss: 0.020099848881363867\nSEED: 11, FOLD: 1, EPOCH: 14,train_loss: 0.014639678647390741, valid_loss: 0.019535678412233082\nSEED: 11, FOLD: 1, EPOCH: 15,train_loss: 0.013026959647465012, valid_loss: 0.02010063332106386\nSEED: 11, FOLD: 1, EPOCH: 16,train_loss: 0.012223564101842003, valid_loss: 0.020755518759999956\nSEED: 11, FOLD: 1, EPOCH: 17,train_loss: 0.011307729185437378, valid_loss: 0.02082877531647682\nSEED: 11, FOLD: 1, EPOCH: 18,train_loss: 0.00985973211599217, valid_loss: 0.02118706288082259\nSEED: 11, FOLD: 1, EPOCH: 19,train_loss: 0.008393219209856528, valid_loss: 0.021142656675406865\nSEED: 11, FOLD: 1, EPOCH: 20,train_loss: 0.007392679914778126, valid_loss: 0.02184108623436519\nSEED: 11, FOLD: 1, EPOCH: 21,train_loss: 0.006696424720322956, valid_loss: 0.021372356159346444\nSEED: 11, FOLD: 1, EPOCH: 22,train_loss: 0.006209999852665309, valid_loss: 0.021418850336756026\nSEED: 11, FOLD: 1, EPOCH: 23,train_loss: 0.005900933731185353, valid_loss: 0.021499053122741835\nSEED: 11, FOLD: 1, EPOCH: 24,train_loss: 0.005806601849263129, valid_loss: 0.021446808001824788\nFOLD: 2, EPOCH: 0,train_loss: 0.7319128897742949, valid_loss: 0.6963848822257098\nSEED: 11, FOLD: 2, EPOCH: 0,train_loss: 0.46862319979708694, valid_loss: 0.0239302763605819\nSEED: 11, FOLD: 2, EPOCH: 1,train_loss: 0.021621101225415867, valid_loss: 0.021980435642249444\nSEED: 11, FOLD: 2, EPOCH: 2,train_loss: 0.02032525304272987, valid_loss: 0.0194168086437618\nSEED: 11, FOLD: 2, EPOCH: 3,train_loss: 0.019069671347413376, valid_loss: 0.018678602214683506\nSEED: 11, FOLD: 2, EPOCH: 4,train_loss: 0.01830015994230474, valid_loss: 0.02844576455433579\nSEED: 11, FOLD: 2, EPOCH: 5,train_loss: 0.0178546242793833, valid_loss: 0.01856432720909224\nSEED: 11, FOLD: 2, EPOCH: 6,train_loss: 0.01746280313860895, valid_loss: 0.495198299861787\nSEED: 11, FOLD: 2, EPOCH: 7,train_loss: 0.01715712090684236, valid_loss: 0.01862360567183179\nSEED: 11, FOLD: 2, EPOCH: 8,train_loss: 0.016977788016631985, valid_loss: 0.01846012007445097\nSEED: 11, FOLD: 2, EPOCH: 9,train_loss: 0.016819414163035326, valid_loss: 0.01818924695801209\nSEED: 11, FOLD: 2, EPOCH: 10,train_loss: 0.016584455312324175, valid_loss: 0.018698856782387283\nSEED: 11, FOLD: 2, EPOCH: 11,train_loss: 0.016451961367620505, valid_loss: 0.02058550121043535\nSEED: 11, FOLD: 2, EPOCH: 12,train_loss: 0.016110044472135494, valid_loss: 0.020492599236176294\nSEED: 11, FOLD: 2, EPOCH: 13,train_loss: 0.01579205502850422, valid_loss: 0.02288946509361267\nSEED: 11, FOLD: 2, EPOCH: 14,train_loss: 0.015288600448411013, valid_loss: 0.11874848642550848\nSEED: 11, FOLD: 2, EPOCH: 15,train_loss: 0.01467547821474896, valid_loss: 0.02520604689112481\nSEED: 11, FOLD: 2, EPOCH: 16,train_loss: 0.013693538919577131, valid_loss: 0.02247791868798873\nSEED: 11, FOLD: 2, EPOCH: 17,train_loss: 0.012605570560402197, valid_loss: 0.025844907935927895\nSEED: 11, FOLD: 2, EPOCH: 18,train_loss: 0.011128152545163597, valid_loss: 0.027123829075957045\nSEED: 11, FOLD: 2, EPOCH: 19,train_loss: 0.009586051599109087, valid_loss: 0.03335022564758273\nSEED: 11, FOLD: 2, EPOCH: 20,train_loss: 0.008166437017043, valid_loss: 0.037564365193247795\nSEED: 11, FOLD: 2, EPOCH: 21,train_loss: 0.007095896510704272, valid_loss: 0.021832010380047208\nSEED: 11, FOLD: 2, EPOCH: 22,train_loss: 0.006488522244752317, valid_loss: 0.02964391148484805\nSEED: 11, FOLD: 2, EPOCH: 23,train_loss: 0.006147302687168121, valid_loss: 0.02339845857418635\nSEED: 11, FOLD: 2, EPOCH: 24,train_loss: 0.006035933092209524, valid_loss: 0.023204988416503456\nFOLD: 3, EPOCH: 0,train_loss: 0.7309909419737001, valid_loss: 0.6962510909352984\nSEED: 11, FOLD: 3, EPOCH: 0,train_loss: 0.46912481037872855, valid_loss: 0.024347658455371856\nSEED: 11, FOLD: 3, EPOCH: 1,train_loss: 0.02177174478445364, valid_loss: 0.020938649347850256\nSEED: 11, FOLD: 3, EPOCH: 2,train_loss: 0.020517615196497543, valid_loss: 0.01916803632463728\nSEED: 11, FOLD: 3, EPOCH: 3,train_loss: 0.01919399012905964, valid_loss: 0.01856403648853302\nSEED: 11, FOLD: 3, EPOCH: 4,train_loss: 0.018320344435725954, valid_loss: 0.018377877399325372\nSEED: 11, FOLD: 3, EPOCH: 5,train_loss: 0.017788806417282078, valid_loss: 0.017959622932331904\nSEED: 11, FOLD: 3, EPOCH: 6,train_loss: 0.0174306930663685, valid_loss: 0.018989792306508338\nSEED: 11, FOLD: 3, EPOCH: 7,train_loss: 0.01713274781713667, valid_loss: 0.01833950366292681\nSEED: 11, FOLD: 3, EPOCH: 8,train_loss: 0.016907623867787745, valid_loss: 0.017988414157714162\nSEED: 11, FOLD: 3, EPOCH: 9,train_loss: 0.01673373801336772, valid_loss: 0.21550288487757954\nSEED: 11, FOLD: 3, EPOCH: 10,train_loss: 0.016504244177021843, valid_loss: 0.021804438584617208\nSEED: 11, FOLD: 3, EPOCH: 11,train_loss: 0.016362844149757555, valid_loss: 0.01906729021242687\nSEED: 11, FOLD: 3, EPOCH: 12,train_loss: 0.0161721572023479, valid_loss: 0.019118700070040566\nSEED: 11, FOLD: 3, EPOCH: 13,train_loss: 0.015617717023722935, valid_loss: 0.01925498385514532\nSEED: 11, FOLD: 3, EPOCH: 14,train_loss: 0.015193819743243681, valid_loss: 0.019276535883545876\nSEED: 11, FOLD: 3, EPOCH: 15,train_loss: 0.01460828663835275, valid_loss: 0.019416259761367526\nSEED: 11, FOLD: 3, EPOCH: 16,train_loss: 0.013563830931873425, valid_loss: 0.020056778618267605\nSEED: 11, FOLD: 3, EPOCH: 17,train_loss: 0.012329177694746118, valid_loss: 0.020337921806744166\nSEED: 11, FOLD: 3, EPOCH: 18,train_loss: 0.010773581074739712, valid_loss: 0.02360953747161797\nSEED: 11, FOLD: 3, EPOCH: 19,train_loss: 0.009422751750959002, valid_loss: 0.020695132602538382\nSEED: 11, FOLD: 3, EPOCH: 20,train_loss: 0.008052381889327713, valid_loss: 0.021186248000179018\nSEED: 11, FOLD: 3, EPOCH: 21,train_loss: 0.007043152389562, valid_loss: 0.021346576405423028\nSEED: 11, FOLD: 3, EPOCH: 22,train_loss: 0.006385153763509099, valid_loss: 0.021344661552991185\nSEED: 11, FOLD: 3, EPOCH: 23,train_loss: 0.0060407807713077554, valid_loss: 0.021444704277174813\nSEED: 11, FOLD: 3, EPOCH: 24,train_loss: 0.005918278136169133, valid_loss: 0.021442856001002448\nFOLD: 4, EPOCH: 0,train_loss: 0.7313629771671156, valid_loss: 0.6943902577672686\nSEED: 11, FOLD: 4, EPOCH: 0,train_loss: 0.470224875616875, valid_loss: 0.02357586297605719\nSEED: 11, FOLD: 4, EPOCH: 1,train_loss: 0.021893203204130605, valid_loss: 0.020306424157960076\nSEED: 11, FOLD: 4, EPOCH: 2,train_loss: 0.020527410055816608, valid_loss: 0.01882466253425394\nSEED: 11, FOLD: 4, EPOCH: 3,train_loss: 0.019061375837637125, valid_loss: 0.01943404445690768\nSEED: 11, FOLD: 4, EPOCH: 4,train_loss: 0.018330008362549065, valid_loss: 0.018355248123407365\nSEED: 11, FOLD: 4, EPOCH: 5,train_loss: 0.017869631984155542, valid_loss: 0.018062767386436463\nSEED: 11, FOLD: 4, EPOCH: 6,train_loss: 0.01741906318704795, valid_loss: 0.017880324061427796\nSEED: 11, FOLD: 4, EPOCH: 7,train_loss: 0.01712590793188471, valid_loss: 0.017829332128167154\nSEED: 11, FOLD: 4, EPOCH: 8,train_loss: 0.017013921069293995, valid_loss: 0.017709341725068432\nSEED: 11, FOLD: 4, EPOCH: 9,train_loss: 0.01688764277628086, valid_loss: 0.01768295615911484\nSEED: 11, FOLD: 4, EPOCH: 10,train_loss: 0.016727345540140666, valid_loss: 0.018178958179695264\nSEED: 11, FOLD: 4, EPOCH: 11,train_loss: 0.016594281807596232, valid_loss: 0.017816824545817716\nSEED: 11, FOLD: 4, EPOCH: 12,train_loss: 0.01642151557616074, valid_loss: 0.05902054735592433\nSEED: 11, FOLD: 4, EPOCH: 13,train_loss: 0.016181760352023327, valid_loss: 0.018209391246948925\nSEED: 11, FOLD: 4, EPOCH: 14,train_loss: 0.015766888530585017, valid_loss: 0.018410719824688775\nSEED: 11, FOLD: 4, EPOCH: 15,train_loss: 0.015146569777144132, valid_loss: 0.01880773811468056\nSEED: 11, FOLD: 4, EPOCH: 16,train_loss: 0.014383290296107748, valid_loss: 0.018876465888960022\nSEED: 11, FOLD: 4, EPOCH: 17,train_loss: 0.013208195675898642, valid_loss: 0.019725297125322477\nSEED: 11, FOLD: 4, EPOCH: 18,train_loss: 0.012002217760105637, valid_loss: 0.01993146017193794\nSEED: 11, FOLD: 4, EPOCH: 19,train_loss: 0.010506587646847223, valid_loss: 0.30518128047032017\nSEED: 11, FOLD: 4, EPOCH: 20,train_loss: 0.008950877808931753, valid_loss: 0.021174957656434606\nSEED: 11, FOLD: 4, EPOCH: 21,train_loss: 0.007701531905735279, valid_loss: 0.020842224253075463\nSEED: 11, FOLD: 4, EPOCH: 22,train_loss: 0.006889098908507476, valid_loss: 0.020678567300949777\nSEED: 11, FOLD: 4, EPOCH: 23,train_loss: 0.006495697539381303, valid_loss: 0.02079511529632977\nSEED: 11, FOLD: 4, EPOCH: 24,train_loss: 0.006332666742323089, valid_loss: 0.020788754256708283\nFOLD: 0, EPOCH: 0,train_loss: 0.7322802776875703, valid_loss: 0.6935793399810791\nSEED: 12, FOLD: 0, EPOCH: 0,train_loss: 0.4682974064641673, valid_loss: 0.023480604961514474\nSEED: 12, FOLD: 0, EPOCH: 1,train_loss: 0.02163553529459497, valid_loss: 0.020845052919217517\nSEED: 12, FOLD: 0, EPOCH: 2,train_loss: 0.020341526136558125, valid_loss: 0.01947694793343544\nSEED: 12, FOLD: 0, EPOCH: 3,train_loss: 0.018905775135625965, valid_loss: 20.187148710606355\nSEED: 12, FOLD: 0, EPOCH: 4,train_loss: 0.018179659279522257, valid_loss: 0.5180904499654259\nSEED: 12, FOLD: 0, EPOCH: 5,train_loss: 0.01772138833378752, valid_loss: 1.664369795737522\nSEED: 12, FOLD: 0, EPOCH: 6,train_loss: 0.017452083676513554, valid_loss: 0.01847640382392066\nSEED: 12, FOLD: 0, EPOCH: 7,train_loss: 0.0171678916119255, valid_loss: 0.536290184860783\nSEED: 12, FOLD: 0, EPOCH: 8,train_loss: 0.01694669387559744, valid_loss: 1.3577954460467612\nSEED: 12, FOLD: 0, EPOCH: 9,train_loss: 0.01672196222226257, valid_loss: 1.4641285169869662\nSEED: 12, FOLD: 0, EPOCH: 10,train_loss: 0.01655659257042883, valid_loss: 28.329900375806858\nSEED: 12, FOLD: 0, EPOCH: 11,train_loss: 0.01637662265557742, valid_loss: 0.01856716897870813\nSEED: 12, FOLD: 0, EPOCH: 12,train_loss: 0.0159970052216364, valid_loss: 0.29004400574735234\nSEED: 12, FOLD: 0, EPOCH: 13,train_loss: 0.01563894159524985, valid_loss: 0.018726414442062377\nSEED: 12, FOLD: 0, EPOCH: 14,train_loss: 0.015019269693858814, valid_loss: 0.019070765216435706\nSEED: 12, FOLD: 0, EPOCH: 15,train_loss: 0.014344342815541271, valid_loss: 0.019162624861512864\nSEED: 12, FOLD: 0, EPOCH: 16,train_loss: 0.013412405709749546, valid_loss: 0.01982741773660694\nSEED: 12, FOLD: 0, EPOCH: 17,train_loss: 0.012127889846654041, valid_loss: 0.02443580281521593\nSEED: 12, FOLD: 0, EPOCH: 18,train_loss: 0.010715804359727148, valid_loss: 0.021677940604942186\nSEED: 12, FOLD: 0, EPOCH: 19,train_loss: 0.009191560299149241, valid_loss: 0.02197038744177137\nSEED: 12, FOLD: 0, EPOCH: 20,train_loss: 0.007757027174575605, valid_loss: 0.022044757806829043\nSEED: 12, FOLD: 0, EPOCH: 21,train_loss: 0.0067270771208880606, valid_loss: 0.02185909492628915\nSEED: 12, FOLD: 0, EPOCH: 22,train_loss: 0.0061130732216912766, valid_loss: 0.021889898127743175\nSEED: 12, FOLD: 0, EPOCH: 23,train_loss: 0.005792974001741496, valid_loss: 0.021929210584078516\nSEED: 12, FOLD: 0, EPOCH: 24,train_loss: 0.005689191770321433, valid_loss: 0.02194160707294941\nFOLD: 1, EPOCH: 0,train_loss: 0.732361455326495, valid_loss: 0.6946450559531941\nSEED: 12, FOLD: 1, EPOCH: 0,train_loss: 0.4677651445178882, valid_loss: 0.024154821958611992\nSEED: 12, FOLD: 1, EPOCH: 1,train_loss: 0.02179602628060873, valid_loss: 0.020565470187541318\nSEED: 12, FOLD: 1, EPOCH: 2,train_loss: 0.02018133565729511, valid_loss: 0.018934130668640137\nSEED: 12, FOLD: 1, EPOCH: 3,train_loss: 0.018930558047756767, valid_loss: 0.2485311745720751\nSEED: 12, FOLD: 1, EPOCH: 4,train_loss: 0.01809857837666852, valid_loss: 0.01811438355156604\nSEED: 12, FOLD: 1, EPOCH: 5,train_loss: 0.0175492438973616, valid_loss: 0.017938441925627345\nSEED: 12, FOLD: 1, EPOCH: 6,train_loss: 0.017227176401386227, valid_loss: 0.018352012916961136\nSEED: 12, FOLD: 1, EPOCH: 7,train_loss: 0.017024222720900307, valid_loss: 0.018164310604333878\nSEED: 12, FOLD: 1, EPOCH: 8,train_loss: 0.016900107008067593, valid_loss: 0.01796621916925206\nSEED: 12, FOLD: 1, EPOCH: 9,train_loss: 0.01675535105438768, valid_loss: 0.018356933751527\nSEED: 12, FOLD: 1, EPOCH: 10,train_loss: 0.01658344471935129, valid_loss: 0.08381352989989169\nSEED: 12, FOLD: 1, EPOCH: 11,train_loss: 0.01642724724513465, valid_loss: 5.08943894330193\nSEED: 12, FOLD: 1, EPOCH: 12,train_loss: 0.01624340303512155, valid_loss: 0.018114901312133846\nSEED: 12, FOLD: 1, EPOCH: 13,train_loss: 0.015751089077388893, valid_loss: 0.02145543464404695\nSEED: 12, FOLD: 1, EPOCH: 14,train_loss: 0.01532824825414497, valid_loss: 0.01869167042348315\nSEED: 12, FOLD: 1, EPOCH: 15,train_loss: 0.014553074772213247, valid_loss: 0.01908767278141835\nSEED: 12, FOLD: 1, EPOCH: 16,train_loss: 0.01357010080465588, valid_loss: 0.01926856811213143\nSEED: 12, FOLD: 1, EPOCH: 17,train_loss: 0.012278123036620842, valid_loss: 0.019951466470956802\nSEED: 12, FOLD: 1, EPOCH: 18,train_loss: 0.010829970618520958, valid_loss: 0.020655900623430225\nSEED: 12, FOLD: 1, EPOCH: 19,train_loss: 0.009212711873207834, valid_loss: 0.02106564207112088\nSEED: 12, FOLD: 1, EPOCH: 20,train_loss: 0.007809925915511406, valid_loss: 0.02131648706820081\nSEED: 12, FOLD: 1, EPOCH: 21,train_loss: 0.006753960374634767, valid_loss: 0.021255393512547016\nSEED: 12, FOLD: 1, EPOCH: 22,train_loss: 0.006144606734396539, valid_loss: 0.02130179660504355\nSEED: 12, FOLD: 1, EPOCH: 23,train_loss: 0.005834838517172181, valid_loss: 0.021378277417491463\nSEED: 12, FOLD: 1, EPOCH: 24,train_loss: 0.005724574088294437, valid_loss: 0.021384089034708106\nFOLD: 2, EPOCH: 0,train_loss: 0.7324609230034542, valid_loss: 0.6963349308286394\nSEED: 12, FOLD: 2, EPOCH: 0,train_loss: 0.4686042221983636, valid_loss: 0.02447452252464635\nSEED: 12, FOLD: 2, EPOCH: 1,train_loss: 0.02177647086553765, valid_loss: 0.0214470735085862\nSEED: 12, FOLD: 2, EPOCH: 2,train_loss: 0.02038404325118465, valid_loss: 0.019152081065944262\nSEED: 12, FOLD: 2, EPOCH: 3,train_loss: 0.019040395458140513, valid_loss: 0.7243985431534904\nSEED: 12, FOLD: 2, EPOCH: 4,train_loss: 0.01828189157493358, valid_loss: 0.01846380095396723\nSEED: 12, FOLD: 2, EPOCH: 5,train_loss: 0.017769466507772023, valid_loss: 0.01806612562920366\nSEED: 12, FOLD: 2, EPOCH: 6,train_loss: 0.01730285957455635, valid_loss: 0.018168595805764198\nSEED: 12, FOLD: 2, EPOCH: 7,train_loss: 0.017073527155240086, valid_loss: 0.01788580119609833\nSEED: 12, FOLD: 2, EPOCH: 8,train_loss: 0.016812019621151208, valid_loss: 0.018009973370603154\nSEED: 12, FOLD: 2, EPOCH: 9,train_loss: 0.01661318308082375, valid_loss: 0.018168369946735246\nSEED: 12, FOLD: 2, EPOCH: 10,train_loss: 0.01645560811416511, valid_loss: 0.01899857691356114\nSEED: 12, FOLD: 2, EPOCH: 11,train_loss: 0.01625263248400314, valid_loss: 0.018693881322230613\nSEED: 12, FOLD: 2, EPOCH: 12,train_loss: 0.015833383630009464, valid_loss: 0.018394620290824344\nSEED: 12, FOLD: 2, EPOCH: 13,train_loss: 0.015376210885707044, valid_loss: 0.019286624821169034\nSEED: 12, FOLD: 2, EPOCH: 14,train_loss: 0.014687530533240659, valid_loss: 0.01924128931547914\nSEED: 12, FOLD: 2, EPOCH: 15,train_loss: 0.013810347582138803, valid_loss: 0.02970977281885488\nSEED: 12, FOLD: 2, EPOCH: 16,train_loss: 0.0127810501377948, valid_loss: 0.020232919922896792\nSEED: 12, FOLD: 2, EPOCH: 17,train_loss: 0.011425249604848179, valid_loss: 0.020905664616397448\nSEED: 12, FOLD: 2, EPOCH: 18,train_loss: 0.009978649947438797, valid_loss: 0.020956489337342125\nSEED: 12, FOLD: 2, EPOCH: 19,train_loss: 0.008430428000806022, valid_loss: 0.021639488477792058\nSEED: 12, FOLD: 2, EPOCH: 20,train_loss: 0.007184129589012939, valid_loss: 0.02160805282848222\nSEED: 12, FOLD: 2, EPOCH: 21,train_loss: 0.006371409717240256, valid_loss: 0.02161140718630382\nSEED: 12, FOLD: 2, EPOCH: 22,train_loss: 0.005886481738356996, valid_loss: 0.02185679099389485\nSEED: 12, FOLD: 2, EPOCH: 23,train_loss: 0.005645114663362938, valid_loss: 0.02185200218643461\nSEED: 12, FOLD: 2, EPOCH: 24,train_loss: 0.005560232027277459, valid_loss: 0.02183754507984434\nFOLD: 3, EPOCH: 0,train_loss: 0.7320226366105287, valid_loss: 0.6921928191886229\nSEED: 12, FOLD: 3, EPOCH: 0,train_loss: 0.46779889381234196, valid_loss: 0.02396924848503926\nSEED: 12, FOLD: 3, EPOCH: 1,train_loss: 0.021755879987841068, valid_loss: 0.02062623142538702\nSEED: 12, FOLD: 3, EPOCH: 2,train_loss: 0.020378362387418747, valid_loss: 0.01871517607394387\nSEED: 12, FOLD: 3, EPOCH: 3,train_loss: 0.019209109057766804, valid_loss: 0.018129713833332062\nSEED: 12, FOLD: 3, EPOCH: 4,train_loss: 0.01850699673852195, valid_loss: 0.017774180536541867\nSEED: 12, FOLD: 3, EPOCH: 5,train_loss: 0.01807197744188749, valid_loss: 1.5103609160081868\nSEED: 12, FOLD: 3, EPOCH: 6,train_loss: 0.01770140294768456, valid_loss: 0.017780549139441812\nSEED: 12, FOLD: 3, EPOCH: 7,train_loss: 0.017399565384223842, valid_loss: 0.017637729946085635\nSEED: 12, FOLD: 3, EPOCH: 8,train_loss: 0.017143068787898275, valid_loss: 0.017814058563945925\nSEED: 12, FOLD: 3, EPOCH: 9,train_loss: 0.016991642391498106, valid_loss: 0.01786034000927911\nSEED: 12, FOLD: 3, EPOCH: 10,train_loss: 0.016792950409370056, valid_loss: 0.017755042734172416\nSEED: 12, FOLD: 3, EPOCH: 11,train_loss: 0.01658972431703106, valid_loss: 0.018196914098499453\nSEED: 12, FOLD: 3, EPOCH: 12,train_loss: 0.016354084656020437, valid_loss: 0.017951901974704337\nSEED: 12, FOLD: 3, EPOCH: 13,train_loss: 0.01599757249156634, valid_loss: 0.018295290222501055\nSEED: 12, FOLD: 3, EPOCH: 14,train_loss: 0.015562841284048298, valid_loss: 0.036350278430344427\nSEED: 12, FOLD: 3, EPOCH: 15,train_loss: 0.014895707551065994, valid_loss: 0.01863302898538463\nSEED: 12, FOLD: 3, EPOCH: 16,train_loss: 0.013988587121222761, valid_loss: 0.019739267964135197\nSEED: 12, FOLD: 3, EPOCH: 17,train_loss: 0.013055951759705076, valid_loss: 0.01957297927754767\nSEED: 12, FOLD: 3, EPOCH: 18,train_loss: 0.011590054299196472, valid_loss: 0.02018018954378717\nSEED: 12, FOLD: 3, EPOCH: 19,train_loss: 0.010092666669600252, valid_loss: 0.02066900033284636\nSEED: 12, FOLD: 3, EPOCH: 20,train_loss: 0.008592684125608725, valid_loss: 0.020641235086847756\nSEED: 12, FOLD: 3, EPOCH: 21,train_loss: 0.007395321206338163, valid_loss: 0.020641846910995597\nSEED: 12, FOLD: 3, EPOCH: 22,train_loss: 0.006634095579088814, valid_loss: 0.020712270620552933\nSEED: 12, FOLD: 3, EPOCH: 23,train_loss: 0.0062719638648348446, valid_loss: 0.020732754731879514\nSEED: 12, FOLD: 3, EPOCH: 24,train_loss: 0.006122411248962517, valid_loss: 0.020729624721057275\nFOLD: 4, EPOCH: 0,train_loss: 0.7322377349338393, valid_loss: 0.6937794770513263\nSEED: 12, FOLD: 4, EPOCH: 0,train_loss: 0.46930923273474195, valid_loss: 0.02761722542345524\nSEED: 12, FOLD: 4, EPOCH: 1,train_loss: 0.02161625019498985, valid_loss: 0.020949511655739377\nSEED: 12, FOLD: 4, EPOCH: 2,train_loss: 0.019968162515085108, valid_loss: 0.018914590988840376\nSEED: 12, FOLD: 4, EPOCH: 3,train_loss: 0.01887730458737725, valid_loss: 0.018930382068668095\nSEED: 12, FOLD: 4, EPOCH: 4,train_loss: 0.018191211122720347, valid_loss: 0.018375963558043752\nSEED: 12, FOLD: 4, EPOCH: 5,train_loss: 0.017664668877629467, valid_loss: 0.018254486950380462\nSEED: 12, FOLD: 4, EPOCH: 6,train_loss: 0.017318452416110214, valid_loss: 0.018350287792938097\nSEED: 12, FOLD: 4, EPOCH: 7,train_loss: 0.01707741210957731, valid_loss: 0.018421521224081517\nSEED: 12, FOLD: 4, EPOCH: 8,train_loss: 0.016808253094336412, valid_loss: 0.018437035807541437\nSEED: 12, FOLD: 4, EPOCH: 9,train_loss: 0.016611067449035, valid_loss: 0.018432215707642693\nSEED: 12, FOLD: 4, EPOCH: 10,train_loss: 0.01640802351282026, valid_loss: 0.018463919231934207\nSEED: 12, FOLD: 4, EPOCH: 11,train_loss: 0.01622847785806134, valid_loss: 0.01846979231174503\nSEED: 12, FOLD: 4, EPOCH: 12,train_loss: 0.01579591996260803, valid_loss: 0.01855891676885741\nSEED: 12, FOLD: 4, EPOCH: 13,train_loss: 0.015399394203385297, valid_loss: 0.019069398513862065\nSEED: 12, FOLD: 4, EPOCH: 14,train_loss: 0.014833192708120294, valid_loss: 0.01979979851416179\nSEED: 12, FOLD: 4, EPOCH: 15,train_loss: 0.01403734711318338, valid_loss: 0.01946334820240736\nSEED: 12, FOLD: 4, EPOCH: 16,train_loss: 0.013127187613642564, valid_loss: 0.0202020955405065\nSEED: 12, FOLD: 4, EPOCH: 17,train_loss: 0.011868099009033538, valid_loss: 0.020368031625236784\nSEED: 12, FOLD: 4, EPOCH: 18,train_loss: 0.010590603119646111, valid_loss: 0.021070461560572896\nSEED: 12, FOLD: 4, EPOCH: 19,train_loss: 0.009094492321575645, valid_loss: 0.021270112799746648\nSEED: 12, FOLD: 4, EPOCH: 20,train_loss: 0.007848007716646377, valid_loss: 0.02151383337165628\nSEED: 12, FOLD: 4, EPOCH: 21,train_loss: 0.006841976477689769, valid_loss: 0.021390296039836748\nSEED: 12, FOLD: 4, EPOCH: 22,train_loss: 0.006242529281761742, valid_loss: 0.021690383926033972\nSEED: 12, FOLD: 4, EPOCH: 23,train_loss: 0.005966531928547107, valid_loss: 0.021741511193769318\nSEED: 12, FOLD: 4, EPOCH: 24,train_loss: 0.005858231550014584, valid_loss: 0.021779217677456993\nFOLD: 0, EPOCH: 0,train_loss: 0.7341503652109616, valid_loss: 0.6916083523205349\nSEED: 13, FOLD: 0, EPOCH: 0,train_loss: 0.46885210761557455, valid_loss: 0.023505920065300806\nSEED: 13, FOLD: 0, EPOCH: 1,train_loss: 0.021554201530913513, valid_loss: 0.15526099242269992\nSEED: 13, FOLD: 0, EPOCH: 2,train_loss: 0.02012445611636276, valid_loss: 1.4511571609015976\nSEED: 13, FOLD: 0, EPOCH: 3,train_loss: 0.018967209208378757, valid_loss: 0.018626691720315388\nSEED: 13, FOLD: 0, EPOCH: 4,train_loss: 0.018115397880150787, valid_loss: 0.01798219970826592\nSEED: 13, FOLD: 0, EPOCH: 5,train_loss: 0.017633641354631687, valid_loss: 2.9622970189899207\nSEED: 13, FOLD: 0, EPOCH: 6,train_loss: 0.017409014508830034, valid_loss: 0.018551816871123655\nSEED: 13, FOLD: 0, EPOCH: 7,train_loss: 0.017097235832741295, valid_loss: 0.03068288891975369\nSEED: 13, FOLD: 0, EPOCH: 8,train_loss: 0.018110508983279917, valid_loss: 0.01779789961874485\nSEED: 13, FOLD: 0, EPOCH: 9,train_loss: 0.017561957246853388, valid_loss: 0.01795846125377076\nSEED: 13, FOLD: 0, EPOCH: 10,train_loss: 0.01748919625348155, valid_loss: 0.018344249203801156\nSEED: 13, FOLD: 0, EPOCH: 11,train_loss: 0.01730051024587474, valid_loss: 0.5849176131721053\nSEED: 13, FOLD: 0, EPOCH: 12,train_loss: 0.01710341529974687, valid_loss: 0.017897570292864526\nSEED: 13, FOLD: 0, EPOCH: 13,train_loss: 0.016758198080503422, valid_loss: 0.047156026560281006\nSEED: 13, FOLD: 0, EPOCH: 14,train_loss: 0.016614758504041725, valid_loss: 0.01813424200351749\nSEED: 13, FOLD: 0, EPOCH: 15,train_loss: 0.016381159795961088, valid_loss: 0.017992925404437952\nSEED: 13, FOLD: 0, EPOCH: 16,train_loss: 0.01574033269982623, valid_loss: 0.01907834251012121\nSEED: 13, FOLD: 0, EPOCH: 17,train_loss: 0.015146777431979992, valid_loss: 0.018434178616319383\nSEED: 13, FOLD: 0, EPOCH: 18,train_loss: 0.013975373233088118, valid_loss: 0.04917936926441533\nSEED: 13, FOLD: 0, EPOCH: 19,train_loss: 0.012644603376047335, valid_loss: 0.01993991088654314\nSEED: 13, FOLD: 0, EPOCH: 20,train_loss: 0.011048867448192575, valid_loss: 0.020860273843365057\nSEED: 13, FOLD: 0, EPOCH: 21,train_loss: 0.009433431962531979, valid_loss: 0.020371157995292117\nSEED: 13, FOLD: 0, EPOCH: 22,train_loss: 0.00819025376636157, valid_loss: 0.020622178273541587\nSEED: 13, FOLD: 0, EPOCH: 23,train_loss: 0.007504066580609567, valid_loss: 0.020447854857359615\nSEED: 13, FOLD: 0, EPOCH: 24,train_loss: 0.007259132482273423, valid_loss: 0.02070348635315895\nFOLD: 1, EPOCH: 0,train_loss: 0.7342945410721544, valid_loss: 0.6927185339086196\nSEED: 13, FOLD: 1, EPOCH: 0,train_loss: 0.46835445986547763, valid_loss: 0.024526345598347047\nSEED: 13, FOLD: 1, EPOCH: 1,train_loss: 0.02174123290224352, valid_loss: 0.02094060182571411\nSEED: 13, FOLD: 1, EPOCH: 2,train_loss: 0.02038646722887305, valid_loss: 0.01928750704973936\nSEED: 13, FOLD: 1, EPOCH: 3,train_loss: 0.019088329693329506, valid_loss: 0.018674702438361505\nSEED: 13, FOLD: 1, EPOCH: 4,train_loss: 0.018238107518603403, valid_loss: 0.032485337106182295\nSEED: 13, FOLD: 1, EPOCH: 5,train_loss: 0.01783421880606076, valid_loss: 0.018234377562561455\nSEED: 13, FOLD: 1, EPOCH: 6,train_loss: 0.017475016246401312, valid_loss: 0.01804631597855512\nSEED: 13, FOLD: 1, EPOCH: 7,train_loss: 0.017639227987577517, valid_loss: 0.018410709083956832\nSEED: 13, FOLD: 1, EPOCH: 8,train_loss: 0.017336608133400263, valid_loss: 0.018202760695096326\nSEED: 13, FOLD: 1, EPOCH: 9,train_loss: 0.017087800677973723, valid_loss: 0.017954741385491454\nSEED: 13, FOLD: 1, EPOCH: 10,train_loss: 0.01695408693690231, valid_loss: 0.018410378683577564\nSEED: 13, FOLD: 1, EPOCH: 11,train_loss: 0.016749910909034636, valid_loss: 0.01813870991634972\nSEED: 13, FOLD: 1, EPOCH: 12,train_loss: 0.016471877930334944, valid_loss: 0.017998157397789115\nSEED: 13, FOLD: 1, EPOCH: 13,train_loss: 0.016187918554667547, valid_loss: 0.018362691954654807\nSEED: 13, FOLD: 1, EPOCH: 14,train_loss: 0.01580174609451838, valid_loss: 0.018484985784572715\nSEED: 13, FOLD: 1, EPOCH: 15,train_loss: 0.015219228983303343, valid_loss: 0.01872222317273126\nSEED: 13, FOLD: 1, EPOCH: 16,train_loss: 0.014362774694851343, valid_loss: 0.019025766564642683\nSEED: 13, FOLD: 1, EPOCH: 17,train_loss: 0.01323544759762244, valid_loss: 0.01977497136549038\nSEED: 13, FOLD: 1, EPOCH: 18,train_loss: 0.011865536068174719, valid_loss: 0.020268536501509303\nSEED: 13, FOLD: 1, EPOCH: 19,train_loss: 0.010161618202708769, valid_loss: 0.02070902830318493\nSEED: 13, FOLD: 1, EPOCH: 20,train_loss: 0.008541513443587051, valid_loss: 0.021132091553333926\nSEED: 13, FOLD: 1, EPOCH: 21,train_loss: 0.007329892971134488, valid_loss: 0.02125759214601096\nSEED: 13, FOLD: 1, EPOCH: 22,train_loss: 0.006561709969452973, valid_loss: 0.02115940028691993\nSEED: 13, FOLD: 1, EPOCH: 23,train_loss: 0.00616900318140245, valid_loss: 0.0212692123673418\nSEED: 13, FOLD: 1, EPOCH: 24,train_loss: 0.006048765958057365, valid_loss: 0.021318009561475587\nFOLD: 2, EPOCH: 0,train_loss: 0.733751959990764, valid_loss: 0.6894703320094517\nSEED: 13, FOLD: 2, EPOCH: 0,train_loss: 0.46809004499590484, valid_loss: 0.02481204659811088\nSEED: 13, FOLD: 2, EPOCH: 1,train_loss: 0.02164284006247054, valid_loss: 0.02100919442517417\nSEED: 13, FOLD: 2, EPOCH: 2,train_loss: 0.02011655761009973, valid_loss: 0.019134079558508738\nSEED: 13, FOLD: 2, EPOCH: 3,train_loss: 0.018875902376907026, valid_loss: 0.01851346471479961\nSEED: 13, FOLD: 2, EPOCH: 4,train_loss: 0.01809759401594815, valid_loss: 0.017920491046139173\nSEED: 13, FOLD: 2, EPOCH: 5,train_loss: 0.017553042795887028, valid_loss: 0.018082676189286367\nSEED: 13, FOLD: 2, EPOCH: 6,train_loss: 0.01712523495265539, valid_loss: 0.0180830289210592\nSEED: 13, FOLD: 2, EPOCH: 7,train_loss: 0.01687024560743484, valid_loss: 0.01831689854817731\nSEED: 13, FOLD: 2, EPOCH: 8,train_loss: 0.01658146534843937, valid_loss: 0.0182241417201502\nSEED: 13, FOLD: 2, EPOCH: 9,train_loss: 0.016466496748498816, valid_loss: 0.017907651540424143\nSEED: 13, FOLD: 2, EPOCH: 10,train_loss: 0.016117024957539812, valid_loss: 0.017948771880141327\nSEED: 13, FOLD: 2, EPOCH: 11,train_loss: 0.015980293569357498, valid_loss: 0.01824135101799454\nSEED: 13, FOLD: 2, EPOCH: 12,train_loss: 0.015554122734760893, valid_loss: 0.01906460683260645\nSEED: 13, FOLD: 2, EPOCH: 13,train_loss: 0.015015564858913422, valid_loss: 0.018639144061931543\nSEED: 13, FOLD: 2, EPOCH: 14,train_loss: 0.014267351316369099, valid_loss: 0.01943181473761797\nSEED: 13, FOLD: 2, EPOCH: 15,train_loss: 0.013511167231785215, valid_loss: 0.019657184848827974\nSEED: 13, FOLD: 2, EPOCH: 16,train_loss: 0.012392505281267391, valid_loss: 0.020907360714461122\nSEED: 13, FOLD: 2, EPOCH: 17,train_loss: 0.011073326644744131, valid_loss: 0.020829983640994344\nSEED: 13, FOLD: 2, EPOCH: 18,train_loss: 0.009504645549948666, valid_loss: 0.02179013176688126\nSEED: 13, FOLD: 2, EPOCH: 19,train_loss: 0.008118488822483283, valid_loss: 0.021547336424035685\nSEED: 13, FOLD: 2, EPOCH: 20,train_loss: 0.006905387071352722, valid_loss: 0.021850745885499887\nSEED: 13, FOLD: 2, EPOCH: 21,train_loss: 0.006115860194372742, valid_loss: 0.0218600903238569\nSEED: 13, FOLD: 2, EPOCH: 22,train_loss: 0.00566494036330909, valid_loss: 0.022031273879110812\nSEED: 13, FOLD: 2, EPOCH: 23,train_loss: 0.005458411176864436, valid_loss: 0.022011898537831646\nSEED: 13, FOLD: 2, EPOCH: 24,train_loss: 0.00537423442279839, valid_loss: 0.022082758694887163\nFOLD: 3, EPOCH: 0,train_loss: 0.7344892172917833, valid_loss: 0.6947472504207066\nSEED: 13, FOLD: 3, EPOCH: 0,train_loss: 0.4696534418494162, valid_loss: 0.023055298307112285\nSEED: 13, FOLD: 3, EPOCH: 1,train_loss: 0.021829770687614044, valid_loss: 0.020155106538108418\nSEED: 13, FOLD: 3, EPOCH: 2,train_loss: 0.020394011203498735, valid_loss: 0.018506987605776105\nSEED: 13, FOLD: 3, EPOCH: 3,train_loss: 0.019001759724677915, valid_loss: 1598.7223680768693\nSEED: 13, FOLD: 3, EPOCH: 4,train_loss: 0.018278178888080764, valid_loss: 0.017777283010738238\nSEED: 13, FOLD: 3, EPOCH: 5,train_loss: 0.017730885171705353, valid_loss: 0.01755029537848064\nSEED: 13, FOLD: 3, EPOCH: 6,train_loss: 0.017271516130842865, valid_loss: 0.0191005748297487\nSEED: 13, FOLD: 3, EPOCH: 7,train_loss: 0.01701321416146999, valid_loss: 0.018025668311331955\nSEED: 13, FOLD: 3, EPOCH: 8,train_loss: 0.01676488482821597, valid_loss: 0.03259981514087745\nSEED: 13, FOLD: 3, EPOCH: 9,train_loss: 0.01666226538482809, valid_loss: 0.017679542782051222\nSEED: 13, FOLD: 3, EPOCH: 10,train_loss: 0.016466350233467826, valid_loss: 0.01793116708951337\nSEED: 13, FOLD: 3, EPOCH: 11,train_loss: 0.01626424670872027, valid_loss: 0.06459555982479027\nSEED: 13, FOLD: 3, EPOCH: 12,train_loss: 0.01601455612176091, valid_loss: 0.018377577965813022\nSEED: 13, FOLD: 3, EPOCH: 13,train_loss: 0.015611549302337378, valid_loss: 0.018304652108677797\nSEED: 13, FOLD: 3, EPOCH: 14,train_loss: 0.015095890547237256, valid_loss: 0.018441620974668435\nSEED: 13, FOLD: 3, EPOCH: 15,train_loss: 0.014286895044637423, valid_loss: 0.021033574747187752\nSEED: 13, FOLD: 3, EPOCH: 16,train_loss: 0.013299992348808442, valid_loss: 0.019617952991809164\nSEED: 13, FOLD: 3, EPOCH: 17,train_loss: 0.012146971548778297, valid_loss: 0.020118164856519016\nSEED: 13, FOLD: 3, EPOCH: 18,train_loss: 0.010492703625864356, valid_loss: 0.020412255956658295\nSEED: 13, FOLD: 3, EPOCH: 19,train_loss: 0.008945088136778042, valid_loss: 0.020599847579641003\nSEED: 13, FOLD: 3, EPOCH: 20,train_loss: 0.007531597737875515, valid_loss: 0.02080017833837441\nSEED: 13, FOLD: 3, EPOCH: 21,train_loss: 0.006572259222939067, valid_loss: 0.0208320787442582\nSEED: 13, FOLD: 3, EPOCH: 22,train_loss: 0.006025048027182147, valid_loss: 0.02085663540554898\nSEED: 13, FOLD: 3, EPOCH: 23,train_loss: 0.005744664035873474, valid_loss: 0.022263853438198568\nSEED: 13, FOLD: 3, EPOCH: 24,train_loss: 0.005647006288279582, valid_loss: 0.0214276217722467\nFOLD: 4, EPOCH: 0,train_loss: 0.7342814315844627, valid_loss: 0.6911118728773934\nSEED: 13, FOLD: 4, EPOCH: 0,train_loss: 0.4698066651603601, valid_loss: 0.024827335349151065\nSEED: 13, FOLD: 4, EPOCH: 1,train_loss: 0.021494717928614928, valid_loss: 0.9802114013582468\nSEED: 13, FOLD: 4, EPOCH: 2,train_loss: 0.02014751236097221, valid_loss: 0.019538727402687073\nSEED: 13, FOLD: 4, EPOCH: 3,train_loss: 0.018591413097660037, valid_loss: 0.019015181969319072\nSEED: 13, FOLD: 4, EPOCH: 4,train_loss: 0.017864460356696678, valid_loss: 0.018787813984922002\nSEED: 13, FOLD: 4, EPOCH: 5,train_loss: 0.017366006963607603, valid_loss: 0.01876866248037134\nSEED: 13, FOLD: 4, EPOCH: 6,train_loss: 0.017072647286538224, valid_loss: 0.019251027064664025\nSEED: 13, FOLD: 4, EPOCH: 7,train_loss: 0.016825695834836386, valid_loss: 0.018908199721149037\nSEED: 13, FOLD: 4, EPOCH: 8,train_loss: 0.01664711868077734, valid_loss: 0.018646814940231186\nSEED: 13, FOLD: 4, EPOCH: 9,train_loss: 0.016540958396546596, valid_loss: 0.01869129299053124\nSEED: 13, FOLD: 4, EPOCH: 10,train_loss: 0.0163191508257041, valid_loss: 0.018769297056964465\nSEED: 13, FOLD: 4, EPOCH: 11,train_loss: 0.01615393601602664, valid_loss: 0.02743979405079569\nSEED: 13, FOLD: 4, EPOCH: 12,train_loss: 0.01592186657562308, valid_loss: 0.018916206700461253\nSEED: 13, FOLD: 4, EPOCH: 13,train_loss: 0.015578118737542281, valid_loss: 0.029114661791494915\nSEED: 13, FOLD: 4, EPOCH: 14,train_loss: 0.015063289172240417, valid_loss: 0.019757394811936786\nSEED: 13, FOLD: 4, EPOCH: 15,train_loss: 0.014298451017506802, valid_loss: 0.033555325706090246\nSEED: 13, FOLD: 4, EPOCH: 16,train_loss: 0.013345258609548102, valid_loss: 0.020831351993339402\nSEED: 13, FOLD: 4, EPOCH: 17,train_loss: 0.01219596020387907, valid_loss: 0.020983190621648516\nSEED: 13, FOLD: 4, EPOCH: 18,train_loss: 0.010684043563304156, valid_loss: 0.04703924437718732\nSEED: 13, FOLD: 4, EPOCH: 19,train_loss: 0.009093657200544203, valid_loss: 0.02184404746762344\nSEED: 13, FOLD: 4, EPOCH: 20,train_loss: 0.007672240131663797, valid_loss: 0.02231729408460004\nSEED: 13, FOLD: 4, EPOCH: 21,train_loss: 0.00664572334120961, valid_loss: 0.023048236966133118\nSEED: 13, FOLD: 4, EPOCH: 22,train_loss: 0.006032516003797089, valid_loss: 0.023286664805241993\nSEED: 13, FOLD: 4, EPOCH: 23,train_loss: 0.005751190339996867, valid_loss: 0.02359236968415124\nSEED: 13, FOLD: 4, EPOCH: 24,train_loss: 0.005651126085461056, valid_loss: 0.023060465018664086\nFOLD: 0, EPOCH: 0,train_loss: 0.7313291050385737, valid_loss: 0.6970785821185392\nSEED: 14, FOLD: 0, EPOCH: 0,train_loss: 0.4709553116716553, valid_loss: 0.0261268562034649\nSEED: 14, FOLD: 0, EPOCH: 1,train_loss: 0.02154304759333963, valid_loss: 0.021387404488290056\nSEED: 14, FOLD: 0, EPOCH: 2,train_loss: 0.020230451301820038, valid_loss: 0.019402867566575024\nSEED: 14, FOLD: 0, EPOCH: 3,train_loss: 0.018762808023155598, valid_loss: 0.01882704199456117\nSEED: 14, FOLD: 0, EPOCH: 4,train_loss: 0.018152045713656622, valid_loss: 0.018457984305260813\nSEED: 14, FOLD: 0, EPOCH: 5,train_loss: 0.017562206740072674, valid_loss: 0.018335987211150283\nSEED: 14, FOLD: 0, EPOCH: 6,train_loss: 0.0172041746571768, valid_loss: 0.01921738706090871\nSEED: 14, FOLD: 0, EPOCH: 7,train_loss: 0.016994204405911158, valid_loss: 0.01835940367377856\nSEED: 14, FOLD: 0, EPOCH: 8,train_loss: 0.016777882251240637, valid_loss: 0.018149446586475652\nSEED: 14, FOLD: 0, EPOCH: 9,train_loss: 0.0166423961898123, valid_loss: 0.3974163839045693\nSEED: 14, FOLD: 0, EPOCH: 10,train_loss: 0.016556533613660628, valid_loss: 0.0811411609106204\nSEED: 14, FOLD: 0, EPOCH: 11,train_loss: 0.016306181303292946, valid_loss: 0.018277023918926716\nSEED: 14, FOLD: 0, EPOCH: 12,train_loss: 0.016110332770462053, valid_loss: 0.019472993417259526\nSEED: 14, FOLD: 0, EPOCH: 13,train_loss: 0.015627699438482523, valid_loss: 0.01859479655018624\nSEED: 14, FOLD: 0, EPOCH: 14,train_loss: 0.01546139005517614, valid_loss: 0.07584626693278551\nSEED: 14, FOLD: 0, EPOCH: 15,train_loss: 0.014689196920211332, valid_loss: 0.019051613751798868\nSEED: 14, FOLD: 0, EPOCH: 16,train_loss: 0.013780862180705088, valid_loss: 0.019389984992277974\nSEED: 14, FOLD: 0, EPOCH: 17,train_loss: 0.012629652605054604, valid_loss: 0.019728786695529434\nSEED: 14, FOLD: 0, EPOCH: 18,train_loss: 0.011194156624538742, valid_loss: 0.02065971219802604\nSEED: 14, FOLD: 0, EPOCH: 19,train_loss: 0.009608360567548569, valid_loss: 0.020892632248647073\nSEED: 14, FOLD: 0, EPOCH: 20,train_loss: 0.008108447997601352, valid_loss: 0.02132677089642076\nSEED: 14, FOLD: 0, EPOCH: 21,train_loss: 0.006967203337294252, valid_loss: 0.02138323402580093\nSEED: 14, FOLD: 0, EPOCH: 22,train_loss: 0.006234805366240334, valid_loss: 0.022236553623395806\nSEED: 14, FOLD: 0, EPOCH: 23,train_loss: 0.00588745986232939, valid_loss: 0.021789934760069147\nSEED: 14, FOLD: 0, EPOCH: 24,train_loss: 0.005765121261440758, valid_loss: 0.021894743501701775\nFOLD: 1, EPOCH: 0,train_loss: 0.7317494140924329, valid_loss: 0.6941651684897286\nSEED: 14, FOLD: 1, EPOCH: 0,train_loss: 0.4699668441865131, valid_loss: 0.02433066740632057\nSEED: 14, FOLD: 1, EPOCH: 1,train_loss: 0.021819398867605377, valid_loss: 0.021041962876915933\nSEED: 14, FOLD: 1, EPOCH: 2,train_loss: 0.02027396914841485, valid_loss: 0.019300233865422862\nSEED: 14, FOLD: 1, EPOCH: 3,train_loss: 0.019104540959870728, valid_loss: 0.024673176343951907\nSEED: 14, FOLD: 1, EPOCH: 4,train_loss: 0.018330912737950792, valid_loss: 0.018406315759888717\nSEED: 14, FOLD: 1, EPOCH: 5,train_loss: 0.017895956503322524, valid_loss: 0.018407025321253708\nSEED: 14, FOLD: 1, EPOCH: 6,train_loss: 0.01755080146402338, valid_loss: 3.050176441296935\nSEED: 14, FOLD: 1, EPOCH: 7,train_loss: 0.01732130970697116, valid_loss: 0.1012618291590895\nSEED: 14, FOLD: 1, EPOCH: 8,train_loss: 0.01708148835893095, valid_loss: 0.21467867019985404\nSEED: 14, FOLD: 1, EPOCH: 9,train_loss: 0.017055543132778937, valid_loss: 0.018411847949028014\nSEED: 14, FOLD: 1, EPOCH: 10,train_loss: 0.01691860636274745, valid_loss: 0.01842696030757257\nSEED: 14, FOLD: 1, EPOCH: 11,train_loss: 0.01681700378765155, valid_loss: 0.018434226512908936\nSEED: 14, FOLD: 1, EPOCH: 12,train_loss: 0.016547028254037793, valid_loss: 0.018662526298846516\nSEED: 14, FOLD: 1, EPOCH: 13,train_loss: 0.016327099378363494, valid_loss: 0.01838921739586762\nSEED: 14, FOLD: 1, EPOCH: 14,train_loss: 0.01597319777891801, valid_loss: 0.018488743661769797\nSEED: 14, FOLD: 1, EPOCH: 15,train_loss: 0.015483420831661154, valid_loss: 0.019156525044568946\nSEED: 14, FOLD: 1, EPOCH: 16,train_loss: 0.014672752721303136, valid_loss: 0.018775242247751782\nSEED: 14, FOLD: 1, EPOCH: 17,train_loss: 0.013749992332156123, valid_loss: 0.01919696094202144\nSEED: 14, FOLD: 1, EPOCH: 18,train_loss: 0.012482612196655168, valid_loss: 0.019969376921653747\nSEED: 14, FOLD: 1, EPOCH: 19,train_loss: 0.01088267641590677, valid_loss: 0.020247851870954035\nSEED: 14, FOLD: 1, EPOCH: 20,train_loss: 0.009265757566929734, valid_loss: 0.020750543900898526\nSEED: 14, FOLD: 1, EPOCH: 21,train_loss: 0.00787517970876537, valid_loss: 0.02076779564044305\nSEED: 14, FOLD: 1, EPOCH: 22,train_loss: 0.007068606008551199, valid_loss: 0.020844880172184537\nSEED: 14, FOLD: 1, EPOCH: 23,train_loss: 0.006584687756687185, valid_loss: 0.020934238683964525\nSEED: 14, FOLD: 1, EPOCH: 24,train_loss: 0.006418543327327845, valid_loss: 0.020967743332896915\nFOLD: 2, EPOCH: 0,train_loss: 0.731313922698947, valid_loss: 0.6945829619379604\nSEED: 14, FOLD: 2, EPOCH: 0,train_loss: 0.4688597081930957, valid_loss: 0.0239507587188307\nSEED: 14, FOLD: 2, EPOCH: 1,train_loss: 0.02176382434486911, valid_loss: 0.02098674507921233\nSEED: 14, FOLD: 2, EPOCH: 2,train_loss: 0.02046326923089615, valid_loss: 0.01897074786179206\nSEED: 14, FOLD: 2, EPOCH: 3,train_loss: 0.018974272493758926, valid_loss: 0.018253277932458064\nSEED: 14, FOLD: 2, EPOCH: 4,train_loss: 0.018174057671179373, valid_loss: 0.018365469268139673\nSEED: 14, FOLD: 2, EPOCH: 5,train_loss: 0.01762975015394066, valid_loss: 0.018385314985233193\nSEED: 14, FOLD: 2, EPOCH: 6,train_loss: 0.017262686806582453, valid_loss: 0.018087808481034112\nSEED: 14, FOLD: 2, EPOCH: 7,train_loss: 0.017037908715344427, valid_loss: 0.018189066966228625\nSEED: 14, FOLD: 2, EPOCH: 8,train_loss: 0.01686853262177412, valid_loss: 0.017907812068348423\nSEED: 14, FOLD: 2, EPOCH: 9,train_loss: 0.01667305286568792, valid_loss: 0.01828378644388388\nSEED: 14, FOLD: 2, EPOCH: 10,train_loss: 0.0165889414459251, valid_loss: 0.018031504772165242\nSEED: 14, FOLD: 2, EPOCH: 11,train_loss: 0.016430894817239132, valid_loss: 0.01847796722808305\nSEED: 14, FOLD: 2, EPOCH: 12,train_loss: 0.016163689637745636, valid_loss: 0.018542899969307816\nSEED: 14, FOLD: 2, EPOCH: 13,train_loss: 0.015790482308121696, valid_loss: 0.01846770246458404\nSEED: 14, FOLD: 2, EPOCH: 14,train_loss: 0.01522197759291832, valid_loss: 0.019281196846243215\nSEED: 14, FOLD: 2, EPOCH: 15,train_loss: 0.014534975860969744, valid_loss: 0.019199278863037333\nSEED: 14, FOLD: 2, EPOCH: 16,train_loss: 0.013491632119900938, valid_loss: 0.01991509229821317\nSEED: 14, FOLD: 2, EPOCH: 17,train_loss: 0.012278481433842924, valid_loss: 0.02058041950359064\nSEED: 14, FOLD: 2, EPOCH: 18,train_loss: 0.010772193262380535, valid_loss: 0.02079992659170838\nSEED: 14, FOLD: 2, EPOCH: 19,train_loss: 0.009170684329085592, valid_loss: 0.021315546322833088\nSEED: 14, FOLD: 2, EPOCH: 20,train_loss: 0.00777301247285652, valid_loss: 0.021304884048945764\nSEED: 14, FOLD: 2, EPOCH: 21,train_loss: 0.006750732690662793, valid_loss: 0.021416324300362784\nSEED: 14, FOLD: 2, EPOCH: 22,train_loss: 0.006153413982036105, valid_loss: 0.021493532585308832\nSEED: 14, FOLD: 2, EPOCH: 23,train_loss: 0.005862060728469404, valid_loss: 0.021501435953028062\nSEED: 14, FOLD: 2, EPOCH: 24,train_loss: 0.005753985906451725, valid_loss: 0.02147016192183775\nFOLD: 3, EPOCH: 0,train_loss: 0.7312982043210607, valid_loss: 0.6927067262785775\nSEED: 14, FOLD: 3, EPOCH: 0,train_loss: 0.4714075915488231, valid_loss: 0.023695507911699158\nSEED: 14, FOLD: 3, EPOCH: 1,train_loss: 0.021856245265281113, valid_loss: 0.020573904578174863\nSEED: 14, FOLD: 3, EPOCH: 2,train_loss: 0.020342763105448147, valid_loss: 0.018713745474815368\nSEED: 14, FOLD: 3, EPOCH: 3,train_loss: 0.018968100605165437, valid_loss: 0.018396936090929166\nSEED: 14, FOLD: 3, EPOCH: 4,train_loss: 0.018206429470629587, valid_loss: 0.38315227420202325\nSEED: 14, FOLD: 3, EPOCH: 5,train_loss: 0.017725487681527208, valid_loss: 0.018124739878943988\nSEED: 14, FOLD: 3, EPOCH: 6,train_loss: 0.01742253419909164, valid_loss: 0.018294203095138073\nSEED: 14, FOLD: 3, EPOCH: 7,train_loss: 0.017090970405588185, valid_loss: 0.01829650340867894\nSEED: 14, FOLD: 3, EPOCH: 8,train_loss: 0.01701075659153888, valid_loss: 0.01832414636654513\nSEED: 14, FOLD: 3, EPOCH: 9,train_loss: 0.01683233129064532, valid_loss: 0.018439234899623052\nSEED: 14, FOLD: 3, EPOCH: 10,train_loss: 0.016665926651798026, valid_loss: 0.018050335108169488\nSEED: 14, FOLD: 3, EPOCH: 11,train_loss: 0.01659705226112456, valid_loss: 0.018430868163704872\nSEED: 14, FOLD: 3, EPOCH: 12,train_loss: 0.01630558773712085, valid_loss: 0.018339869433215687\nSEED: 14, FOLD: 3, EPOCH: 13,train_loss: 0.016077908347394778, valid_loss: 0.018291040430111545\nSEED: 14, FOLD: 3, EPOCH: 14,train_loss: 0.015614151213671604, valid_loss: 0.018687489043389047\nSEED: 14, FOLD: 3, EPOCH: 15,train_loss: 0.015112441644942673, valid_loss: 0.01895861183958394\nSEED: 14, FOLD: 3, EPOCH: 16,train_loss: 0.014250137503292874, valid_loss: 0.019308367211903845\nSEED: 14, FOLD: 3, EPOCH: 17,train_loss: 0.01313738320974538, valid_loss: 0.02230384834110737\nSEED: 14, FOLD: 3, EPOCH: 18,train_loss: 0.011776570196732552, valid_loss: 0.02059823822762285\nSEED: 14, FOLD: 3, EPOCH: 19,train_loss: 0.010201814455272507, valid_loss: 0.02077763719218118\nSEED: 14, FOLD: 3, EPOCH: 20,train_loss: 0.00864433538658123, valid_loss: 0.021458983634199416\nSEED: 14, FOLD: 3, EPOCH: 21,train_loss: 0.007370569141595251, valid_loss: 0.021250555930393083\nSEED: 14, FOLD: 3, EPOCH: 22,train_loss: 0.006583783500250021, valid_loss: 0.021359015202948025\nSEED: 14, FOLD: 3, EPOCH: 23,train_loss: 0.006181789065853958, valid_loss: 0.02139740266970226\nSEED: 14, FOLD: 3, EPOCH: 24,train_loss: 0.006047224758505603, valid_loss: 0.021400378910558564\nFOLD: 4, EPOCH: 0,train_loss: 0.7312797843104731, valid_loss: 0.6955385293279376\nSEED: 14, FOLD: 4, EPOCH: 0,train_loss: 0.4719326814677376, valid_loss: 0.02372995311660426\nSEED: 14, FOLD: 4, EPOCH: 1,train_loss: 0.02202814090045264, valid_loss: 0.020815184552754676\nSEED: 14, FOLD: 4, EPOCH: 2,train_loss: 0.02061711631062692, valid_loss: 0.018549705243536403\nSEED: 14, FOLD: 4, EPOCH: 3,train_loss: 0.019098036874928614, valid_loss: 0.01841998478131635\nSEED: 14, FOLD: 4, EPOCH: 4,train_loss: 0.018297701638980503, valid_loss: 0.018113120006663458\nSEED: 14, FOLD: 4, EPOCH: 5,train_loss: 0.017812849076831862, valid_loss: 0.017798159005386487\nSEED: 14, FOLD: 4, EPOCH: 6,train_loss: 0.017437810710474958, valid_loss: 0.01774829008749553\nSEED: 14, FOLD: 4, EPOCH: 7,train_loss: 0.01723095358614504, valid_loss: 0.01760220280183213\nSEED: 14, FOLD: 4, EPOCH: 8,train_loss: 0.017047499156944507, valid_loss: 0.017718024578477654\nSEED: 14, FOLD: 4, EPOCH: 9,train_loss: 0.016855999066011748, valid_loss: 0.017762126055146966\nSEED: 14, FOLD: 4, EPOCH: 10,train_loss: 0.01666397419180313, valid_loss: 0.017722907476127148\nSEED: 14, FOLD: 4, EPOCH: 11,train_loss: 0.01641217725908887, valid_loss: 0.018427830189466476\nSEED: 14, FOLD: 4, EPOCH: 12,train_loss: 0.016103874062643433, valid_loss: 0.017981917091778345\nSEED: 14, FOLD: 4, EPOCH: 13,train_loss: 0.01574853093220587, valid_loss: 0.01831941216119698\nSEED: 14, FOLD: 4, EPOCH: 14,train_loss: 0.01524367372430589, valid_loss: 0.01858995370566845\nSEED: 14, FOLD: 4, EPOCH: 15,train_loss: 0.014503229504627903, valid_loss: 0.01865663927580629\nSEED: 14, FOLD: 4, EPOCH: 16,train_loss: 0.013533144060821428, valid_loss: 0.019207461391176496\nSEED: 14, FOLD: 4, EPOCH: 17,train_loss: 0.012232616387416411, valid_loss: 0.020051232618944984\nSEED: 14, FOLD: 4, EPOCH: 18,train_loss: 0.010840061025517265, valid_loss: 0.02036357181412833\nSEED: 14, FOLD: 4, EPOCH: 19,train_loss: 0.009273878040376805, valid_loss: 0.02050760223397187\nSEED: 14, FOLD: 4, EPOCH: 20,train_loss: 0.007896616976762558, valid_loss: 0.020946489753467697\nSEED: 14, FOLD: 4, EPOCH: 21,train_loss: 0.006839986690014166, valid_loss: 0.02105658208685262\nSEED: 14, FOLD: 4, EPOCH: 22,train_loss: 0.006204118197579889, valid_loss: 0.021195130263056073\nSEED: 14, FOLD: 4, EPOCH: 23,train_loss: 0.0058728472914302, valid_loss: 0.021371114892618996\nSEED: 14, FOLD: 4, EPOCH: 24,train_loss: 0.00577606494286961, valid_loss: 0.021365088863032206\nFOLD: 0, EPOCH: 0,train_loss: 0.732853924270964, valid_loss: 0.6908746021134513\nSEED: 15, FOLD: 0, EPOCH: 0,train_loss: 0.4703820264850655, valid_loss: 0.023895102579678806\nSEED: 15, FOLD: 0, EPOCH: 1,train_loss: 0.021796055274070615, valid_loss: 0.02090030796825886\nSEED: 15, FOLD: 0, EPOCH: 2,train_loss: 0.02010626661298919, valid_loss: 0.05813668008361544\nSEED: 15, FOLD: 0, EPOCH: 3,train_loss: 0.01874503320640456, valid_loss: 0.02770452709602458\nSEED: 15, FOLD: 0, EPOCH: 4,train_loss: 0.017983748842656178, valid_loss: 0.018450290762952397\nSEED: 15, FOLD: 0, EPOCH: 5,train_loss: 0.01748367367026797, valid_loss: 0.018607094059033054\nSEED: 15, FOLD: 0, EPOCH: 6,train_loss: 0.017239059212814718, valid_loss: 0.019245426569666182\nSEED: 15, FOLD: 0, EPOCH: 7,train_loss: 0.016932910539372993, valid_loss: 0.018544290134949345\nSEED: 15, FOLD: 0, EPOCH: 8,train_loss: 0.01662508967284956, valid_loss: 0.11058303490281104\nSEED: 15, FOLD: 0, EPOCH: 9,train_loss: 0.01643630283048553, valid_loss: 0.018911058136395046\nSEED: 15, FOLD: 0, EPOCH: 10,train_loss: 0.016186906351116453, valid_loss: 0.01864325555839709\nSEED: 15, FOLD: 0, EPOCH: 11,train_loss: 0.016011726512254156, valid_loss: 0.018880135752260684\nSEED: 15, FOLD: 0, EPOCH: 12,train_loss: 0.01563667541329008, valid_loss: 0.13650714648621423\nSEED: 15, FOLD: 0, EPOCH: 13,train_loss: 0.015143949633640965, valid_loss: 0.019247831430818353\nSEED: 15, FOLD: 0, EPOCH: 14,train_loss: 0.014744918113642366, valid_loss: 0.051748528704047204\nSEED: 15, FOLD: 0, EPOCH: 15,train_loss: 0.0139483505873567, valid_loss: 0.020008235637630736\nSEED: 15, FOLD: 0, EPOCH: 16,train_loss: 0.012914217124781469, valid_loss: 0.020849377076540675\nSEED: 15, FOLD: 0, EPOCH: 17,train_loss: 0.011697260560943697, valid_loss: 0.021040397456714086\nSEED: 15, FOLD: 0, EPOCH: 18,train_loss: 0.010254957808358391, valid_loss: 0.021490539450730595\nSEED: 15, FOLD: 0, EPOCH: 19,train_loss: 0.00878276408099345, valid_loss: 0.0218735968960183\nSEED: 15, FOLD: 0, EPOCH: 20,train_loss: 0.007502691439577263, valid_loss: 0.021991866773792675\nSEED: 15, FOLD: 0, EPOCH: 21,train_loss: 0.006556910843364078, valid_loss: 0.022030578766550336\nSEED: 15, FOLD: 0, EPOCH: 22,train_loss: 0.00598962597181871, valid_loss: 0.02209091553730624\nSEED: 15, FOLD: 0, EPOCH: 23,train_loss: 0.005723808640546172, valid_loss: 0.021960529844675745\nSEED: 15, FOLD: 0, EPOCH: 24,train_loss: 0.005632635454110203, valid_loss: 0.022034477069973947\n********************\nFlops for KAN: 79861586\n********************\nFOLD: 1, EPOCH: 0,train_loss: 0.7327966893064803, valid_loss: 0.6962387050901141\nSEED: 15, FOLD: 1, EPOCH: 0,train_loss: 0.4685254128838795, valid_loss: 0.024372472826923643\nSEED: 15, FOLD: 1, EPOCH: 1,train_loss: 0.021724802954797295, valid_loss: 0.02129281328192779\nSEED: 15, FOLD: 1, EPOCH: 2,train_loss: 0.02050999279363432, valid_loss: 0.019284749403595924\nSEED: 15, FOLD: 1, EPOCH: 3,train_loss: 0.01900705858471169, valid_loss: 0.7408877256991607\nSEED: 15, FOLD: 1, EPOCH: 4,train_loss: 0.018164313958444887, valid_loss: 0.031220802425273825\nSEED: 15, FOLD: 1, EPOCH: 5,train_loss: 0.017676165712106486, valid_loss: 0.11598063483834267\nSEED: 15, FOLD: 1, EPOCH: 6,train_loss: 0.01753459393006304, valid_loss: 0.06530323076461042\nSEED: 15, FOLD: 1, EPOCH: 7,train_loss: 0.017098517629547394, valid_loss: 0.020117821358144283\nSEED: 15, FOLD: 1, EPOCH: 8,train_loss: 0.017039363771892975, valid_loss: 0.018347351253032683\nSEED: 15, FOLD: 1, EPOCH: 9,train_loss: 0.017045458259087973, valid_loss: 0.017993365600705146\nSEED: 15, FOLD: 1, EPOCH: 10,train_loss: 0.016632288194976856, valid_loss: 0.0186868249305657\nSEED: 15, FOLD: 1, EPOCH: 11,train_loss: 0.01653791153533519, valid_loss: 0.01901542650801795\nSEED: 15, FOLD: 1, EPOCH: 12,train_loss: 0.01639245950576404, valid_loss: 0.08199120504515511\nSEED: 15, FOLD: 1, EPOCH: 13,train_loss: 0.015810195154146008, valid_loss: 0.02733702707503523\nSEED: 15, FOLD: 1, EPOCH: 14,train_loss: 0.01544779411557576, valid_loss: 0.01924160434199231\nSEED: 15, FOLD: 1, EPOCH: 15,train_loss: 0.015008592964622421, valid_loss: 0.019023021310567857\nSEED: 15, FOLD: 1, EPOCH: 16,train_loss: 0.013866506543928299, valid_loss: 0.019831506269318715\nSEED: 15, FOLD: 1, EPOCH: 17,train_loss: 0.012840112536281778, valid_loss: 0.02076283996658666\nSEED: 15, FOLD: 1, EPOCH: 18,train_loss: 0.011882662881111753, valid_loss: 0.0358139192951577\nSEED: 15, FOLD: 1, EPOCH: 19,train_loss: 0.010067109909394512, valid_loss: 0.02089689459119524\nSEED: 15, FOLD: 1, EPOCH: 20,train_loss: 0.008646965165204112, valid_loss: 0.020851607035313333\nSEED: 15, FOLD: 1, EPOCH: 21,train_loss: 0.007611091366793582, valid_loss: 0.021138144976326396\nSEED: 15, FOLD: 1, EPOCH: 22,train_loss: 0.006866674374222108, valid_loss: 0.021274537539907865\nSEED: 15, FOLD: 1, EPOCH: 23,train_loss: 0.00661566285956381, valid_loss: 0.021365726313420704\nSEED: 15, FOLD: 1, EPOCH: 24,train_loss: 0.006415522174801731, valid_loss: 0.021335491271955626\n********************\nFlops for KAN: 79861586\n********************\nFOLD: 2, EPOCH: 0,train_loss: 0.7327543980833413, valid_loss: 0.6931267293060527\nSEED: 15, FOLD: 2, EPOCH: 0,train_loss: 0.46899701509138814, valid_loss: 0.024145566255730742\nSEED: 15, FOLD: 2, EPOCH: 1,train_loss: 0.0217925817773178, valid_loss: 0.020167226793573183\nSEED: 15, FOLD: 2, EPOCH: 2,train_loss: 0.020372329914159534, valid_loss: 0.01862372019711663\nSEED: 15, FOLD: 2, EPOCH: 3,train_loss: 0.01901747849162506, valid_loss: 0.8376745704342338\nSEED: 15, FOLD: 2, EPOCH: 4,train_loss: 0.018245438370259777, valid_loss: 0.01783121341620298\nSEED: 15, FOLD: 2, EPOCH: 5,train_loss: 0.01772556696222096, valid_loss: 0.01777869397226502\nSEED: 15, FOLD: 2, EPOCH: 6,train_loss: 0.01738404217378601, valid_loss: 0.018212053924798965\nSEED: 15, FOLD: 2, EPOCH: 7,train_loss: 0.01706749338494695, valid_loss: 0.017805463278337437\nSEED: 15, FOLD: 2, EPOCH: 8,train_loss: 0.016833935493090445, valid_loss: 0.017856796546017423\nSEED: 15, FOLD: 2, EPOCH: 9,train_loss: 0.016647158744002598, valid_loss: 0.017901079975725973\nSEED: 15, FOLD: 2, EPOCH: 10,train_loss: 0.016444454617474392, valid_loss: 0.017862669904442394\nSEED: 15, FOLD: 2, EPOCH: 11,train_loss: 0.016247192417959803, valid_loss: 0.017974411000442857\nSEED: 15, FOLD: 2, EPOCH: 12,train_loss: 0.015861604713659355, valid_loss: 0.018149027683059957\nSEED: 15, FOLD: 2, EPOCH: 13,train_loss: 0.015519906375287235, valid_loss: 0.0182784414740608\nSEED: 15, FOLD: 2, EPOCH: 14,train_loss: 0.014905180289423552, valid_loss: 0.01908759827561238\nSEED: 15, FOLD: 2, EPOCH: 15,train_loss: 0.014141458869520306, valid_loss: 0.019410622032249674\nSEED: 15, FOLD: 2, EPOCH: 16,train_loss: 0.013034436446817024, valid_loss: 0.01959174674223451\nSEED: 15, FOLD: 2, EPOCH: 17,train_loss: 0.011691236483823994, valid_loss: 0.020453304600189712\nSEED: 15, FOLD: 2, EPOCH: 18,train_loss: 0.01027188486541095, valid_loss: 0.020755814717096442\nSEED: 15, FOLD: 2, EPOCH: 19,train_loss: 0.00883964105995129, valid_loss: 0.021079075577504495\nSEED: 15, FOLD: 2, EPOCH: 20,train_loss: 0.007495696933103212, valid_loss: 0.02098285686224699\nSEED: 15, FOLD: 2, EPOCH: 21,train_loss: 0.006567227644035997, valid_loss: 0.021034129950053552\nSEED: 15, FOLD: 2, EPOCH: 22,train_loss: 0.00603464285613618, valid_loss: 0.02119367492987829\nSEED: 15, FOLD: 2, EPOCH: 23,train_loss: 0.0057464258752061405, valid_loss: 0.021192925105638364\nSEED: 15, FOLD: 2, EPOCH: 24,train_loss: 0.005642125437009162, valid_loss: 0.02120879922500428\n********************\nFlops for KAN: 79861586\n********************\nFOLD: 3, EPOCH: 0,train_loss: 0.7333144480767457, valid_loss: 0.6933097669056484\nSEED: 15, FOLD: 3, EPOCH: 0,train_loss: 0.4691204473214305, valid_loss: 0.024628212515796933\nSEED: 15, FOLD: 3, EPOCH: 1,train_loss: 0.021604814998589565, valid_loss: 0.02441108136304787\nSEED: 15, FOLD: 3, EPOCH: 2,train_loss: 0.020470389846604372, valid_loss: 2.6349539279937746\nSEED: 15, FOLD: 3, EPOCH: 3,train_loss: 0.019339689478764067, valid_loss: 0.041217189388615745\nSEED: 15, FOLD: 3, EPOCH: 4,train_loss: 0.018349861402226532, valid_loss: 0.07637429982423782\nSEED: 15, FOLD: 3, EPOCH: 5,train_loss: 0.017728994256290403, valid_loss: 0.1116424777678081\nSEED: 15, FOLD: 3, EPOCH: 6,train_loss: 0.017391013393205576, valid_loss: 4.263326590401785\nSEED: 15, FOLD: 3, EPOCH: 7,train_loss: 0.017239901240564126, valid_loss: 85.78443875994002\nSEED: 15, FOLD: 3, EPOCH: 8,train_loss: 0.017114031560503055, valid_loss: 0.01819236661706652\nSEED: 15, FOLD: 3, EPOCH: 9,train_loss: 0.016962542090618957, valid_loss: 0.022950983739324977\nSEED: 15, FOLD: 3, EPOCH: 10,train_loss: 0.01747804901063226, valid_loss: 0.01924247198871204\nSEED: 15, FOLD: 3, EPOCH: 11,train_loss: 0.01799660012719856, valid_loss: 0.07617199319813933\nSEED: 15, FOLD: 3, EPOCH: 12,train_loss: 0.017287679212302832, valid_loss: 0.018081847578287125\nSEED: 15, FOLD: 3, EPOCH: 13,train_loss: 0.016924407339884318, valid_loss: 0.018854658624955587\nSEED: 15, FOLD: 3, EPOCH: 14,train_loss: 0.016551765795473173, valid_loss: 0.018173928505608013\nSEED: 15, FOLD: 3, EPOCH: 15,train_loss: 0.01607904853164286, valid_loss: 0.01954389911677156\nSEED: 15, FOLD: 3, EPOCH: 16,train_loss: 0.018848140710505886, valid_loss: 0.01826825940183231\nSEED: 15, FOLD: 3, EPOCH: 17,train_loss: 0.017766645866567673, valid_loss: 0.024245940042393548\nSEED: 15, FOLD: 3, EPOCH: 18,train_loss: 0.017308615525995476, valid_loss: 0.3761314548019852\nSEED: 15, FOLD: 3, EPOCH: 19,train_loss: 0.01681835510754499, valid_loss: 0.0719799418002367\nSEED: 15, FOLD: 3, EPOCH: 20,train_loss: 0.016237521267401567, valid_loss: 0.020376807451248168\nSEED: 15, FOLD: 3, EPOCH: 21,train_loss: 0.01575708443271941, valid_loss: 0.01788608841598034\nSEED: 15, FOLD: 3, EPOCH: 22,train_loss: 0.015206373229190924, valid_loss: 0.018264125872935567\nSEED: 15, FOLD: 3, EPOCH: 23,train_loss: 0.015177560531520758, valid_loss: 0.018558399538908685\nSEED: 15, FOLD: 3, EPOCH: 24,train_loss: 0.014734432128244553, valid_loss: 0.018084353634289334\n********************\nFlops for KAN: 79861586\n********************\nFOLD: 4, EPOCH: 0,train_loss: 0.7328753618226536, valid_loss: 0.6962228757994515\nSEED: 15, FOLD: 4, EPOCH: 0,train_loss: 0.4690556855791289, valid_loss: 0.024685083276459147\nSEED: 15, FOLD: 4, EPOCH: 1,train_loss: 0.02161588834301717, valid_loss: 0.02084254047700337\nSEED: 15, FOLD: 4, EPOCH: 2,train_loss: 0.020244594082992146, valid_loss: 0.02211659571954182\nSEED: 15, FOLD: 4, EPOCH: 3,train_loss: 0.01898988267487806, valid_loss: 0.019135336365018574\nSEED: 15, FOLD: 4, EPOCH: 4,train_loss: 0.018153465379947338, valid_loss: 2.4711254970569696\nSEED: 15, FOLD: 4, EPOCH: 5,train_loss: 0.017688835120719414, valid_loss: 0.018146043430481637\nSEED: 15, FOLD: 4, EPOCH: 6,train_loss: 0.01728920410454705, valid_loss: 0.18766378611326218\nSEED: 15, FOLD: 4, EPOCH: 7,train_loss: 0.01715451723261588, valid_loss: 0.01791319644876889\nSEED: 15, FOLD: 4, EPOCH: 8,train_loss: 0.017118184786775837, valid_loss: 0.017815337516367435\nSEED: 15, FOLD: 4, EPOCH: 9,train_loss: 0.0169897665526124, valid_loss: 0.05334144913192306\nSEED: 15, FOLD: 4, EPOCH: 10,train_loss: 0.016898227855563164, valid_loss: 0.01855624584215028\nSEED: 15, FOLD: 4, EPOCH: 11,train_loss: 0.01678381902773095, valid_loss: 0.018144600492502962\nSEED: 15, FOLD: 4, EPOCH: 12,train_loss: 0.01657626889916002, valid_loss: 0.018317357370895997\nSEED: 15, FOLD: 4, EPOCH: 13,train_loss: 0.01637305521770664, valid_loss: 0.017923077701457908\nSEED: 15, FOLD: 4, EPOCH: 14,train_loss: 0.015989571776025106, valid_loss: 0.018263407237827777\nSEED: 15, FOLD: 4, EPOCH: 15,train_loss: 0.015406819539603548, valid_loss: 0.02138844278774091\nSEED: 15, FOLD: 4, EPOCH: 16,train_loss: 0.014759757515528927, valid_loss: 0.018821293408317227\nSEED: 15, FOLD: 4, EPOCH: 17,train_loss: 0.013915257703890835, valid_loss: 0.019125611734177386\nSEED: 15, FOLD: 4, EPOCH: 18,train_loss: 0.012942031538788822, valid_loss: 0.01949331010026591\nSEED: 15, FOLD: 4, EPOCH: 19,train_loss: 0.011216632839616226, valid_loss: 0.01973622984119824\nSEED: 15, FOLD: 4, EPOCH: 20,train_loss: 0.009509906125511381, valid_loss: 0.020310549278344428\nSEED: 15, FOLD: 4, EPOCH: 21,train_loss: 0.008162212706562401, valid_loss: 0.020638160301106316\nSEED: 15, FOLD: 4, EPOCH: 22,train_loss: 0.007220611934536609, valid_loss: 0.02070938747908388\nSEED: 15, FOLD: 4, EPOCH: 23,train_loss: 0.006715558168977715, valid_loss: 0.020804265833326747\nSEED: 15, FOLD: 4, EPOCH: 24,train_loss: 0.0065243013128908215, valid_loss: 0.02084932949926172\n********************\nFlops for KAN: 79861586\n********************\n0.01723039259304107\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"SEED = [0, 1, 2, 3 ,4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\ninput_dir = '../input/lish-moa/'\n\nsc_dic = {}\nfeat_dic = {}\ntrain_features = pd.read_csv(input_dir+'train_features.csv')\ntrain_targets_scored = pd.read_csv(input_dir+'train_targets_scored.csv')\ntrain_targets_nonscored = pd.read_csv(input_dir+'train_targets_nonscored.csv')\ntest_features = pd.read_csv(input_dir+'test_features.csv')\nsample_submission = pd.read_csv(input_dir+'sample_submission.csv')\ntrain_drug = pd.read_csv(input_dir+'train_drug.csv')\n\ntarget_cols = train_targets_scored.drop('sig_id', axis=1).columns.values.tolist()\ntarget_nonsc_cols = train_targets_nonscored.drop('sig_id', axis=1).columns.values.tolist()\n\n######## non-score ########\nnonctr_id = train_features.loc[train_features['cp_type']!='ctl_vehicle','sig_id'].tolist()\ntmp_con1 = [i in nonctr_id for i in train_targets_scored['sig_id']]\nmat_cor = pd.DataFrame(np.corrcoef(train_targets_scored.drop('sig_id',axis = 1)[tmp_con1].T,\n                      train_targets_nonscored.drop('sig_id',axis = 1)[tmp_con1].T))\nmat_cor2 = mat_cor.iloc[(train_targets_scored.shape[1]-1):,0:train_targets_scored.shape[1]-1]\nmat_cor2.index = target_nonsc_cols\nmat_cor2.columns = target_cols\nmat_cor2 = mat_cor2.dropna()\nmat_cor2_max = mat_cor2.abs().max(axis = 1)\n\nq_n_cut = 0.9\ntarget_nonsc_cols2 = mat_cor2_max[mat_cor2_max > np.quantile(mat_cor2_max,q_n_cut)].index.tolist()\nprint(len(target_nonsc_cols2))\n\nGENES = [col for col in train_features.columns if col.startswith('g-')]\nCELLS = [col for col in train_features.columns if col.startswith('c-')]\nfeat_dic['gene'] = GENES\nfeat_dic['cell'] = CELLS\n\n# sample norm \nq2 = train_features[feat_dic['gene']].apply(np.quantile,axis = 1,q = 0.25).copy()\nq7 = train_features[feat_dic['gene']].apply(np.quantile,axis = 1,q = 0.75).copy()\nqmean = (q2+q7)/2\ntrain_features[feat_dic['gene']] = (train_features[feat_dic['gene']].T - qmean.values).T\nq2 = test_features[feat_dic['gene']].apply(np.quantile,axis = 1,q = 0.25).copy()\nq7 = test_features[feat_dic['gene']].apply(np.quantile,axis = 1,q = 0.75).copy()\nqmean = (q2+q7)/2\ntest_features[feat_dic['gene']] = (test_features[feat_dic['gene']].T - qmean.values).T\n\nq2 = train_features[feat_dic['cell']].apply(np.quantile,axis = 1,q = 0.25).copy()\nq7 = train_features[feat_dic['cell']].apply(np.quantile,axis = 1,q = 0.72).copy()\nqmean = (q2+q7)/2\ntrain_features[feat_dic['cell']] = (train_features[feat_dic['cell']].T - qmean.values).T\nqmean2 = train_features[feat_dic['cell']].abs().apply(np.quantile,axis = 1,q = 0.75).copy()+4\ntrain_features[feat_dic['cell']] = (train_features[feat_dic['cell']].T / qmean2.values).T.copy()\n\nq2 = test_features[feat_dic['cell']].apply(np.quantile,axis = 1,q = 0.25).copy()\nq7 = test_features[feat_dic['cell']].apply(np.quantile,axis = 1,q = 0.72).copy()\nqmean = (q2+q7)/2\ntest_features[feat_dic['cell']] = (test_features[feat_dic['cell']].T - qmean.values).T\nqmean2 = test_features[feat_dic['cell']].abs().apply(np.quantile,axis = 1,q = 0.75).copy()+4\ntest_features[feat_dic['cell']] = (test_features[feat_dic['cell']].T / qmean2.values).T.copy()\n\n# remove ctl\ntrain = train_features.merge(train_targets_scored, on='sig_id')\ntrain = train.merge(train_targets_nonscored[['sig_id']+target_nonsc_cols2], on='sig_id')\n\ntrain = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\ntest = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n\ntarget = train[['sig_id']+target_cols]\ntarget_ns = train[['sig_id']+target_nonsc_cols2]\n\ntrain0 = train.drop('cp_type', axis=1)\ntest = test.drop('cp_type', axis=1)\n\ntarget_cols = target.drop('sig_id', axis=1).columns.values.tolist()\n\n# drug ids\ntar_sig = target['sig_id'].tolist()\ntrain_drug = train_drug.loc[[i in tar_sig for i in train_drug['sig_id']]]\ntarget = target.merge(train_drug, on='sig_id', how='left') \nt does it mean when you're body doesn't change and you're fried after your workouts?\n# LOCATE DRUGS\nvc = train_drug.drug_id.value_counts()\nvc1 = vc.loc[vc <= 19].index\nvc2 = vc.loc[vc > 19].index\n\nfeature_cols = []\nfor key_i in feat_dic.keys():\n    value_i = feat_dic[key_i]\n    print(key_i,len(value_i))\n    feature_cols += value_i\nlen(feature_cols)\nfeature_cols0 = dp(feature_cols)\n    \noof = np.zeros((len(train), len(target_cols)))\npredictions = np.zeros((len(test), len(target_cols)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T07:03:00.436161Z","iopub.execute_input":"2025-01-16T07:03:00.436463Z","iopub.status.idle":"2025-01-16T07:03:31.035528Z","shell.execute_reply.started":"2025-01-16T07:03:00.436436Z","shell.execute_reply":"2025-01-16T07:03:31.034502Z"}},"outputs":[{"name":"stdout","text":"33\nObject `workouts` not found.\ngene 772\ncell 100\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"\n# Averaging on multiple SEEDS\nfor seed in SEED:\n\n    seed_everything(seed=seed)\n    folds = train0.copy()\n    feature_cols = dp(feature_cols0)\n    \n    # kfold - leave drug out\n    target2 = target.copy()\n    dct1 = {}; dct2 = {}\n    skf = MultilabelStratifiedKFold(n_splits = 5) # , shuffle = True, random_state = seed\n    tmp = target2.groupby('drug_id')[target_cols].mean().loc[vc1]\n    tmp_idx = tmp.index.tolist()\n    tmp_idx.sort()\n    tmp_idx2 = random.sample(tmp_idx,len(tmp_idx))\n    tmp = tmp.loc[tmp_idx2]\n    for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[target_cols])):\n        dd = {k:fold for k in tmp.index[idxV].values}\n        dct1.update(dd)\n\n    # STRATIFY DRUGS MORE THAN 19X\n    skf = MultilabelStratifiedKFold(n_splits = 5) # , shuffle = True, random_state = seed\n    tmp = target2.loc[target2.drug_id.isin(vc2)].reset_index(drop = True)\n    tmp_idx = tmp.index.tolist()\n    tmp_idx.sort()\n    tmp_idx2 = random.sample(tmp_idx,len(tmp_idx))\n    tmp = tmp.loc[tmp_idx2]\n    for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[target_cols])):\n        dd = {k:fold for k in tmp.sig_id[idxV].values}\n        dct2.update(dd)\n\n    target2['kfold'] = target2.drug_id.map(dct1)\n    target2.loc[target2.kfold.isna(),'kfold'] = target2.loc[target2.kfold.isna(),'sig_id'].map(dct2)\n    target2.kfold = target2.kfold.astype(int)\n\n    folds['kfold'] = target2['kfold'].copy()\n\n    train = folds.copy()\n    test_ = test.copy()\n\n    # HyperParameters\n    DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n    EPOCHS = 25\n    BATCH_SIZE = 128\n    LEARNING_RATE = 1e-3\n    WEIGHT_DECAY = 1e-5\n    NFOLDS = 5\n    EARLY_STOPPING_STEPS = 10\n    EARLY_STOP = False\n\n    n_comp1 = 50\n    n_comp2 = 15\n\n    num_features=len(feature_cols) + n_comp1 + n_comp2\n    num_targets=len(target_cols)\n    num_targets_0=len(target_nonsc_cols2)\n    hidden_size=4096\n\n    tar_freq = np.array([np.min(list(g_table(train[target_cols].iloc[:,i]).values())) for i in range(len(target_cols))])\n    tar_weight0 = np.array([np.log(i+100) for i in tar_freq])\n    tar_weight0_min = dp(np.min(tar_weight0))\n    tar_weight = tar_weight0_min/tar_weight0\n    pos_weight = torch.tensor(tar_weight).to(DEVICE)\n    from torch.nn.modules.loss import _WeightedLoss\n    class SmoothBCEwLogits(_WeightedLoss):\n        def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n            super().__init__(weight=weight, reduction=reduction)\n            self.smoothing = smoothing\n            self.weight = weight\n            self.reduction = reduction\n\n        @staticmethod\n        def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n            assert 0 <= smoothing < 1\n            with torch.no_grad():\n                targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n            return targets\n\n        def forward(self, inputs, targets):\n            targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n                self.smoothing)\n            loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight,\n                                                      pos_weight = pos_weight)\n\n            if  self.reduction == 'sum':\n                loss = loss.sum()\n            elif  self.reduction == 'mean':\n                loss = loss.mean()\n\n            return loss\n\n    class TrainDataset:\n        def __init__(self, features, targets):\n            self.features = features\n            self.targets = targets\n\n        def __len__(self):\n            return (self.features.shape[0])\n\n        def __getitem__(self, idx):\n            dct = {\n                'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n                'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n            }\n            return dct\n\n    class TestDataset:\n        def __init__(self, features):\n            self.features = features\n\n        def __len__(self):\n            return (self.features.shape[0])\n\n        def __getitem__(self, idx):\n            dct = {\n                'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n            }\n            return dct\n\n\n    def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n        model.train()\n        final_loss = 0\n\n        for data in dataloader:\n            optimizer.zero_grad()\n            inputs, targets = data['x'].to(device), data['y'].to(device)\n            outputs = model(inputs)\n            loss = loss_fn(outputs, targets)\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n\n            final_loss += loss.item()\n\n        final_loss /= len(dataloader)\n\n        return final_loss\n\n\n    def valid_fn(model, loss_fn, dataloader, device):\n        model.eval()\n        final_loss = 0\n        valid_preds = []\n\n        for data in dataloader:\n            inputs, targets = data['x'].to(device), data['y'].to(device)\n            outputs = model(inputs)\n            loss = loss_fn(outputs, targets)\n\n            final_loss += loss.item()\n            valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n\n        final_loss /= len(dataloader)\n        valid_preds = np.concatenate(valid_preds)\n\n        return final_loss, valid_preds\n\n    def inference_fn(model, dataloader, device):\n        model.eval()\n        preds = []\n\n        for data in dataloader:\n            inputs = data['x'].to(device)\n            with torch.no_grad():\n                outputs = model(inputs)\n\n            preds.append(outputs.sigmoid().detach().cpu().numpy())\n\n        preds = np.concatenate(preds)\n\n        return preds\n\n    class Model(nn.Module):\n        def __init__(self, num_features, num_targets, hidden_size):\n            super(Model, self).__init__()\n            cha_1 = 256\n            cha_2 = 512\n            cha_3 = 512\n\n            cha_1_reshape = int(hidden_size/cha_1)\n            cha_po_1 = int(hidden_size/cha_1/2)\n            cha_po_2 = int(hidden_size/cha_1/2/2) * cha_3\n\n            self.cha_1 = cha_1\n            self.cha_2 = cha_2\n            self.cha_3 = cha_3\n            self.cha_1_reshape = cha_1_reshape\n            self.cha_po_1 = cha_po_1\n            self.cha_po_2 = cha_po_2\n\n            self.batch_norm1 = nn.BatchNorm1d(num_features)\n            self.dropout1 = nn.Dropout(0.1)\n            self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n\n            self.batch_norm_c1 = nn.BatchNorm1d(cha_1)\n            self.dropout_c1 = nn.Dropout(0.1)\n            self.conv1 = nn.utils.weight_norm(nn.Conv1d(cha_1,cha_2, kernel_size = 5, stride = 1, padding=2,  bias=False),dim=None)\n\n            self.ave_po_c1 = nn.AdaptiveAvgPool1d(output_size = cha_po_1)\n\n            self.batch_norm_c2 = nn.BatchNorm1d(cha_2)\n            self.dropout_c2 = nn.Dropout(0.1)\n            self.conv2 = nn.utils.weight_norm(nn.Conv1d(cha_2,cha_2, kernel_size = 3, stride = 1, padding=1, bias=True),dim=None)\n\n            self.batch_norm_c2_1 = nn.BatchNorm1d(cha_2)\n            self.dropout_c2_1 = nn.Dropout(0.3)\n            self.conv2_1 = nn.utils.weight_norm(nn.Conv1d(cha_2,cha_2, kernel_size = 3, stride = 1, padding=1, bias=True),dim=None)\n\n            self.batch_norm_c2_2 = nn.BatchNorm1d(cha_2)\n            self.dropout_c2_2 = nn.Dropout(0.2)\n            self.conv2_2 = nn.utils.weight_norm(nn.Conv1d(cha_2,cha_3, kernel_size = 5, stride = 1, padding=2, bias=True),dim=None)\n\n            self.max_po_c2 = nn.MaxPool1d(kernel_size=4, stride=2, padding=1)\n\n            self.flt = nn.Flatten()\n\n            self.batch_norm3 = nn.BatchNorm1d(cha_po_2)\n            self.dropout3 = nn.Dropout(0.2)\n            self.dense3 = nn.utils.weight_norm(nn.Linear(cha_po_2, num_targets))\n\n        def forward(self, x):\n\n            x = self.batch_norm1(x)\n            x = self.dropout1(x)\n            x = F.celu(self.dense1(x), alpha=0.06)\n\n            x = x.reshape(x.shape[0],self.cha_1,\n                          self.cha_1_reshape)\n\n            x = self.batch_norm_c1(x)\n            x = self.dropout_c1(x)\n            x = F.relu(self.conv1(x))\n\n            x = self.ave_po_c1(x)\n\n            x = self.batch_norm_c2(x)\n            x = self.dropout_c2(x)\n            x = F.relu(self.conv2(x))\n            x_s = x\n\n            x = self.batch_norm_c2_1(x)\n            x = self.dropout_c2_1(x)\n            x = F.relu(self.conv2_1(x))\n\n            x = self.batch_norm_c2_2(x)\n            x = self.dropout_c2_2(x)\n            x = F.relu(self.conv2_2(x))\n            x =  x * x_s\n\n            x = self.max_po_c2(x)\n\n            x = self.flt(x)\n\n            x = self.batch_norm3(x)\n            x = self.dropout3(x)\n            x = self.dense3(x)\n\n            return x\n\n\n    def run_training(fold, seed):\n\n        seed_everything(seed)\n\n        trn_idx = train[train['kfold'] != fold].index\n        val_idx = train[train['kfold'] == fold].index\n\n        train_df = train[train['kfold'] != fold].reset_index(drop=True).copy()\n        valid_df = train[train['kfold'] == fold].reset_index(drop=True).copy()\n\n        x_train, y_train,y_train_ns = train_df[feature_cols], train_df[target_cols].values,train_df[target_nonsc_cols2].values\n        x_valid, y_valid,y_valid_ns  =  valid_df[feature_cols], valid_df[target_cols].values,valid_df[target_nonsc_cols2].values\n        x_test = test_[feature_cols]\n\n        #------------ norm --------------\n        col_num = list(set(feat_dic['gene'] + feat_dic['cell']) & set(feature_cols))\n        col_num.sort()\n        x_train[col_num],ss = norm_fit(x_train[col_num],True,'quan')\n        x_valid[col_num]    = norm_tra(x_valid[col_num],ss)\n        x_test[col_num]     = norm_tra(x_test[col_num],ss)\n\n        #------------ pca --------------\n        def pca_pre(tr,va,te,\n                    n_comp,feat_raw,feat_new):\n            pca = PCA(n_components=n_comp, random_state=42)\n            tr2 = pd.DataFrame(pca.fit_transform(tr[feat_raw]),columns=feat_new)\n            va2 = pd.DataFrame(pca.transform(va[feat_raw]),columns=feat_new)\n            te2 = pd.DataFrame(pca.transform(te[feat_raw]),columns=feat_new)\n            return(tr2,va2,te2)\n\n\n        pca_feat_g = [f'pca_G-{i}' for i in range(n_comp1)]\n        feat_dic['pca_g'] = pca_feat_g\n        x_tr_g_pca,x_va_g_pca,x_te_g_pca = pca_pre(x_train,x_valid,x_test,\n                                                   n_comp1,feat_dic['gene'],pca_feat_g)\n        x_train = pd.concat([x_train,x_tr_g_pca],axis = 1)\n        x_valid = pd.concat([x_valid,x_va_g_pca],axis = 1)\n        x_test  = pd.concat([x_test,x_te_g_pca],axis = 1)\n\n        pca_feat_g = [f'pca_C-{i}' for i in range(n_comp2)]\n        feat_dic['pca_c'] = pca_feat_g\n        x_tr_c_pca,x_va_c_pca,x_te_c_pca = pca_pre(x_train,x_valid,x_test,\n                                                   n_comp2,feat_dic['cell'],pca_feat_g)\n        x_train = pd.concat([x_train,x_tr_c_pca],axis = 1)\n        x_valid = pd.concat([x_valid,x_va_c_pca],axis = 1)\n        x_test  = pd.concat([x_test,x_te_c_pca], axis = 1)\n\n        x_train,x_valid,x_test = x_train.values,x_valid.values,x_test.values\n\n        train_dataset = TrainDataset(x_train, y_train_ns)\n        valid_dataset = TrainDataset(x_valid, y_valid_ns)\n        trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n        validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n        model = Model(\n            num_features=num_features,\n            num_targets=num_targets_0,\n            hidden_size=hidden_size,\n        )\n\n        model.to(DEVICE)\n\n        optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=0.0001)\n        scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e5, \n                                                  max_lr=0.0001, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n\n        loss_tr = nn.BCEWithLogitsLoss()   #SmoothBCEwLogits(smoothing = 0.001)\n        loss_va = nn.BCEWithLogitsLoss()    \n\n        early_stopping_steps = EARLY_STOPPING_STEPS\n        early_step = 0\n\n        for epoch in range(1):\n            train_loss = train_fn(model, optimizer,scheduler, loss_tr, trainloader, DEVICE)\n            valid_loss, valid_preds = valid_fn(model, loss_va, validloader, DEVICE)\n            print(f\"FOLD: {fold}, EPOCH: {epoch},train_loss: {train_loss}, valid_loss: {valid_loss}\")\n\n        model.dense3 = nn.utils.weight_norm(nn.Linear(model.cha_po_2, num_targets))\n        model.to(DEVICE)\n\n        train_dataset = TrainDataset(x_train, y_train)\n        valid_dataset = TrainDataset(x_valid, y_valid)\n        trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n        validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n        optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n        scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n                                                  max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n\n        loss_tr = SmoothBCEwLogits(smoothing = 0.001)\n        loss_va = nn.BCEWithLogitsLoss()    \n\n        early_stopping_steps = EARLY_STOPPING_STEPS\n        early_step = 0\n\n        oof = np.zeros((len(train), len(target_cols)))\n        best_loss = np.inf\n\n        mod_name = f\"FOLD_mod11_{seed}_{fold}_.pth\"\n        \n        for epoch in range(EPOCHS):\n\n            train_loss = train_fn(model, optimizer,scheduler, loss_tr, trainloader, DEVICE)\n            valid_loss, valid_preds = valid_fn(model, loss_va, validloader, DEVICE)\n            print(f\"SEED: {seed}, FOLD: {fold}, EPOCH: {epoch},train_loss: {train_loss}, valid_loss: {valid_loss}\")\n\n            if valid_loss < best_loss:\n\n                best_loss = valid_loss\n                oof[val_idx] = valid_preds\n                torch.save(model.state_dict(), mod_name)\n\n            elif(EARLY_STOP == True):\n\n                early_step += 1\n                if (early_step >= early_stopping_steps):\n                    break\n\n        #--------------------- PREDICTION---------------------\n        testdataset = TestDataset(x_test)\n        testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n\n        if seed == SEED[-1]:\n            valid_sam = torch.utils.data.DataLoader(testdataset, batch_size=1, shuffle=False)\n            sample = next(iter(valid_sam))\n            inputs = sample['x'].to(DEVICE)\n            flops = FlopCountAnalysis(model, inputs)\n            print(\"*\"*20)\n            print(f\"Flops for KAN: {flops.total()}\")\n            print(\"*\"*20)\n            # print(summary(model, tuple(sample.shape[1:]), \"cuda\"))\n        \n        model = Model(\n            num_features=num_features,\n            num_targets=num_targets,\n            hidden_size=hidden_size,\n        )\n\n        model.load_state_dict(torch.load(mod_name))\n        model.to(DEVICE)\n\n        predictions = np.zeros((len(test_), len(target_cols)))\n        predictions = inference_fn(model, testloader, DEVICE)\n        return oof, predictions\n\n    def run_k_fold(NFOLDS, seed):\n        oof = np.zeros((len(train), len(target_cols)))\n        predictions = np.zeros((len(test), len(target_cols)))\n\n        for fold in range(NFOLDS):\n            oof_, pred_ = run_training(fold, seed)\n\n            predictions += pred_ / NFOLDS\n            oof += oof_\n\n        return oof, predictions\n\n    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n    oof += oof_ / len(SEED)\n    predictions += predictions_ / len(SEED)\n    \n    oof_tmp = dp(oof)\n    oof_tmp = oof_tmp * len(SEED) / (SEED.index(seed)+1)\n    sc_dic[seed] = np.mean([log_loss(train[target_cols].iloc[:,i],oof_tmp[:,i]) for i in range(len(target_cols))])\n\n\nfrom sklearn.metrics import log_loss\nprint(np.mean([log_loss(train[target_cols].iloc[:,i],oof[:,i]) for i in range(len(target_cols))]))\n\ntrain0[target_cols] = oof\ntest[target_cols] = predictions\n\n### for blend test ###\ntrain0.to_csv('train_pred.csv', index=False)\n### for blend test ###\n\nsub1 = sample_submission.drop(columns=target_cols).merge(test[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\nsub1.to_csv('submission_CNN.csv', index=False)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T07:03:31.036893Z","iopub.execute_input":"2025-01-16T07:03:31.037218Z","iopub.status.idle":"2025-01-16T08:43:22.173346Z","shell.execute_reply.started":"2025-01-16T07:03:31.037188Z","shell.execute_reply":"2025-01-16T08:43:22.172509Z"}},"outputs":[{"name":"stdout","text":"FOLD: 0, EPOCH: 0,train_loss: 0.7371697628843612, valid_loss: 0.7161911760057722\nSEED: 0, FOLD: 0, EPOCH: 0,train_loss: 0.46651054235796136, valid_loss: 0.02378365695476532\nSEED: 0, FOLD: 0, EPOCH: 1,train_loss: 0.020906309421727623, valid_loss: 0.01872580163180828\nSEED: 0, FOLD: 0, EPOCH: 2,train_loss: 0.01885275546785282, valid_loss: 0.01821439963366304\nSEED: 0, FOLD: 0, EPOCH: 3,train_loss: 0.018271777171479618, valid_loss: 0.018483552762440274\nSEED: 0, FOLD: 0, EPOCH: 4,train_loss: 0.017935359600823427, valid_loss: 0.018655182314770563\nSEED: 0, FOLD: 0, EPOCH: 5,train_loss: 0.017843040165261947, valid_loss: 0.017579075427992003\nSEED: 0, FOLD: 0, EPOCH: 6,train_loss: 0.017858127280529858, valid_loss: 0.018010207185787813\nSEED: 0, FOLD: 0, EPOCH: 7,train_loss: 0.017780755929972813, valid_loss: 0.018267175182700157\nSEED: 0, FOLD: 0, EPOCH: 8,train_loss: 0.01780426421918083, valid_loss: 0.017827110152159417\nSEED: 0, FOLD: 0, EPOCH: 9,train_loss: 0.017827692461888426, valid_loss: 0.017804124977971826\nSEED: 0, FOLD: 0, EPOCH: 10,train_loss: 0.01784347827154873, valid_loss: 0.017607234524829048\nSEED: 0, FOLD: 0, EPOCH: 11,train_loss: 0.01771418383156044, valid_loss: 0.017576301683272635\nSEED: 0, FOLD: 0, EPOCH: 12,train_loss: 0.017683656258589548, valid_loss: 0.017395748623779843\nSEED: 0, FOLD: 0, EPOCH: 13,train_loss: 0.017531365939024567, valid_loss: 0.017512797378003597\nSEED: 0, FOLD: 0, EPOCH: 14,train_loss: 0.01743027733206965, valid_loss: 0.01734369924025876\nSEED: 0, FOLD: 0, EPOCH: 15,train_loss: 0.017229167785009613, valid_loss: 0.017492637650242875\nSEED: 0, FOLD: 0, EPOCH: 16,train_loss: 0.01704309759931504, valid_loss: 0.017565574097846235\nSEED: 0, FOLD: 0, EPOCH: 17,train_loss: 0.01687873202794488, valid_loss: 0.01724294690149171\nSEED: 0, FOLD: 0, EPOCH: 18,train_loss: 0.016562385855755514, valid_loss: 0.017202968203595705\nSEED: 0, FOLD: 0, EPOCH: 19,train_loss: 0.016149791537959507, valid_loss: 0.01718043400240796\nSEED: 0, FOLD: 0, EPOCH: 20,train_loss: 0.01575148656991297, valid_loss: 0.017267278262547085\nSEED: 0, FOLD: 0, EPOCH: 21,train_loss: 0.015234344591643068, valid_loss: 0.017108515676643166\nSEED: 0, FOLD: 0, EPOCH: 22,train_loss: 0.014734478444670853, valid_loss: 0.017150506563484668\nSEED: 0, FOLD: 0, EPOCH: 23,train_loss: 0.014255626147369976, valid_loss: 0.017143646201917103\nSEED: 0, FOLD: 0, EPOCH: 24,train_loss: 0.013988754266630049, valid_loss: 0.017148269872580255\nFOLD: 1, EPOCH: 0,train_loss: 0.7363893485417331, valid_loss: 0.7169321775436401\nSEED: 0, FOLD: 1, EPOCH: 0,train_loss: 0.46707569221782425, valid_loss: 0.024509455050740925\nSEED: 0, FOLD: 1, EPOCH: 1,train_loss: 0.0205828926260889, valid_loss: 0.019302634043352945\nSEED: 0, FOLD: 1, EPOCH: 2,train_loss: 0.018718094530984435, valid_loss: 0.01910351546747344\nSEED: 0, FOLD: 1, EPOCH: 3,train_loss: 0.01812710471614434, valid_loss: 0.018766946824533597\nSEED: 0, FOLD: 1, EPOCH: 4,train_loss: 0.017799286015440514, valid_loss: 0.018376976171774525\nSEED: 0, FOLD: 1, EPOCH: 5,train_loss: 0.01776749862317186, valid_loss: 0.018320524426443236\nSEED: 0, FOLD: 1, EPOCH: 6,train_loss: 0.017761407052948527, valid_loss: 0.018523654607789857\nSEED: 0, FOLD: 1, EPOCH: 7,train_loss: 0.017794394750066483, valid_loss: 0.01795062691505466\nSEED: 0, FOLD: 1, EPOCH: 8,train_loss: 0.01776300537243594, valid_loss: 0.018201453877346858\nSEED: 0, FOLD: 1, EPOCH: 9,train_loss: 0.01772756383747515, valid_loss: 0.018869395447628837\nSEED: 0, FOLD: 1, EPOCH: 10,train_loss: 0.017732737164427765, valid_loss: 0.018321557103523185\nSEED: 0, FOLD: 1, EPOCH: 11,train_loss: 0.017693385801339237, valid_loss: 0.018203459839735713\nSEED: 0, FOLD: 1, EPOCH: 12,train_loss: 0.01761933145568754, valid_loss: 0.018283636309206486\nSEED: 0, FOLD: 1, EPOCH: 13,train_loss: 0.017535462261714638, valid_loss: 0.017898265485252654\nSEED: 0, FOLD: 1, EPOCH: 14,train_loss: 0.017380509430365843, valid_loss: 0.017977344617247582\nSEED: 0, FOLD: 1, EPOCH: 15,train_loss: 0.017213800602531346, valid_loss: 0.01776249885026898\nSEED: 0, FOLD: 1, EPOCH: 16,train_loss: 0.01710489769568191, valid_loss: 0.01777000759861299\nSEED: 0, FOLD: 1, EPOCH: 17,train_loss: 0.016893189937474518, valid_loss: 0.017724928605769363\nSEED: 0, FOLD: 1, EPOCH: 18,train_loss: 0.016563351021359002, valid_loss: 0.0175738910479205\nSEED: 0, FOLD: 1, EPOCH: 19,train_loss: 0.01625721700435137, valid_loss: 0.017615389770695142\nSEED: 0, FOLD: 1, EPOCH: 20,train_loss: 0.015835486501999146, valid_loss: 0.01769277647669826\nSEED: 0, FOLD: 1, EPOCH: 21,train_loss: 0.015365262461459115, valid_loss: 0.017435620059924467\nSEED: 0, FOLD: 1, EPOCH: 22,train_loss: 0.014822256805742309, valid_loss: 0.01748333027852433\nSEED: 0, FOLD: 1, EPOCH: 23,train_loss: 0.014391187428884263, valid_loss: 0.01747233598892178\nSEED: 0, FOLD: 1, EPOCH: 24,train_loss: 0.014145976435529055, valid_loss: 0.017481764725276402\nFOLD: 2, EPOCH: 0,train_loss: 0.7371872227261032, valid_loss: 0.71432005833177\nSEED: 0, FOLD: 2, EPOCH: 0,train_loss: 0.46685901392197265, valid_loss: 0.0232803099514807\nSEED: 0, FOLD: 2, EPOCH: 1,train_loss: 0.02089900511276463, valid_loss: 0.0184535992824856\nSEED: 0, FOLD: 2, EPOCH: 2,train_loss: 0.018861331342571022, valid_loss: 0.017982896444771218\nSEED: 0, FOLD: 2, EPOCH: 3,train_loss: 0.018142062576784603, valid_loss: 0.017639416763011145\nSEED: 0, FOLD: 2, EPOCH: 4,train_loss: 0.01798201037192906, valid_loss: 0.017729003091945368\nSEED: 0, FOLD: 2, EPOCH: 5,train_loss: 0.0178729805191034, valid_loss: 0.017827111104612842\nSEED: 0, FOLD: 2, EPOCH: 6,train_loss: 0.017883836696653263, valid_loss: 0.017666086171041515\nSEED: 0, FOLD: 2, EPOCH: 7,train_loss: 0.017920202616116276, valid_loss: 0.017709408037583616\nSEED: 0, FOLD: 2, EPOCH: 8,train_loss: 0.017961029644947554, valid_loss: 0.017793404924518922\nSEED: 0, FOLD: 2, EPOCH: 9,train_loss: 0.017859733481284067, valid_loss: 0.01800333714003072\nSEED: 0, FOLD: 2, EPOCH: 10,train_loss: 0.017828516520397818, valid_loss: 0.017862692776629153\nSEED: 0, FOLD: 2, EPOCH: 11,train_loss: 0.01774977536980009, valid_loss: 0.01782901267356732\nSEED: 0, FOLD: 2, EPOCH: 12,train_loss: 0.01769287596065281, valid_loss: 0.01762523751377183\nSEED: 0, FOLD: 2, EPOCH: 13,train_loss: 0.017614489778930296, valid_loss: 0.01756619875702788\nSEED: 0, FOLD: 2, EPOCH: 14,train_loss: 0.017506084256414055, valid_loss: 0.01748749548021485\nSEED: 0, FOLD: 2, EPOCH: 15,train_loss: 0.01732774120013135, valid_loss: 0.017379783367847696\nSEED: 0, FOLD: 2, EPOCH: 16,train_loss: 0.017182716485652803, valid_loss: 0.017193391836960528\nSEED: 0, FOLD: 2, EPOCH: 17,train_loss: 0.016897525462875332, valid_loss: 0.017234905102454564\nSEED: 0, FOLD: 2, EPOCH: 18,train_loss: 0.01662449031204417, valid_loss: 0.017033693024559933\nSEED: 0, FOLD: 2, EPOCH: 19,train_loss: 0.01625544674343605, valid_loss: 0.016967327662688846\nSEED: 0, FOLD: 2, EPOCH: 20,train_loss: 0.015867229213641174, valid_loss: 0.017095093314042863\nSEED: 0, FOLD: 2, EPOCH: 21,train_loss: 0.01537637741210452, valid_loss: 0.016932672136189306\nSEED: 0, FOLD: 2, EPOCH: 22,train_loss: 0.014847488992887995, valid_loss: 0.016853340572732335\nSEED: 0, FOLD: 2, EPOCH: 23,train_loss: 0.014412095156106829, valid_loss: 0.016850213520228863\nSEED: 0, FOLD: 2, EPOCH: 24,train_loss: 0.014165817240280086, valid_loss: 0.016852496082291883\nFOLD: 3, EPOCH: 0,train_loss: 0.7368812772674836, valid_loss: 0.7151822924613953\nSEED: 0, FOLD: 3, EPOCH: 0,train_loss: 0.4658635797087049, valid_loss: 0.024612167051860263\nSEED: 0, FOLD: 3, EPOCH: 1,train_loss: 0.020859375879492447, valid_loss: 0.018707296199032237\nSEED: 0, FOLD: 3, EPOCH: 2,train_loss: 0.018779935004810493, valid_loss: 0.01800009302262749\nSEED: 0, FOLD: 3, EPOCH: 3,train_loss: 0.01803661862631207, valid_loss: 0.017955566862864154\nSEED: 0, FOLD: 3, EPOCH: 4,train_loss: 0.01802477445723354, valid_loss: 0.01804285113300596\nSEED: 0, FOLD: 3, EPOCH: 5,train_loss: 0.017872202898497166, valid_loss: 0.018790389916726522\nSEED: 0, FOLD: 3, EPOCH: 6,train_loss: 0.017861349447427885, valid_loss: 0.018206375491406235\nSEED: 0, FOLD: 3, EPOCH: 7,train_loss: 0.01786482201187291, valid_loss: 0.017672814588461604\nSEED: 0, FOLD: 3, EPOCH: 8,train_loss: 0.017815408128165247, valid_loss: 0.01795278143669878\nSEED: 0, FOLD: 3, EPOCH: 9,train_loss: 0.017824138399969408, valid_loss: 0.017714106211704866\nSEED: 0, FOLD: 3, EPOCH: 10,train_loss: 0.017797119429577953, valid_loss: 0.01785508080252579\nSEED: 0, FOLD: 3, EPOCH: 11,train_loss: 0.017771391589464485, valid_loss: 0.017729820763426166\nSEED: 0, FOLD: 3, EPOCH: 12,train_loss: 0.017672688835233017, valid_loss: 0.017711963903691088\nSEED: 0, FOLD: 3, EPOCH: 13,train_loss: 0.017575488412293835, valid_loss: 0.017574569316846984\nSEED: 0, FOLD: 3, EPOCH: 14,train_loss: 0.017493875677008993, valid_loss: 0.01767846875424896\nSEED: 0, FOLD: 3, EPOCH: 15,train_loss: 0.01725182727492158, valid_loss: 0.017511211654969622\nSEED: 0, FOLD: 3, EPOCH: 16,train_loss: 0.01714297001371565, valid_loss: 0.01738632959978921\nSEED: 0, FOLD: 3, EPOCH: 17,train_loss: 0.0169044875310383, valid_loss: 0.017471465761108057\nSEED: 0, FOLD: 3, EPOCH: 18,train_loss: 0.01653871110950907, valid_loss: 0.017763713374733925\nSEED: 0, FOLD: 3, EPOCH: 19,train_loss: 0.01625586286916033, valid_loss: 0.017311998962291648\nSEED: 0, FOLD: 3, EPOCH: 20,train_loss: 0.015871891900357128, valid_loss: 0.0171245255906667\nSEED: 0, FOLD: 3, EPOCH: 21,train_loss: 0.01533760174272069, valid_loss: 0.017126252448984556\nSEED: 0, FOLD: 3, EPOCH: 22,train_loss: 0.01478228322567715, valid_loss: 0.017147345282137395\nSEED: 0, FOLD: 3, EPOCH: 23,train_loss: 0.014318200334420671, valid_loss: 0.01720357457441943\nSEED: 0, FOLD: 3, EPOCH: 24,train_loss: 0.014081026899857798, valid_loss: 0.01720555198511907\nFOLD: 4, EPOCH: 0,train_loss: 0.7371297966742861, valid_loss: 0.7154773695128305\nSEED: 0, FOLD: 4, EPOCH: 0,train_loss: 0.46697545040776767, valid_loss: 0.02378250647868429\nSEED: 0, FOLD: 4, EPOCH: 1,train_loss: 0.021167256369970848, valid_loss: 0.025009630780134882\nSEED: 0, FOLD: 4, EPOCH: 2,train_loss: 0.019164787605404854, valid_loss: 0.018374069992985045\nSEED: 0, FOLD: 4, EPOCH: 3,train_loss: 0.018134393790007933, valid_loss: 0.018366947025060653\nSEED: 0, FOLD: 4, EPOCH: 4,train_loss: 0.0178316333466142, valid_loss: 0.018288300558924674\nSEED: 0, FOLD: 4, EPOCH: 5,train_loss: 0.017853870569471863, valid_loss: 0.01823425894337041\nSEED: 0, FOLD: 4, EPOCH: 6,train_loss: 0.017893886841509655, valid_loss: 0.018075677858931678\nSEED: 0, FOLD: 4, EPOCH: 7,train_loss: 0.017904667197254257, valid_loss: 0.01795433046562331\nSEED: 0, FOLD: 4, EPOCH: 8,train_loss: 0.0178393322394054, valid_loss: 0.01793497268642698\nSEED: 0, FOLD: 4, EPOCH: 9,train_loss: 0.017873442900515554, valid_loss: 0.01842360555061272\nSEED: 0, FOLD: 4, EPOCH: 10,train_loss: 0.01776108994702066, valid_loss: 0.018058343550988606\nSEED: 0, FOLD: 4, EPOCH: 11,train_loss: 0.017791178516125765, valid_loss: 0.01785990558564663\nSEED: 0, FOLD: 4, EPOCH: 12,train_loss: 0.01766087164076558, valid_loss: 0.017700794312570777\nSEED: 0, FOLD: 4, EPOCH: 13,train_loss: 0.01758335289828803, valid_loss: 0.017617952504328318\nSEED: 0, FOLD: 4, EPOCH: 14,train_loss: 0.017396769776562418, valid_loss: 0.017761976697615214\nSEED: 0, FOLD: 4, EPOCH: 15,train_loss: 0.017303428997326155, valid_loss: 0.017424977783645903\nSEED: 0, FOLD: 4, EPOCH: 16,train_loss: 0.017097215802557228, valid_loss: 0.017557486838528088\nSEED: 0, FOLD: 4, EPOCH: 17,train_loss: 0.016872567907515644, valid_loss: 0.017537404889506954\nSEED: 0, FOLD: 4, EPOCH: 18,train_loss: 0.016613277707896803, valid_loss: 0.017383108474314214\nSEED: 0, FOLD: 4, EPOCH: 19,train_loss: 0.016224183270410784, valid_loss: 0.017441883337284837\nSEED: 0, FOLD: 4, EPOCH: 20,train_loss: 0.01583285635823141, valid_loss: 0.01731026161994253\nSEED: 0, FOLD: 4, EPOCH: 21,train_loss: 0.015378570865731741, valid_loss: 0.01741942699466433\nSEED: 0, FOLD: 4, EPOCH: 22,train_loss: 0.01486726767262039, valid_loss: 0.017253204621374606\nSEED: 0, FOLD: 4, EPOCH: 23,train_loss: 0.01441754256307647, valid_loss: 0.017270083725452422\nSEED: 0, FOLD: 4, EPOCH: 24,train_loss: 0.014194105542602314, valid_loss: 0.017243939345436436\nFOLD: 0, EPOCH: 0,train_loss: 0.7346841157346532, valid_loss: 0.6985056264059885\nSEED: 1, FOLD: 0, EPOCH: 0,train_loss: 0.46679061270602373, valid_loss: 0.024028545564838816\nSEED: 1, FOLD: 0, EPOCH: 1,train_loss: 0.021025139905944252, valid_loss: 0.018462849514825002\nSEED: 1, FOLD: 0, EPOCH: 2,train_loss: 0.019199544523397217, valid_loss: 0.017761916374521597\nSEED: 1, FOLD: 0, EPOCH: 3,train_loss: 0.018307540714200855, valid_loss: 0.017700021527707575\nSEED: 1, FOLD: 0, EPOCH: 4,train_loss: 0.017938221048941647, valid_loss: 0.017444060503372123\nSEED: 1, FOLD: 0, EPOCH: 5,train_loss: 0.017837258777918592, valid_loss: 0.01790236931826387\nSEED: 1, FOLD: 0, EPOCH: 6,train_loss: 0.01783699849350513, valid_loss: 0.017710331215390136\nSEED: 1, FOLD: 0, EPOCH: 7,train_loss: 0.017839624357504257, valid_loss: 0.017481976108891625\nSEED: 1, FOLD: 0, EPOCH: 8,train_loss: 0.01782926462887638, valid_loss: 0.017505545461816447\nSEED: 1, FOLD: 0, EPOCH: 9,train_loss: 0.017805786573908466, valid_loss: 0.017369267983095987\nSEED: 1, FOLD: 0, EPOCH: 10,train_loss: 0.017776424794093422, valid_loss: 0.017169764451682567\nSEED: 1, FOLD: 0, EPOCH: 11,train_loss: 0.01773074591883283, valid_loss: 0.017096814859126296\nSEED: 1, FOLD: 0, EPOCH: 12,train_loss: 0.017688830207655395, valid_loss: 0.017291568991328988\nSEED: 1, FOLD: 0, EPOCH: 13,train_loss: 0.01759473752041442, valid_loss: 0.017133649358791966\nSEED: 1, FOLD: 0, EPOCH: 14,train_loss: 0.01747802994551434, valid_loss: 0.01707515934748309\nSEED: 1, FOLD: 0, EPOCH: 15,train_loss: 0.017324804422864014, valid_loss: 0.01717568202210324\nSEED: 1, FOLD: 0, EPOCH: 16,train_loss: 0.01708472792086178, valid_loss: 0.01659584833042962\nSEED: 1, FOLD: 0, EPOCH: 17,train_loss: 0.016899545521785814, valid_loss: 0.01672393884509802\nSEED: 1, FOLD: 0, EPOCH: 18,train_loss: 0.016587015646307365, valid_loss: 0.016735995853585855\nSEED: 1, FOLD: 0, EPOCH: 19,train_loss: 0.01616858192247109, valid_loss: 0.016699512356093953\nSEED: 1, FOLD: 0, EPOCH: 20,train_loss: 0.0156850370551473, valid_loss: 0.01669354997575283\nSEED: 1, FOLD: 0, EPOCH: 21,train_loss: 0.01516683702694549, valid_loss: 0.016580394628856864\nSEED: 1, FOLD: 0, EPOCH: 22,train_loss: 0.014595585180095572, valid_loss: 0.016669943423143454\nSEED: 1, FOLD: 0, EPOCH: 23,train_loss: 0.014119433893727652, valid_loss: 0.016638985089957713\nSEED: 1, FOLD: 0, EPOCH: 24,train_loss: 0.013849106583528328, valid_loss: 0.016633332281240396\nFOLD: 1, EPOCH: 0,train_loss: 0.7344414452566718, valid_loss: 0.6978871430669512\nSEED: 1, FOLD: 1, EPOCH: 0,train_loss: 0.4667734283219724, valid_loss: 0.024212196096777917\nSEED: 1, FOLD: 1, EPOCH: 1,train_loss: 0.020838108090479878, valid_loss: 0.018665647400277003\nSEED: 1, FOLD: 1, EPOCH: 2,train_loss: 0.019123685022775273, valid_loss: 0.018424597701856067\nSEED: 1, FOLD: 1, EPOCH: 3,train_loss: 0.018155346651745105, valid_loss: 0.017703619758997646\nSEED: 1, FOLD: 1, EPOCH: 4,train_loss: 0.01785839268135546, valid_loss: 0.018034962405051504\nSEED: 1, FOLD: 1, EPOCH: 5,train_loss: 0.01778957600548972, valid_loss: 0.017777471297553606\nSEED: 1, FOLD: 1, EPOCH: 6,train_loss: 0.017730442575947213, valid_loss: 0.018690390991313116\nSEED: 1, FOLD: 1, EPOCH: 7,train_loss: 0.017865139236469773, valid_loss: 0.017623349837958813\nSEED: 1, FOLD: 1, EPOCH: 8,train_loss: 0.017845668469684838, valid_loss: 0.017708424159458707\nSEED: 1, FOLD: 1, EPOCH: 9,train_loss: 0.017720621901761442, valid_loss: 0.01765098265771355\nSEED: 1, FOLD: 1, EPOCH: 10,train_loss: 0.01769453726953616, valid_loss: 0.01804472016436713\nSEED: 1, FOLD: 1, EPOCH: 11,train_loss: 0.01774972568463235, valid_loss: 0.01750449711190803\nSEED: 1, FOLD: 1, EPOCH: 12,train_loss: 0.01758769159987025, valid_loss: 0.017762207718832152\nSEED: 1, FOLD: 1, EPOCH: 13,train_loss: 0.017527003922112233, valid_loss: 0.018007289032850947\nSEED: 1, FOLD: 1, EPOCH: 14,train_loss: 0.017411774269094432, valid_loss: 0.017551574669778348\nSEED: 1, FOLD: 1, EPOCH: 15,train_loss: 0.017234275117516518, valid_loss: 0.017356396546321255\nSEED: 1, FOLD: 1, EPOCH: 16,train_loss: 0.017003202137883998, valid_loss: 0.017417030914553575\nSEED: 1, FOLD: 1, EPOCH: 17,train_loss: 0.016807219904106465, valid_loss: 0.017575082475585597\nSEED: 1, FOLD: 1, EPOCH: 18,train_loss: 0.016507839036248896, valid_loss: 0.017262997079108444\nSEED: 1, FOLD: 1, EPOCH: 19,train_loss: 0.016139450571397797, valid_loss: 0.017200677788683345\nSEED: 1, FOLD: 1, EPOCH: 20,train_loss: 0.015673559138646525, valid_loss: 0.017130489487733158\nSEED: 1, FOLD: 1, EPOCH: 21,train_loss: 0.015151816773751792, valid_loss: 0.017161403436745916\nSEED: 1, FOLD: 1, EPOCH: 22,train_loss: 0.01461662713057586, valid_loss: 0.017176097445189952\nSEED: 1, FOLD: 1, EPOCH: 23,train_loss: 0.014149535216227934, valid_loss: 0.017207128501364164\nSEED: 1, FOLD: 1, EPOCH: 24,train_loss: 0.01388372774541813, valid_loss: 0.0172095320054463\nFOLD: 2, EPOCH: 0,train_loss: 0.7344415343326071, valid_loss: 0.6999688284737723\nSEED: 1, FOLD: 2, EPOCH: 0,train_loss: 0.46607202356276306, valid_loss: 0.02447053843310901\nSEED: 1, FOLD: 2, EPOCH: 1,train_loss: 0.02073421712586845, valid_loss: 0.019177364291889328\nSEED: 1, FOLD: 2, EPOCH: 2,train_loss: 0.0190423638627365, valid_loss: 0.018505326897970267\nSEED: 1, FOLD: 2, EPOCH: 3,train_loss: 0.01823541097531932, valid_loss: 0.017967883524085793\nSEED: 1, FOLD: 2, EPOCH: 4,train_loss: 0.017906425055116415, valid_loss: 0.018148397095501423\nSEED: 1, FOLD: 2, EPOCH: 5,train_loss: 0.017855762254338766, valid_loss: 0.01772004741110972\nSEED: 1, FOLD: 2, EPOCH: 6,train_loss: 0.01786529226903466, valid_loss: 0.017791347524949482\nSEED: 1, FOLD: 2, EPOCH: 7,train_loss: 0.017837926907383877, valid_loss: 0.01795736149485622\nSEED: 1, FOLD: 2, EPOCH: 8,train_loss: 0.017965394821341917, valid_loss: 0.017797151899763514\nSEED: 1, FOLD: 2, EPOCH: 9,train_loss: 0.017895085926073185, valid_loss: 0.01763725182307618\nSEED: 1, FOLD: 2, EPOCH: 10,train_loss: 0.017822200925075922, valid_loss: 0.01776123379490205\nSEED: 1, FOLD: 2, EPOCH: 11,train_loss: 0.017818715092658564, valid_loss: 0.017737093354974476\nSEED: 1, FOLD: 2, EPOCH: 12,train_loss: 0.017703410777924717, valid_loss: 0.018011172035975114\nSEED: 1, FOLD: 2, EPOCH: 13,train_loss: 0.01760695085766307, valid_loss: 0.017666846407311303\nSEED: 1, FOLD: 2, EPOCH: 14,train_loss: 0.017462826495909172, valid_loss: 0.017532570660114287\nSEED: 1, FOLD: 2, EPOCH: 15,train_loss: 0.017313071796535583, valid_loss: 0.01752452916864838\nSEED: 1, FOLD: 2, EPOCH: 16,train_loss: 0.017165341414511204, valid_loss: 0.01727051048406533\nSEED: 1, FOLD: 2, EPOCH: 17,train_loss: 0.016979987341640652, valid_loss: 0.017177732342055867\nSEED: 1, FOLD: 2, EPOCH: 18,train_loss: 0.01667507525290484, valid_loss: 0.017167060822248458\nSEED: 1, FOLD: 2, EPOCH: 19,train_loss: 0.016317285354370655, valid_loss: 0.017194743108536515\nSEED: 1, FOLD: 2, EPOCH: 20,train_loss: 0.015917123781274193, valid_loss: 0.01707299846623625\nSEED: 1, FOLD: 2, EPOCH: 21,train_loss: 0.015421865561950033, valid_loss: 0.017202578830931868\nSEED: 1, FOLD: 2, EPOCH: 22,train_loss: 0.01490335930408775, valid_loss: 0.01704484394618443\nSEED: 1, FOLD: 2, EPOCH: 23,train_loss: 0.01445277325431074, valid_loss: 0.017028456473989147\nSEED: 1, FOLD: 2, EPOCH: 24,train_loss: 0.014222565275765415, valid_loss: 0.01704196392425469\nFOLD: 3, EPOCH: 0,train_loss: 0.7347853136235389, valid_loss: 0.6966582536697388\nSEED: 1, FOLD: 3, EPOCH: 0,train_loss: 0.4669390262199053, valid_loss: 0.024296168237924576\nSEED: 1, FOLD: 3, EPOCH: 1,train_loss: 0.020704540086613186, valid_loss: 0.019314959538834435\nSEED: 1, FOLD: 3, EPOCH: 2,train_loss: 0.01886790065580736, valid_loss: 0.01860742654119219\nSEED: 1, FOLD: 3, EPOCH: 3,train_loss: 0.018074500860403412, valid_loss: 0.018315464311412403\nSEED: 1, FOLD: 3, EPOCH: 4,train_loss: 0.017704102089223656, valid_loss: 0.01819726838065045\nSEED: 1, FOLD: 3, EPOCH: 5,train_loss: 0.0177282208468819, valid_loss: 0.01820618933332818\nSEED: 1, FOLD: 3, EPOCH: 6,train_loss: 0.017741416520236628, valid_loss: 0.018543820961245468\nSEED: 1, FOLD: 3, EPOCH: 7,train_loss: 0.01778889992746754, valid_loss: 0.01863872456763472\nSEED: 1, FOLD: 3, EPOCH: 8,train_loss: 0.017833088308680748, valid_loss: 0.018749255474124635\nSEED: 1, FOLD: 3, EPOCH: 9,train_loss: 0.017830270605728678, valid_loss: 0.018553897844893592\nSEED: 1, FOLD: 3, EPOCH: 10,train_loss: 0.017821029948907486, valid_loss: 0.018254787182169302\nSEED: 1, FOLD: 3, EPOCH: 11,train_loss: 0.017746583720588165, valid_loss: 0.01897447141153472\nSEED: 1, FOLD: 3, EPOCH: 12,train_loss: 0.017725882552348186, valid_loss: 0.01826080179640225\nSEED: 1, FOLD: 3, EPOCH: 13,train_loss: 0.017551044926749193, valid_loss: 0.0183789285165923\nSEED: 1, FOLD: 3, EPOCH: 14,train_loss: 0.017442680962815666, valid_loss: 0.018027242086827756\nSEED: 1, FOLD: 3, EPOCH: 15,train_loss: 0.017311164582877056, valid_loss: 0.018082501819091185\nSEED: 1, FOLD: 3, EPOCH: 16,train_loss: 0.017155570281750483, valid_loss: 0.017958167142101696\nSEED: 1, FOLD: 3, EPOCH: 17,train_loss: 0.016864864749537, valid_loss: 0.01800115044627871\nSEED: 1, FOLD: 3, EPOCH: 18,train_loss: 0.01662221887702311, valid_loss: 0.017757438655410494\nSEED: 1, FOLD: 3, EPOCH: 19,train_loss: 0.016273968097200428, valid_loss: 0.017760269210806916\nSEED: 1, FOLD: 3, EPOCH: 20,train_loss: 0.015849225607741137, valid_loss: 0.01776830641818898\nSEED: 1, FOLD: 3, EPOCH: 21,train_loss: 0.015346588350940441, valid_loss: 0.017741757498255798\nSEED: 1, FOLD: 3, EPOCH: 22,train_loss: 0.014769159804057816, valid_loss: 0.017669103746967656\nSEED: 1, FOLD: 3, EPOCH: 23,train_loss: 0.014351441740881706, valid_loss: 0.017700758815876075\nSEED: 1, FOLD: 3, EPOCH: 24,train_loss: 0.014095002967540337, valid_loss: 0.0176707994725023\nFOLD: 4, EPOCH: 0,train_loss: 0.7347105093245959, valid_loss: 0.6983044232640948\nSEED: 1, FOLD: 4, EPOCH: 0,train_loss: 0.46709042696459013, valid_loss: 0.023966804359640395\nSEED: 1, FOLD: 4, EPOCH: 1,train_loss: 0.021003870579012988, valid_loss: 0.019013203414423124\nSEED: 1, FOLD: 4, EPOCH: 2,train_loss: 0.01906018834697069, valid_loss: 0.018510408034282073\nSEED: 1, FOLD: 4, EPOCH: 3,train_loss: 0.018182093739835887, valid_loss: 0.01831535401621035\nSEED: 1, FOLD: 4, EPOCH: 4,train_loss: 0.01775461115133371, valid_loss: 0.018163303206009524\nSEED: 1, FOLD: 4, EPOCH: 5,train_loss: 0.017715745469568854, valid_loss: 0.018245716180120195\nSEED: 1, FOLD: 4, EPOCH: 6,train_loss: 0.017761134991191165, valid_loss: 0.018101959941642626\nSEED: 1, FOLD: 4, EPOCH: 7,train_loss: 0.017710922102369096, valid_loss: 0.018216846750250884\nSEED: 1, FOLD: 4, EPOCH: 8,train_loss: 0.017736628284528308, valid_loss: 0.018317149100559097\nSEED: 1, FOLD: 4, EPOCH: 9,train_loss: 0.017786910077624948, valid_loss: 0.018114210266087737\nSEED: 1, FOLD: 4, EPOCH: 10,train_loss: 0.017715055074026115, valid_loss: 0.01841424150126321\nSEED: 1, FOLD: 4, EPOCH: 11,train_loss: 0.017653168756922667, valid_loss: 0.01804902045322316\nSEED: 1, FOLD: 4, EPOCH: 12,train_loss: 0.01758104615103807, valid_loss: 0.01816744583525828\nSEED: 1, FOLD: 4, EPOCH: 13,train_loss: 0.017456874679638086, valid_loss: 0.018062448129057884\nSEED: 1, FOLD: 4, EPOCH: 14,train_loss: 0.01734535452522283, valid_loss: 0.017954428839896407\nSEED: 1, FOLD: 4, EPOCH: 15,train_loss: 0.017222160548243645, valid_loss: 0.017876141890883445\nSEED: 1, FOLD: 4, EPOCH: 16,train_loss: 0.016995048619480462, valid_loss: 0.01775792217148202\nSEED: 1, FOLD: 4, EPOCH: 17,train_loss: 0.016783903937542092, valid_loss: 0.017684272570269447\nSEED: 1, FOLD: 4, EPOCH: 18,train_loss: 0.016471021835875774, valid_loss: 0.017732410239321844\nSEED: 1, FOLD: 4, EPOCH: 19,train_loss: 0.0161358663730704, valid_loss: 0.017721523850091864\nSEED: 1, FOLD: 4, EPOCH: 20,train_loss: 0.015702608530919482, valid_loss: 0.017703451455703803\nSEED: 1, FOLD: 4, EPOCH: 21,train_loss: 0.015203489296573357, valid_loss: 0.01764118354767561\nSEED: 1, FOLD: 4, EPOCH: 22,train_loss: 0.014648798275331077, valid_loss: 0.017606209058846745\nSEED: 1, FOLD: 4, EPOCH: 23,train_loss: 0.01420331977470948, valid_loss: 0.017614826719675746\nSEED: 1, FOLD: 4, EPOCH: 24,train_loss: 0.013959432931712075, valid_loss: 0.017628669206585203\nFOLD: 0, EPOCH: 0,train_loss: 0.737838315790978, valid_loss: 0.7051378403391156\nSEED: 2, FOLD: 0, EPOCH: 0,train_loss: 0.4662470029855984, valid_loss: 0.02596723384090832\nSEED: 2, FOLD: 0, EPOCH: 1,train_loss: 0.021003841921903084, valid_loss: 0.018352542657937322\nSEED: 2, FOLD: 0, EPOCH: 2,train_loss: 0.01878195442934183, valid_loss: 0.01759211208139147\nSEED: 2, FOLD: 0, EPOCH: 3,train_loss: 0.0183231339223035, valid_loss: 0.01757153222071273\nSEED: 2, FOLD: 0, EPOCH: 4,train_loss: 0.01800625712570289, valid_loss: 0.017232441529631614\nSEED: 2, FOLD: 0, EPOCH: 5,train_loss: 0.01793441229729333, valid_loss: 0.017797597284827913\nSEED: 2, FOLD: 0, EPOCH: 6,train_loss: 0.018007932757229908, valid_loss: 0.017933553058121887\nSEED: 2, FOLD: 0, EPOCH: 7,train_loss: 0.017912370456463617, valid_loss: 0.017478461749851702\nSEED: 2, FOLD: 0, EPOCH: 8,train_loss: 0.0180599555251715, valid_loss: 0.017255242408386297\nSEED: 2, FOLD: 0, EPOCH: 9,train_loss: 0.017924654574227938, valid_loss: 0.017044758211289132\nSEED: 2, FOLD: 0, EPOCH: 10,train_loss: 0.017868889414745827, valid_loss: 0.01742289082280227\nSEED: 2, FOLD: 0, EPOCH: 11,train_loss: 0.017866988139955894, valid_loss: 0.017375034572822707\nSEED: 2, FOLD: 0, EPOCH: 12,train_loss: 0.01784260534559903, valid_loss: 0.017212222729410444\nSEED: 2, FOLD: 0, EPOCH: 13,train_loss: 0.017704781421554693, valid_loss: 0.016947586834430695\nSEED: 2, FOLD: 0, EPOCH: 14,train_loss: 0.01757065710220216, valid_loss: 0.016915866626160486\nSEED: 2, FOLD: 0, EPOCH: 15,train_loss: 0.017434456149467092, valid_loss: 0.016840022163731712\nSEED: 2, FOLD: 0, EPOCH: 16,train_loss: 0.017218925868687424, valid_loss: 0.017099036143294402\nSEED: 2, FOLD: 0, EPOCH: 17,train_loss: 0.017012618077190025, valid_loss: 0.01692412705825908\nSEED: 2, FOLD: 0, EPOCH: 18,train_loss: 0.01674474595600496, valid_loss: 0.016796565800905227\nSEED: 2, FOLD: 0, EPOCH: 19,train_loss: 0.01636102425771347, valid_loss: 0.016919063350984028\nSEED: 2, FOLD: 0, EPOCH: 20,train_loss: 0.015942369263781155, valid_loss: 0.016675788776150773\nSEED: 2, FOLD: 0, EPOCH: 21,train_loss: 0.015468826085545015, valid_loss: 0.016636935275580203\nSEED: 2, FOLD: 0, EPOCH: 22,train_loss: 0.014961067141722078, valid_loss: 0.016599758262080804\nSEED: 2, FOLD: 0, EPOCH: 23,train_loss: 0.014527574087074701, valid_loss: 0.016587406396865845\nSEED: 2, FOLD: 0, EPOCH: 24,train_loss: 0.014289406053991854, valid_loss: 0.016572444939187594\nFOLD: 1, EPOCH: 0,train_loss: 0.7380034772382267, valid_loss: 0.7072151950427464\nSEED: 2, FOLD: 1, EPOCH: 0,train_loss: 0.46584179148455895, valid_loss: 0.024182284623384474\nSEED: 2, FOLD: 1, EPOCH: 1,train_loss: 0.020905782050196674, valid_loss: 0.019310523303491728\nSEED: 2, FOLD: 1, EPOCH: 2,train_loss: 0.019229575370748837, valid_loss: 0.017808615815426622\nSEED: 2, FOLD: 1, EPOCH: 3,train_loss: 0.018207526725271473, valid_loss: 0.017638361187917846\nSEED: 2, FOLD: 1, EPOCH: 4,train_loss: 0.0180509044667301, valid_loss: 0.01842942610383034\nSEED: 2, FOLD: 1, EPOCH: 5,train_loss: 0.01797800382896178, valid_loss: 0.017623341722147804\nSEED: 2, FOLD: 1, EPOCH: 6,train_loss: 0.017926207331913538, valid_loss: 0.017904241170201982\nSEED: 2, FOLD: 1, EPOCH: 7,train_loss: 0.01793672629645553, valid_loss: 0.01786935544971909\nSEED: 2, FOLD: 1, EPOCH: 8,train_loss: 0.017938938869190388, valid_loss: 0.01779555795448167\nSEED: 2, FOLD: 1, EPOCH: 9,train_loss: 0.01793880852452223, valid_loss: 0.017570603106703078\nSEED: 2, FOLD: 1, EPOCH: 10,train_loss: 0.017863437958547602, valid_loss: 0.017404718085059098\nSEED: 2, FOLD: 1, EPOCH: 11,train_loss: 0.017868829513157623, valid_loss: 0.017937056879912105\nSEED: 2, FOLD: 1, EPOCH: 12,train_loss: 0.01781437536566586, valid_loss: 0.017591133793549877\nSEED: 2, FOLD: 1, EPOCH: 13,train_loss: 0.017668066674546488, valid_loss: 0.017444990761578082\nSEED: 2, FOLD: 1, EPOCH: 14,train_loss: 0.017568845571815105, valid_loss: 0.01723943522998265\nSEED: 2, FOLD: 1, EPOCH: 15,train_loss: 0.01746570729934003, valid_loss: 0.01690804460751159\nSEED: 2, FOLD: 1, EPOCH: 16,train_loss: 0.0171866313473362, valid_loss: 0.016900859799768242\nSEED: 2, FOLD: 1, EPOCH: 22,train_loss: 0.014967061403760876, valid_loss: 0.0166698995711548\nSEED: 2, FOLD: 1, EPOCH: 23,train_loss: 0.01453482408238494, valid_loss: 0.016684353058891637\nSEED: 2, FOLD: 1, EPOCH: 24,train_loss: 0.01428196625109168, valid_loss: 0.016667514560478075\nFOLD: 2, EPOCH: 0,train_loss: 0.738061832776968, valid_loss: 0.7036521094185966\nSEED: 2, FOLD: 2, EPOCH: 0,train_loss: 0.46659398803730373, valid_loss: 0.02402640235211168\nSEED: 2, FOLD: 2, EPOCH: 1,train_loss: 0.020945292857030163, valid_loss: 0.01867219845631293\nSEED: 2, FOLD: 2, EPOCH: 2,train_loss: 0.01897515475318052, valid_loss: 0.018049386755696364\nSEED: 2, FOLD: 2, EPOCH: 3,train_loss: 0.018175616320492565, valid_loss: 0.017928155378571578\nSEED: 2, FOLD: 2, EPOCH: 4,train_loss: 0.017841181792048872, valid_loss: 0.017857156268187933\nSEED: 2, FOLD: 2, EPOCH: 5,train_loss: 0.017820314558195896, valid_loss: 0.018169602405812058\nSEED: 2, FOLD: 2, EPOCH: 6,train_loss: 0.01782218519382287, valid_loss: 0.017774135938712528\nSEED: 2, FOLD: 2, EPOCH: 7,train_loss: 0.017809228445200817, valid_loss: 0.017806469622467246\nSEED: 2, FOLD: 2, EPOCH: 8,train_loss: 0.017785795120711344, valid_loss: 0.01798969618976116\nSEED: 2, FOLD: 2, EPOCH: 9,train_loss: 0.01782351264568127, valid_loss: 0.017879723784114634\nSEED: 2, FOLD: 2, EPOCH: 10,train_loss: 0.01775940616979547, valid_loss: 0.017765741156680243\nSEED: 2, FOLD: 2, EPOCH: 11,train_loss: 0.017711630840178415, valid_loss: 0.017750334553420545\nSEED: 2, FOLD: 2, EPOCH: 12,train_loss: 0.01768135744403454, valid_loss: 0.017857343410806997\nSEED: 2, FOLD: 2, EPOCH: 13,train_loss: 0.017518229870314615, valid_loss: 0.017977945054216043\nSEED: 2, FOLD: 2, EPOCH: 14,train_loss: 0.017463718628699797, valid_loss: 0.017822517507842608\nSEED: 2, FOLD: 2, EPOCH: 15,train_loss: 0.01728778502539448, valid_loss: 0.017508541579757418\nSEED: 2, FOLD: 2, EPOCH: 16,train_loss: 0.017045986217757065, valid_loss: 0.01766184988830771\nSEED: 2, FOLD: 2, EPOCH: 17,train_loss: 0.01690804622932405, valid_loss: 0.017426337700869356\nSEED: 2, FOLD: 2, EPOCH: 18,train_loss: 0.016541274163224127, valid_loss: 0.017523672564753463\nSEED: 2, FOLD: 2, EPOCH: 19,train_loss: 0.0161973536082044, valid_loss: 0.01743991303124598\nSEED: 2, FOLD: 2, EPOCH: 20,train_loss: 0.015799323123866234, valid_loss: 0.01735758257231542\nSEED: 2, FOLD: 2, EPOCH: 21,train_loss: 0.01532809499759173, valid_loss: 0.017285346612334253\nSEED: 2, FOLD: 2, EPOCH: 22,train_loss: 0.014805381955659908, valid_loss: 0.017305259060646807\nSEED: 2, FOLD: 2, EPOCH: 23,train_loss: 0.014331619025788445, valid_loss: 0.017302487125354152\nSEED: 2, FOLD: 2, EPOCH: 24,train_loss: 0.014100045444902735, valid_loss: 0.017309654371014664\nFOLD: 3, EPOCH: 0,train_loss: 0.7379806537697785, valid_loss: 0.7072644693510873\nSEED: 2, FOLD: 3, EPOCH: 0,train_loss: 0.4677053796412953, valid_loss: 0.02419823684862682\nSEED: 2, FOLD: 3, EPOCH: 1,train_loss: 0.020912280714098553, valid_loss: 0.018911400277699743\nSEED: 2, FOLD: 3, EPOCH: 2,train_loss: 0.019101617327571787, valid_loss: 0.018416476941534452\nSEED: 2, FOLD: 3, EPOCH: 3,train_loss: 0.01808978538334805, valid_loss: 0.018502790933208807\nSEED: 2, FOLD: 3, EPOCH: 4,train_loss: 0.01785257521907996, valid_loss: 0.018003781751862593\nSEED: 2, FOLD: 3, EPOCH: 5,train_loss: 0.01774853728983524, valid_loss: 0.018843214000974384\nSEED: 2, FOLD: 3, EPOCH: 6,train_loss: 0.017801890469217388, valid_loss: 0.018030116068465368\nSEED: 2, FOLD: 3, EPOCH: 7,train_loss: 0.01775042688215736, valid_loss: 0.01796407742159707\nSEED: 2, FOLD: 3, EPOCH: 8,train_loss: 0.017814878394732076, valid_loss: 0.018378126647855555\nSEED: 2, FOLD: 3, EPOCH: 9,train_loss: 0.017764939872180894, valid_loss: 0.01805981434881687\nSEED: 2, FOLD: 3, EPOCH: 10,train_loss: 0.017649182995414212, valid_loss: 0.018164362705179623\nSEED: 2, FOLD: 3, EPOCH: 11,train_loss: 0.017703270628015057, valid_loss: 0.017959883676043578\nSEED: 2, FOLD: 3, EPOCH: 12,train_loss: 0.01763542797280489, valid_loss: 0.01811778646494661\nSEED: 2, FOLD: 3, EPOCH: 13,train_loss: 0.01750886798530382, valid_loss: 0.017868972569704055\nSEED: 2, FOLD: 3, EPOCH: 14,train_loss: 0.01743702725745248, valid_loss: 0.01774673592299223\nSEED: 2, FOLD: 3, EPOCH: 15,train_loss: 0.017275505012621845, valid_loss: 0.017604139207729273\nSEED: 2, FOLD: 3, EPOCH: 16,train_loss: 0.017105744750558458, valid_loss: 0.017631435420896326\nSEED: 2, FOLD: 3, EPOCH: 17,train_loss: 0.01686908977011042, valid_loss: 0.01752418838441372\nSEED: 2, FOLD: 3, EPOCH: 18,train_loss: 0.016586822002147235, valid_loss: 0.017571320331522398\nSEED: 2, FOLD: 3, EPOCH: 19,train_loss: 0.01625638415044459, valid_loss: 0.017434917390346527\nSEED: 2, FOLD: 3, EPOCH: 20,train_loss: 0.01580966819404033, valid_loss: 0.017366827332547734\nSEED: 2, FOLD: 3, EPOCH: 21,train_loss: 0.01530731538052324, valid_loss: 0.01746973491140774\nSEED: 2, FOLD: 3, EPOCH: 22,train_loss: 0.01482779998332262, valid_loss: 0.01737322099506855\nSEED: 2, FOLD: 3, EPOCH: 23,train_loss: 0.014379345145701926, valid_loss: 0.01733522162373577\nSEED: 2, FOLD: 3, EPOCH: 24,train_loss: 0.014161541656910503, valid_loss: 0.01732287843312536\nFOLD: 4, EPOCH: 0,train_loss: 0.7379032170427018, valid_loss: 0.7056873236383711\nSEED: 2, FOLD: 4, EPOCH: 0,train_loss: 0.46639298115843447, valid_loss: 0.024472212312476975\nSEED: 2, FOLD: 4, EPOCH: 1,train_loss: 0.02075743273008561, valid_loss: 0.019391477001564843\nSEED: 2, FOLD: 4, EPOCH: 2,train_loss: 0.018743395049502884, valid_loss: 0.018725663955722536\nSEED: 2, FOLD: 4, EPOCH: 3,train_loss: 0.018084558158896973, valid_loss: 0.018646525937531674\nSEED: 2, FOLD: 4, EPOCH: 4,train_loss: 0.01774754087049244, valid_loss: 0.01838629184556859\nSEED: 2, FOLD: 4, EPOCH: 5,train_loss: 0.017740046443498653, valid_loss: 0.018427814516638007\nSEED: 2, FOLD: 4, EPOCH: 6,train_loss: 0.01767085929252747, valid_loss: 0.01874609837042434\nSEED: 2, FOLD: 4, EPOCH: 7,train_loss: 0.01767941423273389, valid_loss: 0.018670812302402088\nSEED: 2, FOLD: 4, EPOCH: 8,train_loss: 0.017752052021577307, valid_loss: 0.01883153606738363\nSEED: 2, FOLD: 4, EPOCH: 9,train_loss: 0.017717232765710873, valid_loss: 0.018863121100834438\nSEED: 2, FOLD: 4, EPOCH: 10,train_loss: 0.017636081129582464, valid_loss: 0.018544486697231022\nSEED: 2, FOLD: 4, EPOCH: 11,train_loss: 0.017581560912177614, valid_loss: 0.018746820837259294\nSEED: 2, FOLD: 4, EPOCH: 12,train_loss: 0.017534110053995813, valid_loss: 0.01876065651220935\nSEED: 2, FOLD: 4, EPOCH: 13,train_loss: 0.017425962986991457, valid_loss: 0.018442484523568836\nSEED: 2, FOLD: 4, EPOCH: 14,train_loss: 0.01732361069003093, valid_loss: 0.018284601239221435\nSEED: 2, FOLD: 4, EPOCH: 15,train_loss: 0.01715942515411239, valid_loss: 0.018311077090246337\nSEED: 2, FOLD: 4, EPOCH: 16,train_loss: 0.01697967275707186, valid_loss: 0.01822353710553476\nSEED: 2, FOLD: 4, EPOCH: 17,train_loss: 0.016768598834565586, valid_loss: 0.018167523268078054\nSEED: 2, FOLD: 4, EPOCH: 18,train_loss: 0.016484818576524656, valid_loss: 0.017957228980958462\nSEED: 2, FOLD: 4, EPOCH: 19,train_loss: 0.016137013731497354, valid_loss: 0.018110555703086513\nSEED: 2, FOLD: 4, EPOCH: 20,train_loss: 0.015718568129923897, valid_loss: 0.01781317187207086\nSEED: 2, FOLD: 4, EPOCH: 21,train_loss: 0.015254828943938448, valid_loss: 0.017827546117561203\nSEED: 2, FOLD: 4, EPOCH: 22,train_loss: 0.01472897380185516, valid_loss: 0.017818270570465495\nSEED: 2, FOLD: 4, EPOCH: 23,train_loss: 0.014317810481441194, valid_loss: 0.017814408562013082\nSEED: 2, FOLD: 4, EPOCH: 24,train_loss: 0.014064444100781195, valid_loss: 0.017813362048140595\nFOLD: 0, EPOCH: 0,train_loss: 0.7344647481821586, valid_loss: 0.6941100324903215\nSEED: 3, FOLD: 0, EPOCH: 0,train_loss: 0.46589468565324077, valid_loss: 0.023588752107960836\nSEED: 3, FOLD: 0, EPOCH: 1,train_loss: 0.020842017889346764, valid_loss: 0.019007698313466142\nSEED: 3, FOLD: 0, EPOCH: 2,train_loss: 0.018919427811667538, valid_loss: 0.01806895608481552\nSEED: 3, FOLD: 0, EPOCH: 3,train_loss: 0.01832213302048436, valid_loss: 0.017876464926770756\nSEED: 3, FOLD: 0, EPOCH: 4,train_loss: 0.017822024911858032, valid_loss: 0.01785469845469509\nSEED: 3, FOLD: 0, EPOCH: 5,train_loss: 0.017761593725046387, valid_loss: 0.017851054023153016\nSEED: 3, FOLD: 0, EPOCH: 6,train_loss: 0.01775879382520266, valid_loss: 0.017789798795378634\nSEED: 3, FOLD: 0, EPOCH: 7,train_loss: 0.017825830768307915, valid_loss: 0.017583075391926935\nSEED: 3, FOLD: 0, EPOCH: 8,train_loss: 0.017834619936141848, valid_loss: 0.01757009159773588\nSEED: 3, FOLD: 0, EPOCH: 9,train_loss: 0.01778705642167209, valid_loss: 0.017687024814741954\nSEED: 3, FOLD: 0, EPOCH: 10,train_loss: 0.01773493033091443, valid_loss: 0.017899516484301006\nSEED: 3, FOLD: 0, EPOCH: 11,train_loss: 0.01770137730257019, valid_loss: 0.01743317643579628\nSEED: 3, FOLD: 0, EPOCH: 12,train_loss: 0.017591100503299116, valid_loss: 0.017636475672147104\nSEED: 3, FOLD: 0, EPOCH: 13,train_loss: 0.017532040196322443, valid_loss: 0.01760244834502893\nSEED: 3, FOLD: 0, EPOCH: 14,train_loss: 0.017398436789981264, valid_loss: 0.017453099690776852\nSEED: 3, FOLD: 0, EPOCH: 15,train_loss: 0.017240239152063925, valid_loss: 0.017196611451384212\nSEED: 3, FOLD: 0, EPOCH: 16,train_loss: 0.017052057617600414, valid_loss: 0.01735434093778687\nSEED: 3, FOLD: 0, EPOCH: 17,train_loss: 0.0168074032669698, valid_loss: 0.017229581151955893\nSEED: 3, FOLD: 0, EPOCH: 18,train_loss: 0.01652894060437878, valid_loss: 0.017105329309457115\nSEED: 3, FOLD: 0, EPOCH: 19,train_loss: 0.016178427405817354, valid_loss: 0.017076597535716637\nSEED: 3, FOLD: 0, EPOCH: 20,train_loss: 0.015801471286871725, valid_loss: 0.017134612512641718\nSEED: 3, FOLD: 0, EPOCH: 21,train_loss: 0.015312459110619797, valid_loss: 0.017023095541766713\nSEED: 3, FOLD: 0, EPOCH: 22,train_loss: 0.014810369964149118, valid_loss: 0.017044393472107393\nSEED: 3, FOLD: 0, EPOCH: 23,train_loss: 0.014373086433371773, valid_loss: 0.01704574332772089\nSEED: 3, FOLD: 0, EPOCH: 24,train_loss: 0.014141417587634878, valid_loss: 0.017053643384549233\nFOLD: 1, EPOCH: 0,train_loss: 0.7349957076535709, valid_loss: 0.6938519103186471\nSEED: 3, FOLD: 1, EPOCH: 0,train_loss: 0.465767413067321, valid_loss: 0.024218104779720306\nSEED: 3, FOLD: 1, EPOCH: 1,train_loss: 0.020654127730623535, valid_loss: 0.018417605119092125\nSEED: 3, FOLD: 1, EPOCH: 2,train_loss: 0.01868852611253227, valid_loss: 0.018108393996953964\nSEED: 3, FOLD: 1, EPOCH: 3,train_loss: 0.018134577685724133, valid_loss: 0.018888827998723302\nSEED: 3, FOLD: 1, EPOCH: 4,train_loss: 0.017931580334307924, valid_loss: 0.017794504681868214\nSEED: 3, FOLD: 1, EPOCH: 5,train_loss: 0.017895817682416975, valid_loss: 0.017921172987137524\nSEED: 3, FOLD: 1, EPOCH: 6,train_loss: 0.017884819403938625, valid_loss: 0.0180470595402377\nSEED: 3, FOLD: 1, EPOCH: 7,train_loss: 0.01788765341853318, valid_loss: 0.017963204000677382\nSEED: 3, FOLD: 1, EPOCH: 8,train_loss: 0.017816083849934133, valid_loss: 0.017907929899437087\nSEED: 3, FOLD: 1, EPOCH: 9,train_loss: 0.017831282028793426, valid_loss: 0.017613609481070724\nSEED: 3, FOLD: 1, EPOCH: 10,train_loss: 0.01779976458815129, valid_loss: 0.017850036839289325\nSEED: 3, FOLD: 1, EPOCH: 11,train_loss: 0.017755999040884384, valid_loss: 0.01758782994002104\nSEED: 3, FOLD: 1, EPOCH: 12,train_loss: 0.01766462508670014, valid_loss: 0.01743759731096881\nSEED: 3, FOLD: 1, EPOCH: 13,train_loss: 0.017595277235343838, valid_loss: 0.017727415210434368\nSEED: 3, FOLD: 1, EPOCH: 14,train_loss: 0.0174634899282693, valid_loss: 0.017670789627092225\nSEED: 3, FOLD: 1, EPOCH: 15,train_loss: 0.017385012470185757, valid_loss: 0.017388825437852314\nSEED: 3, FOLD: 1, EPOCH: 16,train_loss: 0.01720252569656873, valid_loss: 0.017343544108527047\nSEED: 3, FOLD: 1, EPOCH: 17,train_loss: 0.016908660483803007, valid_loss: 0.01739094459584781\nSEED: 3, FOLD: 1, EPOCH: 18,train_loss: 0.016700082391068554, valid_loss: 0.017240044341555665\nSEED: 3, FOLD: 1, EPOCH: 19,train_loss: 0.016345091609527237, valid_loss: 0.017300703482968468\nSEED: 3, FOLD: 1, EPOCH: 20,train_loss: 0.015898428054229505, valid_loss: 0.01711422359304769\nSEED: 3, FOLD: 1, EPOCH: 21,train_loss: 0.015397237262864044, valid_loss: 0.017139821951942785\nSEED: 3, FOLD: 1, EPOCH: 22,train_loss: 0.014915647902998371, valid_loss: 0.01718327985810382\nSEED: 3, FOLD: 1, EPOCH: 23,train_loss: 0.014459495459669743, valid_loss: 0.017140279444200653\nSEED: 3, FOLD: 1, EPOCH: 24,train_loss: 0.014236684092253015, valid_loss: 0.01714458790208612\nFOLD: 2, EPOCH: 0,train_loss: 0.7342789673457181, valid_loss: 0.6949436221803937\nSEED: 3, FOLD: 2, EPOCH: 0,train_loss: 0.468272543179184, valid_loss: 0.02381891682744026\nSEED: 3, FOLD: 2, EPOCH: 1,train_loss: 0.020749715000499776, valid_loss: 0.019158932540033546\nSEED: 3, FOLD: 2, EPOCH: 2,train_loss: 0.01879892518648701, valid_loss: 0.018261477697108473\nSEED: 3, FOLD: 2, EPOCH: 3,train_loss: 0.018120228727586077, valid_loss: 0.018113798568291324\nSEED: 3, FOLD: 2, EPOCH: 4,train_loss: 0.01778448567501385, valid_loss: 0.018543161771127154\nSEED: 3, FOLD: 2, EPOCH: 5,train_loss: 0.01781126850005919, valid_loss: 0.01850786440606628\nSEED: 3, FOLD: 2, EPOCH: 6,train_loss: 0.017821418427365975, valid_loss: 0.018251098559371064\nSEED: 3, FOLD: 2, EPOCH: 7,train_loss: 0.017771120964936965, valid_loss: 0.018161153447415146\nSEED: 3, FOLD: 2, EPOCH: 8,train_loss: 0.017849006601711258, valid_loss: 0.018051480209188803\nSEED: 3, FOLD: 2, EPOCH: 9,train_loss: 0.017815923896094744, valid_loss: 0.018182484645928657\nSEED: 3, FOLD: 2, EPOCH: 10,train_loss: 0.017745120607207725, valid_loss: 0.01790311171540192\nSEED: 3, FOLD: 2, EPOCH: 11,train_loss: 0.01771792084196188, valid_loss: 0.018086827812450273\nSEED: 3, FOLD: 2, EPOCH: 12,train_loss: 0.01759382858736454, valid_loss: 0.018002645751195295\nSEED: 3, FOLD: 2, EPOCH: 13,train_loss: 0.017528273722659932, valid_loss: 0.017912441066333225\nSEED: 3, FOLD: 2, EPOCH: 14,train_loss: 0.01740781875177674, valid_loss: 0.01788126781050648\nSEED: 3, FOLD: 2, EPOCH: 15,train_loss: 0.01725760646789831, valid_loss: 0.017750146479478906\nSEED: 3, FOLD: 2, EPOCH: 16,train_loss: 0.017085768771867682, valid_loss: 0.01770723502018622\nSEED: 3, FOLD: 2, EPOCH: 17,train_loss: 0.016845191679351085, valid_loss: 0.0176445356171046\nSEED: 3, FOLD: 2, EPOCH: 18,train_loss: 0.016589370977650158, valid_loss: 0.017450083260025298\nSEED: 3, FOLD: 2, EPOCH: 19,train_loss: 0.016217231832063982, valid_loss: 0.01736854857632092\nSEED: 3, FOLD: 2, EPOCH: 20,train_loss: 0.01580119733936595, valid_loss: 0.017403489723801614\nSEED: 3, FOLD: 2, EPOCH: 21,train_loss: 0.015300747516979702, valid_loss: 0.01733556323285614\nSEED: 3, FOLD: 2, EPOCH: 22,train_loss: 0.014787118351698792, valid_loss: 0.017366749473980495\nSEED: 3, FOLD: 2, EPOCH: 23,train_loss: 0.014358783385505641, valid_loss: 0.01734272302793605\nSEED: 3, FOLD: 2, EPOCH: 24,train_loss: 0.014116588952767588, valid_loss: 0.01732724141329527\nFOLD: 3, EPOCH: 0,train_loss: 0.7348025125869806, valid_loss: 0.6906725951603481\nSEED: 3, FOLD: 3, EPOCH: 0,train_loss: 0.4659973960774748, valid_loss: 0.024617464521101542\nSEED: 3, FOLD: 3, EPOCH: 1,train_loss: 0.021035148208771927, valid_loss: 0.02044354679861239\nSEED: 3, FOLD: 3, EPOCH: 2,train_loss: 0.019386175560994423, valid_loss: 0.01819273672465767\nSEED: 3, FOLD: 3, EPOCH: 3,train_loss: 0.01826481315968693, valid_loss: 0.017696382185178144\nSEED: 3, FOLD: 3, EPOCH: 4,train_loss: 0.01791994588152654, valid_loss: 0.01801459677517414\nSEED: 3, FOLD: 3, EPOCH: 5,train_loss: 0.017946039043042972, valid_loss: 0.01786587310156652\nSEED: 3, FOLD: 3, EPOCH: 6,train_loss: 0.017883005862434704, valid_loss: 0.01767114283783095\nSEED: 3, FOLD: 3, EPOCH: 7,train_loss: 0.017896538492346157, valid_loss: 0.017887231255216258\nSEED: 3, FOLD: 3, EPOCH: 8,train_loss: 0.017862017205713884, valid_loss: 0.017782112556908813\nSEED: 3, FOLD: 3, EPOCH: 9,train_loss: 0.017854909129116848, valid_loss: 0.01811730545014143\nSEED: 3, FOLD: 3, EPOCH: 10,train_loss: 0.017843550806730123, valid_loss: 0.017659194421555315\nSEED: 3, FOLD: 3, EPOCH: 11,train_loss: 0.017737130236312532, valid_loss: 0.017631905525922774\nSEED: 3, FOLD: 3, EPOCH: 12,train_loss: 0.01764652656013335, valid_loss: 0.01784006277365344\nSEED: 3, FOLD: 3, EPOCH: 13,train_loss: 0.01762381721072007, valid_loss: 0.017558842232184752\nSEED: 3, FOLD: 3, EPOCH: 14,train_loss: 0.017487592569997778, valid_loss: 0.017536482853548866\nSEED: 3, FOLD: 3, EPOCH: 15,train_loss: 0.017364025284684656, valid_loss: 0.01773053269301142\nSEED: 3, FOLD: 3, EPOCH: 16,train_loss: 0.01718526552228824, valid_loss: 0.017344187492770807\nSEED: 3, FOLD: 3, EPOCH: 17,train_loss: 0.01690578084115101, valid_loss: 0.017366368296955315\nSEED: 3, FOLD: 3, EPOCH: 18,train_loss: 0.016649375480694183, valid_loss: 0.017618001784597125\nSEED: 3, FOLD: 3, EPOCH: 19,train_loss: 0.01633018769485795, valid_loss: 0.01721004785171577\nSEED: 3, FOLD: 3, EPOCH: 20,train_loss: 0.015888428970145575, valid_loss: 0.01731261680168765\nSEED: 3, FOLD: 3, EPOCH: 21,train_loss: 0.015404235868566278, valid_loss: 0.017212116585246153\nSEED: 3, FOLD: 3, EPOCH: 22,train_loss: 0.014840850701042707, valid_loss: 0.017229147468294417\nSEED: 3, FOLD: 3, EPOCH: 23,train_loss: 0.014413429727858824, valid_loss: 0.01723350291805608\nSEED: 3, FOLD: 3, EPOCH: 24,train_loss: 0.01415269903541691, valid_loss: 0.01722900705145938\nFOLD: 4, EPOCH: 0,train_loss: 0.7343464463296598, valid_loss: 0.6946517263139997\nSEED: 3, FOLD: 4, EPOCH: 0,train_loss: 0.46737979527861967, valid_loss: 0.023323919038687434\nSEED: 3, FOLD: 4, EPOCH: 1,train_loss: 0.020971209517795675, valid_loss: 0.018527140681232724\nSEED: 3, FOLD: 4, EPOCH: 2,train_loss: 0.019068753836255004, valid_loss: 0.018285109209162848\nSEED: 3, FOLD: 4, EPOCH: 3,train_loss: 0.018413910642266273, valid_loss: 0.01756196455763919\nSEED: 3, FOLD: 4, EPOCH: 4,train_loss: 0.018093565356557387, valid_loss: 0.017421692636396202\nSEED: 3, FOLD: 4, EPOCH: 5,train_loss: 0.017965077069064563, valid_loss: 0.017469779375408376\nSEED: 3, FOLD: 4, EPOCH: 6,train_loss: 0.017940505829225056, valid_loss: 0.01755427968289171\nSEED: 3, FOLD: 4, EPOCH: 7,train_loss: 0.017984632674577464, valid_loss: 0.01765752498592649\nSEED: 3, FOLD: 4, EPOCH: 8,train_loss: 0.017973107625696347, valid_loss: 0.01775805511112724\nSEED: 3, FOLD: 4, EPOCH: 9,train_loss: 0.017900620077322, valid_loss: 0.017650114771510874\nSEED: 3, FOLD: 4, EPOCH: 10,train_loss: 0.017851464314399844, valid_loss: 0.017468449047633578\nSEED: 3, FOLD: 4, EPOCH: 11,train_loss: 0.017821010868370967, valid_loss: 0.017306615172752313\nSEED: 3, FOLD: 4, EPOCH: 12,train_loss: 0.01773341966752153, valid_loss: 0.017269538901746272\nSEED: 3, FOLD: 4, EPOCH: 13,train_loss: 0.01766605635112437, valid_loss: 0.017355173054550376\nSEED: 3, FOLD: 4, EPOCH: 14,train_loss: 0.017523877431441397, valid_loss: 0.017211378844720977\nSEED: 3, FOLD: 4, EPOCH: 15,train_loss: 0.017355087396763537, valid_loss: 0.01714937122804778\nSEED: 3, FOLD: 4, EPOCH: 16,train_loss: 0.017168909787152804, valid_loss: 0.017317371921879904\nSEED: 3, FOLD: 4, EPOCH: 17,train_loss: 0.016963532085727602, valid_loss: 0.017033027963978903\nSEED: 3, FOLD: 4, EPOCH: 18,train_loss: 0.016627173959175602, valid_loss: 0.0169509300163814\nSEED: 3, FOLD: 4, EPOCH: 19,train_loss: 0.016293495873084467, valid_loss: 0.017104433716407845\nSEED: 3, FOLD: 4, EPOCH: 20,train_loss: 0.015875349677827236, valid_loss: 0.016931876141045774\nSEED: 3, FOLD: 4, EPOCH: 21,train_loss: 0.015379390223835507, valid_loss: 0.016896280885807104\nSEED: 3, FOLD: 4, EPOCH: 22,train_loss: 0.014866187787839096, valid_loss: 0.016846228896507196\nSEED: 3, FOLD: 4, EPOCH: 23,train_loss: 0.014424648224274172, valid_loss: 0.01682662365159818\nSEED: 3, FOLD: 4, EPOCH: 24,train_loss: 0.014177380714320788, valid_loss: 0.016865927459938184\nFOLD: 0, EPOCH: 0,train_loss: 0.7338663076145061, valid_loss: 0.7073965345110212\nSEED: 4, FOLD: 0, EPOCH: 0,train_loss: 0.467595302729287, valid_loss: 0.024826666499887195\nSEED: 4, FOLD: 0, EPOCH: 1,train_loss: 0.020958393650210422, valid_loss: 0.019222637957760264\nSEED: 4, FOLD: 0, EPOCH: 2,train_loss: 0.01904240664958522, valid_loss: 0.018259771540760993\nSEED: 4, FOLD: 0, EPOCH: 3,train_loss: 0.01823243728933343, valid_loss: 0.018221090734004974\nSEED: 4, FOLD: 0, EPOCH: 4,train_loss: 0.01788529113906881, valid_loss: 0.017877409420907497\nSEED: 4, FOLD: 0, EPOCH: 5,train_loss: 0.0179377857433713, valid_loss: 0.018380635231733323\nSEED: 4, FOLD: 0, EPOCH: 6,train_loss: 0.01789714672697195, valid_loss: 0.01800857904766287\nSEED: 4, FOLD: 0, EPOCH: 7,train_loss: 0.0178867738990896, valid_loss: 0.017718926178557533\nSEED: 4, FOLD: 0, EPOCH: 8,train_loss: 0.017912834902982348, valid_loss: 0.01806792209723166\nSEED: 4, FOLD: 0, EPOCH: 9,train_loss: 0.017819535986020946, valid_loss: 0.01812469693166869\nSEED: 4, FOLD: 0, EPOCH: 10,train_loss: 0.017808614474167858, valid_loss: 0.0178445003926754\nSEED: 4, FOLD: 0, EPOCH: 11,train_loss: 0.017734703405395798, valid_loss: 0.017713052300470215\nSEED: 4, FOLD: 0, EPOCH: 12,train_loss: 0.017641285015944985, valid_loss: 0.017848279380372593\nSEED: 4, FOLD: 0, EPOCH: 13,train_loss: 0.017577057191427204, valid_loss: 0.01782427126807826\nSEED: 4, FOLD: 0, EPOCH: 14,train_loss: 0.017450383142230734, valid_loss: 0.017574372781174522\nSEED: 4, FOLD: 0, EPOCH: 15,train_loss: 0.017306953830563503, valid_loss: 0.01740144616258996\nSEED: 4, FOLD: 0, EPOCH: 16,train_loss: 0.01719518352056975, valid_loss: 0.01735484299382993\nSEED: 4, FOLD: 0, EPOCH: 17,train_loss: 0.016882488571539307, valid_loss: 0.01737029246453728\nSEED: 4, FOLD: 0, EPOCH: 18,train_loss: 0.016575999517479668, valid_loss: 0.017232527637055944\nSEED: 4, FOLD: 0, EPOCH: 19,train_loss: 0.016257491705102333, valid_loss: 0.01728816990341459\nSEED: 4, FOLD: 0, EPOCH: 20,train_loss: 0.015846996203712795, valid_loss: 0.017108049696045263\nSEED: 4, FOLD: 0, EPOCH: 21,train_loss: 0.015317834232110476, valid_loss: 0.017163054990981308\nSEED: 4, FOLD: 0, EPOCH: 22,train_loss: 0.014803969429508932, valid_loss: 0.017166902683675288\nSEED: 4, FOLD: 0, EPOCH: 23,train_loss: 0.014372138346990814, valid_loss: 0.017134326989097254\nSEED: 4, FOLD: 0, EPOCH: 24,train_loss: 0.01409667334181891, valid_loss: 0.01715984112982239\nFOLD: 1, EPOCH: 0,train_loss: 0.7341207170831985, valid_loss: 0.7067737614407259\nSEED: 4, FOLD: 1, EPOCH: 0,train_loss: 0.4676008370259534, valid_loss: 0.023911897914812845\nSEED: 4, FOLD: 1, EPOCH: 1,train_loss: 0.020729581946912018, valid_loss: 0.019002492566976475\nSEED: 4, FOLD: 1, EPOCH: 2,train_loss: 0.0187349672820689, valid_loss: 0.01867182199459742\nSEED: 4, FOLD: 1, EPOCH: 3,train_loss: 0.01811309660906377, valid_loss: 0.018772352815550918\nSEED: 4, FOLD: 1, EPOCH: 4,train_loss: 0.017854562623129375, valid_loss: 0.018197035280001515\nSEED: 4, FOLD: 1, EPOCH: 5,train_loss: 0.017727391922549494, valid_loss: 0.018436612670912463\nSEED: 4, FOLD: 1, EPOCH: 6,train_loss: 0.01773309777153359, valid_loss: 0.018543530693825555\nSEED: 4, FOLD: 1, EPOCH: 7,train_loss: 0.017742827136501455, valid_loss: 0.01871456392109394\nSEED: 4, FOLD: 1, EPOCH: 8,train_loss: 0.017763555117383385, valid_loss: 0.018065623035106587\nSEED: 4, FOLD: 1, EPOCH: 9,train_loss: 0.01778078773666335, valid_loss: 0.018037839381791213\nSEED: 4, FOLD: 1, EPOCH: 10,train_loss: 0.017671290130448946, valid_loss: 0.01794385288239402\nSEED: 4, FOLD: 1, EPOCH: 11,train_loss: 0.017670292191315388, valid_loss: 0.017921701155822065\nSEED: 4, FOLD: 1, EPOCH: 12,train_loss: 0.01756937555509849, valid_loss: 0.01810077131342362\nSEED: 4, FOLD: 1, EPOCH: 13,train_loss: 0.017489188532952383, valid_loss: 0.01792290836901349\nSEED: 4, FOLD: 1, EPOCH: 14,train_loss: 0.017342296105040157, valid_loss: 0.017756492529502687\nSEED: 4, FOLD: 1, EPOCH: 15,train_loss: 0.017223892234049847, valid_loss: 0.017790317288873828\nSEED: 4, FOLD: 1, EPOCH: 16,train_loss: 0.017025608164460762, valid_loss: 0.017633006387554547\nSEED: 4, FOLD: 1, EPOCH: 17,train_loss: 0.016778996369491022, valid_loss: 0.017615222016020733\nSEED: 4, FOLD: 1, EPOCH: 18,train_loss: 0.016495414361681626, valid_loss: 0.017698380027842874\nSEED: 4, FOLD: 1, EPOCH: 19,train_loss: 0.016154055146203525, valid_loss: 0.017464208170114195\nSEED: 4, FOLD: 1, EPOCH: 20,train_loss: 0.015684891478630943, valid_loss: 0.017559012014637974\nSEED: 4, FOLD: 1, EPOCH: 21,train_loss: 0.015248627368144798, valid_loss: 0.01743489394293112\nSEED: 4, FOLD: 1, EPOCH: 22,train_loss: 0.014717379881851915, valid_loss: 0.017479526782956195\nSEED: 4, FOLD: 1, EPOCH: 23,train_loss: 0.014252419887191576, valid_loss: 0.017453814500614125\nSEED: 4, FOLD: 1, EPOCH: 24,train_loss: 0.01401313069694932, valid_loss: 0.01746040873010369\nFOLD: 2, EPOCH: 0,train_loss: 0.73419597313024, valid_loss: 0.7085948007447379\nSEED: 4, FOLD: 2, EPOCH: 0,train_loss: 0.46838538923665235, valid_loss: 0.02400860786437988\nSEED: 4, FOLD: 2, EPOCH: 1,train_loss: 0.02070933009457329, valid_loss: 0.018781078872936112\nSEED: 4, FOLD: 2, EPOCH: 2,train_loss: 0.018828752268429682, valid_loss: 0.01781614747430597\nSEED: 4, FOLD: 2, EPOCH: 3,train_loss: 0.018341746019280476, valid_loss: 0.017533912203673806\nSEED: 4, FOLD: 2, EPOCH: 4,train_loss: 0.01795942297178334, valid_loss: 0.017424860237432376\nSEED: 4, FOLD: 2, EPOCH: 5,train_loss: 0.01777805257723599, valid_loss: 0.017814218239592654\nSEED: 4, FOLD: 2, EPOCH: 6,train_loss: 0.017838559957032186, valid_loss: 0.017160279729536602\nSEED: 4, FOLD: 2, EPOCH: 7,train_loss: 0.017834261160991762, valid_loss: 0.017218966888529915\nSEED: 4, FOLD: 2, EPOCH: 8,train_loss: 0.01782603383037275, valid_loss: 0.017363756934979133\nSEED: 4, FOLD: 2, EPOCH: 9,train_loss: 0.017814011468241613, valid_loss: 0.017361608892679216\nSEED: 4, FOLD: 2, EPOCH: 10,train_loss: 0.017837276027632364, valid_loss: 0.017261841760150023\nSEED: 4, FOLD: 2, EPOCH: 11,train_loss: 0.01772338670907893, valid_loss: 0.01703240465638893\nSEED: 4, FOLD: 2, EPOCH: 12,train_loss: 0.017642457186635853, valid_loss: 0.017275460051106556\nSEED: 4, FOLD: 2, EPOCH: 13,train_loss: 0.017596790020394583, valid_loss: 0.017187579894172293\nSEED: 4, FOLD: 2, EPOCH: 14,train_loss: 0.017464090334386496, valid_loss: 0.016880580157573735\nSEED: 4, FOLD: 2, EPOCH: 15,train_loss: 0.017313420711814062, valid_loss: 0.017107532692274878\nSEED: 4, FOLD: 2, EPOCH: 16,train_loss: 0.017099881605447634, valid_loss: 0.016921598065112318\nSEED: 4, FOLD: 2, EPOCH: 17,train_loss: 0.016885653637565563, valid_loss: 0.016780036089143583\nSEED: 4, FOLD: 2, EPOCH: 18,train_loss: 0.01654240478882971, valid_loss: 0.016806496772915125\nSEED: 4, FOLD: 2, EPOCH: 19,train_loss: 0.01623501241935984, valid_loss: 0.016742668513740813\nSEED: 4, FOLD: 2, EPOCH: 20,train_loss: 0.01580640160735103, valid_loss: 0.016753061381833894\nSEED: 4, FOLD: 2, EPOCH: 21,train_loss: 0.015387171265277742, valid_loss: 0.016714200869734797\nSEED: 4, FOLD: 2, EPOCH: 22,train_loss: 0.01478464053808779, valid_loss: 0.016690797890935624\nSEED: 4, FOLD: 2, EPOCH: 23,train_loss: 0.014313674167446468, valid_loss: 0.01669490739170994\nSEED: 4, FOLD: 2, EPOCH: 24,train_loss: 0.014074141429602236, valid_loss: 0.016681529408586877\nFOLD: 3, EPOCH: 0,train_loss: 0.7343625301036282, valid_loss: 0.7130340950829642\nSEED: 4, FOLD: 3, EPOCH: 0,train_loss: 0.4682949219789842, valid_loss: 0.023635858403784887\nSEED: 4, FOLD: 3, EPOCH: 1,train_loss: 0.02136877812175215, valid_loss: 3.2140495879309516\nSEED: 4, FOLD: 3, EPOCH: 2,train_loss: 0.02078152342658976, valid_loss: 0.12567165110792433\nSEED: 4, FOLD: 3, EPOCH: 3,train_loss: 0.01977159969670617, valid_loss: 0.019096244286213603\nSEED: 4, FOLD: 3, EPOCH: 4,train_loss: 0.01901442934151577, valid_loss: 0.018605337451611248\nSEED: 4, FOLD: 3, EPOCH: 5,train_loss: 0.018672782657802967, valid_loss: 0.01844509249286992\nSEED: 4, FOLD: 3, EPOCH: 6,train_loss: 0.018599332397992628, valid_loss: 0.018775622174143792\nSEED: 4, FOLD: 3, EPOCH: 7,train_loss: 0.018736364157951397, valid_loss: 0.019276884464280945\nSEED: 4, FOLD: 3, EPOCH: 8,train_loss: 0.01853440334831459, valid_loss: 0.018006952612527778\nSEED: 4, FOLD: 3, EPOCH: 9,train_loss: 0.018414731650356796, valid_loss: 0.017993505485355853\nSEED: 4, FOLD: 3, EPOCH: 10,train_loss: 0.018309334232269422, valid_loss: 0.0177646383110966\nSEED: 4, FOLD: 3, EPOCH: 11,train_loss: 0.01811239473602694, valid_loss: 0.0183426633477211\nSEED: 4, FOLD: 3, EPOCH: 12,train_loss: 0.01803519314262962, valid_loss: 0.01833623429494245\nSEED: 4, FOLD: 3, EPOCH: 13,train_loss: 0.01817721089321202, valid_loss: 0.01828155368566513\nSEED: 4, FOLD: 3, EPOCH: 14,train_loss: 0.018030377921472857, valid_loss: 0.01741352118551731\nSEED: 4, FOLD: 3, EPOCH: 15,train_loss: 0.017673800274243822, valid_loss: 0.01739068151052509\nSEED: 4, FOLD: 3, EPOCH: 16,train_loss: 0.0177353501279393, valid_loss: 0.017209070894335\nSEED: 4, FOLD: 3, EPOCH: 17,train_loss: 0.01726839725818971, valid_loss: 0.017178563613976752\nSEED: 4, FOLD: 3, EPOCH: 18,train_loss: 0.01713907439261675, valid_loss: 0.017255491417433533\nSEED: 4, FOLD: 3, EPOCH: 19,train_loss: 0.016756951565975727, valid_loss: 0.017151265059198652\nSEED: 4, FOLD: 3, EPOCH: 20,train_loss: 0.016528179970286463, valid_loss: 0.017129476102335114\nSEED: 4, FOLD: 3, EPOCH: 21,train_loss: 0.016109187162710703, valid_loss: 0.017065640538930893\nSEED: 4, FOLD: 3, EPOCH: 22,train_loss: 0.015729543604496597, valid_loss: 0.01694893701268094\nSEED: 4, FOLD: 3, EPOCH: 23,train_loss: 0.015756693027535643, valid_loss: 0.01693493284817253\nSEED: 4, FOLD: 3, EPOCH: 24,train_loss: 0.015234602203565662, valid_loss: 0.016941958319927966\nFOLD: 4, EPOCH: 0,train_loss: 0.7341794641348567, valid_loss: 0.7050364119665963\nSEED: 4, FOLD: 4, EPOCH: 0,train_loss: 0.4686988710432592, valid_loss: 0.02376605272293091\nSEED: 4, FOLD: 4, EPOCH: 1,train_loss: 0.02095867630882855, valid_loss: 0.01919584779867104\nSEED: 4, FOLD: 4, EPOCH: 2,train_loss: 0.018982870225543087, valid_loss: 0.018875843552606447\nSEED: 4, FOLD: 4, EPOCH: 3,train_loss: 0.018209596762746354, valid_loss: 0.018000612620796476\nSEED: 4, FOLD: 4, EPOCH: 4,train_loss: 0.017842770520135436, valid_loss: 0.018046913615294865\nSEED: 4, FOLD: 4, EPOCH: 5,train_loss: 0.017793876825947397, valid_loss: 0.018001514779669898\nSEED: 4, FOLD: 4, EPOCH: 6,train_loss: 0.017789281646374368, valid_loss: 0.018229471359934125\nSEED: 4, FOLD: 4, EPOCH: 7,train_loss: 0.017750834244011093, valid_loss: 0.018024349957704543\nSEED: 4, FOLD: 4, EPOCH: 8,train_loss: 0.017782445799858465, valid_loss: 0.01838126185217074\nSEED: 4, FOLD: 4, EPOCH: 9,train_loss: 0.017822545647186085, valid_loss: 0.018178261896329265\nSEED: 4, FOLD: 4, EPOCH: 10,train_loss: 0.017775914903702963, valid_loss: 0.018181339305426394\nSEED: 4, FOLD: 4, EPOCH: 11,train_loss: 0.017678825055541348, valid_loss: 0.01804387713117259\nSEED: 4, FOLD: 4, EPOCH: 12,train_loss: 0.01765921097384752, valid_loss: 0.018081247487238477\nSEED: 4, FOLD: 4, EPOCH: 13,train_loss: 0.017569156417990252, valid_loss: 0.018062550202012063\nSEED: 4, FOLD: 4, EPOCH: 14,train_loss: 0.017424392622698397, valid_loss: 0.017793897805469378\nSEED: 4, FOLD: 4, EPOCH: 15,train_loss: 0.017232369278034156, valid_loss: 0.017746809577303273\nSEED: 4, FOLD: 4, EPOCH: 16,train_loss: 0.01710036706288148, valid_loss: 0.01756646798125335\nSEED: 4, FOLD: 4, EPOCH: 17,train_loss: 0.016866841863324173, valid_loss: 0.0175601457378694\nSEED: 4, FOLD: 4, EPOCH: 18,train_loss: 0.016591601848711064, valid_loss: 0.0175661011199866\nSEED: 4, FOLD: 4, EPOCH: 19,train_loss: 0.0162131318849695, valid_loss: 0.0175898547151259\nSEED: 4, FOLD: 4, EPOCH: 20,train_loss: 0.015817468251733885, valid_loss: 0.017495258498404706\nSEED: 4, FOLD: 4, EPOCH: 21,train_loss: 0.015399602357379711, valid_loss: 0.017375029996037482\nSEED: 4, FOLD: 4, EPOCH: 22,train_loss: 0.014834098558682595, valid_loss: 0.017449472871209893\nSEED: 4, FOLD: 4, EPOCH: 23,train_loss: 0.014417177331327956, valid_loss: 0.017461188696324827\nSEED: 4, FOLD: 4, EPOCH: 24,train_loss: 0.014176998219459596, valid_loss: 0.017442784644663333\nFOLD: 0, EPOCH: 0,train_loss: 0.7363871154577836, valid_loss: 0.7021701148578099\nSEED: 5, FOLD: 0, EPOCH: 0,train_loss: 0.4671905228085276, valid_loss: 0.023956027680209706\nSEED: 5, FOLD: 0, EPOCH: 1,train_loss: 0.021069572604112866, valid_loss: 0.01942207861159529\nSEED: 5, FOLD: 0, EPOCH: 2,train_loss: 0.019192449876741655, valid_loss: 0.0184244269239051\nSEED: 5, FOLD: 0, EPOCH: 3,train_loss: 0.018167247037416782, valid_loss: 0.01821253624345575\nSEED: 5, FOLD: 0, EPOCH: 4,train_loss: 0.017980932474028374, valid_loss: 0.01820365507155657\nSEED: 5, FOLD: 0, EPOCH: 5,train_loss: 0.017827916417972767, valid_loss: 0.01795809455215931\nSEED: 5, FOLD: 0, EPOCH: 6,train_loss: 0.017815729414207348, valid_loss: 0.018720401238117898\nSEED: 5, FOLD: 0, EPOCH: 7,train_loss: 0.017825290682199207, valid_loss: 0.018326845206320285\nSEED: 5, FOLD: 0, EPOCH: 8,train_loss: 0.017900611732856953, valid_loss: 0.018568603375128338\nSEED: 5, FOLD: 0, EPOCH: 9,train_loss: 0.01790021783064889, valid_loss: 0.018325862394911904\nSEED: 5, FOLD: 0, EPOCH: 10,train_loss: 0.017837051511404738, valid_loss: 0.01799501800643546\nSEED: 5, FOLD: 0, EPOCH: 11,train_loss: 0.01780731799215942, valid_loss: 0.018122074540172305\nSEED: 5, FOLD: 0, EPOCH: 12,train_loss: 0.01773245529393139, valid_loss: 0.017858976019280298\nSEED: 5, FOLD: 0, EPOCH: 13,train_loss: 0.017687453247228827, valid_loss: 0.017930513806641103\nSEED: 5, FOLD: 0, EPOCH: 14,train_loss: 0.0174186034195557, valid_loss: 0.017796438347016063\nSEED: 5, FOLD: 0, EPOCH: 15,train_loss: 0.01733155961593856, valid_loss: 0.017904039126421724\nSEED: 5, FOLD: 0, EPOCH: 16,train_loss: 0.01715909021542124, valid_loss: 0.01762140795056309\nSEED: 5, FOLD: 0, EPOCH: 17,train_loss: 0.016916662987753534, valid_loss: 0.017612112925520965\nSEED: 5, FOLD: 0, EPOCH: 18,train_loss: 0.01666497785355086, valid_loss: 0.017436697546924864\nSEED: 5, FOLD: 0, EPOCH: 19,train_loss: 0.01626736282006554, valid_loss: 0.01736725994518825\nSEED: 5, FOLD: 0, EPOCH: 20,train_loss: 0.01590353075036968, valid_loss: 0.017363766660647734\nSEED: 5, FOLD: 0, EPOCH: 21,train_loss: 0.015435661600929672, valid_loss: 0.0173434069114072\nSEED: 5, FOLD: 0, EPOCH: 22,train_loss: 0.014975275304438412, valid_loss: 0.017363148874470165\nSEED: 5, FOLD: 0, EPOCH: 23,train_loss: 0.014534669867514269, valid_loss: 0.017358441544430597\nSEED: 5, FOLD: 0, EPOCH: 24,train_loss: 0.01433325159376946, valid_loss: 0.017373383045196533\nFOLD: 1, EPOCH: 0,train_loss: 0.7364222568317051, valid_loss: 0.702619445323944\nSEED: 5, FOLD: 1, EPOCH: 0,train_loss: 0.4690605601309425, valid_loss: 0.02409268750676087\nSEED: 5, FOLD: 1, EPOCH: 1,train_loss: 0.020999661871116525, valid_loss: 0.01881530726594584\nSEED: 5, FOLD: 1, EPOCH: 2,train_loss: 0.01920974995587429, valid_loss: 0.018217044350292002\nSEED: 5, FOLD: 1, EPOCH: 3,train_loss: 0.01836824939878535, valid_loss: 0.0178997991340501\nSEED: 5, FOLD: 1, EPOCH: 4,train_loss: 0.017961429500014243, valid_loss: 0.017665281146764755\nSEED: 5, FOLD: 1, EPOCH: 5,train_loss: 0.017959128331093893, valid_loss: 0.01777585130184889\nSEED: 5, FOLD: 1, EPOCH: 6,train_loss: 0.017850924494003294, valid_loss: 0.017897671487714564\nSEED: 5, FOLD: 1, EPOCH: 7,train_loss: 0.01788507528385542, valid_loss: 0.017788254496242318\nSEED: 5, FOLD: 1, EPOCH: 8,train_loss: 0.01790567136022949, valid_loss: 0.017821406998804638\nSEED: 5, FOLD: 1, EPOCH: 9,train_loss: 0.017839575145583954, valid_loss: 0.01782759034207889\nSEED: 5, FOLD: 1, EPOCH: 10,train_loss: 0.017816238574357362, valid_loss: 0.01803664296333279\nSEED: 5, FOLD: 1, EPOCH: 11,train_loss: 0.017757158814827458, valid_loss: 0.017730743438005448\nSEED: 5, FOLD: 1, EPOCH: 12,train_loss: 0.017721589382765066, valid_loss: 0.017973696094538485\nSEED: 5, FOLD: 1, EPOCH: 13,train_loss: 0.017613820928781138, valid_loss: 0.01739445717207023\nSEED: 5, FOLD: 1, EPOCH: 14,train_loss: 0.017488636579500498, valid_loss: 0.017819256681416717\nSEED: 5, FOLD: 1, EPOCH: 15,train_loss: 0.01732236930733397, valid_loss: 0.01733239654983793\nSEED: 5, FOLD: 1, EPOCH: 16,train_loss: 0.017155792468982023, valid_loss: 0.017299701832234858\nSEED: 5, FOLD: 1, EPOCH: 17,train_loss: 0.016928118266110872, valid_loss: 0.017180419473775795\nSEED: 5, FOLD: 1, EPOCH: 18,train_loss: 0.01662872064804291, valid_loss: 0.017326112809990135\nSEED: 5, FOLD: 1, EPOCH: 19,train_loss: 0.016303215740099006, valid_loss: 0.017107650318316053\nSEED: 5, FOLD: 1, EPOCH: 20,train_loss: 0.01586328888053659, valid_loss: 0.017148968470948083\nSEED: 5, FOLD: 1, EPOCH: 21,train_loss: 0.015421509559191492, valid_loss: 0.017088972830346653\nSEED: 5, FOLD: 1, EPOCH: 22,train_loss: 0.014873471314998438, valid_loss: 0.017178466117807798\nSEED: 5, FOLD: 1, EPOCH: 23,train_loss: 0.014443250488571441, valid_loss: 0.017157910205423833\nSEED: 5, FOLD: 1, EPOCH: 24,train_loss: 0.01422430073883194, valid_loss: 0.017146875097283295\nFOLD: 2, EPOCH: 0,train_loss: 0.7360225311224011, valid_loss: 0.700458858694349\nSEED: 5, FOLD: 2, EPOCH: 0,train_loss: 0.467010041496352, valid_loss: 0.023120268221412388\nSEED: 5, FOLD: 2, EPOCH: 1,train_loss: 0.020902799577384754, valid_loss: 0.018374271371534894\nSEED: 5, FOLD: 2, EPOCH: 2,train_loss: 0.019274907510565674, valid_loss: 0.021100810755576405\nSEED: 5, FOLD: 2, EPOCH: 3,train_loss: 0.018715927485322605, valid_loss: 0.017632164220724788\nSEED: 5, FOLD: 2, EPOCH: 4,train_loss: 0.018113908567128405, valid_loss: 0.017529475635715892\nSEED: 5, FOLD: 2, EPOCH: 5,train_loss: 0.018021398925802845, valid_loss: 0.017904614018542427\nSEED: 5, FOLD: 2, EPOCH: 6,train_loss: 0.018050092603147463, valid_loss: 0.0176038157460945\nSEED: 5, FOLD: 2, EPOCH: 7,train_loss: 0.018007386475801468, valid_loss: 0.017355495771127088\nSEED: 5, FOLD: 2, EPOCH: 8,train_loss: 0.01806707543901343, valid_loss: 0.017669359355100563\nSEED: 5, FOLD: 2, EPOCH: 9,train_loss: 0.018018174741039242, valid_loss: 0.01749501686011042\nSEED: 5, FOLD: 2, EPOCH: 10,train_loss: 0.01792732281340421, valid_loss: 0.01745142601430416\nSEED: 5, FOLD: 2, EPOCH: 11,train_loss: 0.01791664472092753, valid_loss: 0.017397905167724406\nSEED: 5, FOLD: 2, EPOCH: 12,train_loss: 0.017824845354788114, valid_loss: 0.017416482897741455\nSEED: 5, FOLD: 2, EPOCH: 13,train_loss: 0.017791793944881014, valid_loss: 0.017148657089897563\nSEED: 5, FOLD: 2, EPOCH: 14,train_loss: 0.017611181606417118, valid_loss: 0.017754366701202732\nSEED: 5, FOLD: 2, EPOCH: 15,train_loss: 0.017514190076431936, valid_loss: 0.017243754251727035\nSEED: 5, FOLD: 2, EPOCH: 16,train_loss: 0.017230260428851066, valid_loss: 0.017034549239490715\nSEED: 5, FOLD: 2, EPOCH: 17,train_loss: 0.017091176830286135, valid_loss: 0.01698454131505319\nSEED: 5, FOLD: 2, EPOCH: 18,train_loss: 0.016804062633140795, valid_loss: 0.016879932156630924\nSEED: 5, FOLD: 2, EPOCH: 19,train_loss: 0.016460026479393677, valid_loss: 0.016799975080149514\nSEED: 5, FOLD: 2, EPOCH: 20,train_loss: 0.015991514271962038, valid_loss: 0.016712021880916188\nSEED: 5, FOLD: 2, EPOCH: 21,train_loss: 0.015565829297554666, valid_loss: 0.01670206319540739\nSEED: 5, FOLD: 2, EPOCH: 22,train_loss: 0.015073284297587647, valid_loss: 0.01673235126904079\nSEED: 5, FOLD: 2, EPOCH: 23,train_loss: 0.014624168461971525, valid_loss: 0.016690498936389173\nSEED: 5, FOLD: 2, EPOCH: 24,train_loss: 0.014419931736167358, valid_loss: 0.016700052842497825\nFOLD: 3, EPOCH: 0,train_loss: 0.736475260153304, valid_loss: 0.6990528736795698\nSEED: 5, FOLD: 3, EPOCH: 0,train_loss: 0.46815364896217837, valid_loss: 0.024398753845265932\nSEED: 5, FOLD: 3, EPOCH: 1,train_loss: 0.02086250058436481, valid_loss: 0.01915948949754238\nSEED: 5, FOLD: 3, EPOCH: 2,train_loss: 0.018953479799258446, valid_loss: 0.018254675662943295\nSEED: 5, FOLD: 3, EPOCH: 3,train_loss: 0.018032003438820804, valid_loss: 0.018035803522382463\nSEED: 5, FOLD: 3, EPOCH: 4,train_loss: 0.017864733349776615, valid_loss: 0.018132705773626055\nSEED: 5, FOLD: 3, EPOCH: 5,train_loss: 0.017815635043339138, valid_loss: 0.01791650676833732\nSEED: 5, FOLD: 3, EPOCH: 6,train_loss: 0.017772704668778137, valid_loss: 0.01825720364493983\nSEED: 5, FOLD: 3, EPOCH: 7,train_loss: 0.01781082139044565, valid_loss: 0.017990176086979254\nSEED: 5, FOLD: 3, EPOCH: 8,train_loss: 0.017833734570193466, valid_loss: 0.018268588238528796\nSEED: 5, FOLD: 3, EPOCH: 9,train_loss: 0.017787305862527258, valid_loss: 0.018099547283990044\nSEED: 5, FOLD: 3, EPOCH: 10,train_loss: 0.017755009009618395, valid_loss: 0.017926680296659468\nSEED: 5, FOLD: 3, EPOCH: 11,train_loss: 0.017694480411273285, valid_loss: 0.018159089317279203\nSEED: 5, FOLD: 3, EPOCH: 12,train_loss: 0.017622027464591673, valid_loss: 0.018089195234434946\nSEED: 5, FOLD: 3, EPOCH: 13,train_loss: 0.017517977781648184, valid_loss: 0.017962776390569552\nSEED: 5, FOLD: 3, EPOCH: 14,train_loss: 0.017419257140072593, valid_loss: 0.017717422465128557\nSEED: 5, FOLD: 3, EPOCH: 15,train_loss: 0.01721161051252245, valid_loss: 0.017596412423465935\nSEED: 5, FOLD: 3, EPOCH: 16,train_loss: 0.017044173771121204, valid_loss: 0.01767437607049942\nSEED: 5, FOLD: 3, EPOCH: 17,train_loss: 0.01677102162536696, valid_loss: 0.017573270228292262\nSEED: 5, FOLD: 3, EPOCH: 18,train_loss: 0.01650907283472101, valid_loss: 0.017398348370833056\nSEED: 5, FOLD: 3, EPOCH: 19,train_loss: 0.016148685137775256, valid_loss: 0.017299446357148033\nSEED: 5, FOLD: 3, EPOCH: 20,train_loss: 0.015726746590196215, valid_loss: 0.017340094675975186\nSEED: 5, FOLD: 3, EPOCH: 21,train_loss: 0.015228677575007407, valid_loss: 0.017289461035813605\nSEED: 5, FOLD: 3, EPOCH: 22,train_loss: 0.014701091793168634, valid_loss: 0.017388460119920117\nSEED: 5, FOLD: 3, EPOCH: 23,train_loss: 0.014218944417190378, valid_loss: 0.017340139831815447\nSEED: 5, FOLD: 3, EPOCH: 24,train_loss: 0.013966244461871412, valid_loss: 0.017324746000979628\nFOLD: 4, EPOCH: 0,train_loss: 0.7359478102214094, valid_loss: 0.7018029479419484\nSEED: 5, FOLD: 4, EPOCH: 0,train_loss: 0.4686320109994731, valid_loss: 0.024671391803113854\nSEED: 5, FOLD: 4, EPOCH: 1,train_loss: 0.020710971287411194, valid_loss: 0.018889652729472694\nSEED: 5, FOLD: 4, EPOCH: 2,train_loss: 0.018815991009815014, valid_loss: 0.018746766042621696\nSEED: 5, FOLD: 4, EPOCH: 3,train_loss: 0.018168164788326925, valid_loss: 0.01823431094560553\nSEED: 5, FOLD: 4, EPOCH: 4,train_loss: 0.018027633597291468, valid_loss: 0.018559643505688977\nSEED: 5, FOLD: 4, EPOCH: 5,train_loss: 0.0179176341769272, valid_loss: 0.018347359919810995\nSEED: 5, FOLD: 4, EPOCH: 6,train_loss: 0.01778398951569545, valid_loss: 0.01822268228758784\nSEED: 5, FOLD: 4, EPOCH: 7,train_loss: 0.01785398280059082, valid_loss: 0.018529255490969208\nSEED: 5, FOLD: 4, EPOCH: 8,train_loss: 0.017811806258354067, valid_loss: 0.018300937488675117\nSEED: 5, FOLD: 4, EPOCH: 9,train_loss: 0.017801369094978207, valid_loss: 0.01809573091347428\nSEED: 5, FOLD: 4, EPOCH: 10,train_loss: 0.017745701150725716, valid_loss: 0.0181229301070904\nSEED: 5, FOLD: 4, EPOCH: 11,train_loss: 0.017731632328713717, valid_loss: 0.018014590118956918\nSEED: 5, FOLD: 4, EPOCH: 12,train_loss: 0.01761146820406767, valid_loss: 0.01803323034854496\nSEED: 5, FOLD: 4, EPOCH: 13,train_loss: 0.01761914789001795, valid_loss: 0.01793415340430596\nSEED: 5, FOLD: 4, EPOCH: 14,train_loss: 0.017395988855834887, valid_loss: 0.018178041695671922\nSEED: 5, FOLD: 4, EPOCH: 15,train_loss: 0.01728927900177845, valid_loss: 0.017899134114165518\nSEED: 5, FOLD: 4, EPOCH: 16,train_loss: 0.01707587388438591, valid_loss: 0.017785840914310777\nSEED: 5, FOLD: 4, EPOCH: 17,train_loss: 0.016901403220127457, valid_loss: 0.01764676029629567\nSEED: 5, FOLD: 4, EPOCH: 18,train_loss: 0.016590211830655302, valid_loss: 0.017579928643124944\nSEED: 5, FOLD: 4, EPOCH: 19,train_loss: 0.01626225373964163, valid_loss: 0.01753654533668476\nSEED: 5, FOLD: 4, EPOCH: 20,train_loss: 0.015814493707232716, valid_loss: 0.017416940700701055\nSEED: 5, FOLD: 4, EPOCH: 21,train_loss: 0.015374896352759737, valid_loss: 0.017452810370527646\nSEED: 5, FOLD: 4, EPOCH: 22,train_loss: 0.01483124633576127, valid_loss: 0.017479016527752664\nSEED: 5, FOLD: 4, EPOCH: 23,train_loss: 0.014415459882845913, valid_loss: 0.017448382452130318\nSEED: 5, FOLD: 4, EPOCH: 24,train_loss: 0.014153939233148012, valid_loss: 0.01745342926177032\nFOLD: 0, EPOCH: 0,train_loss: 0.7343476936764961, valid_loss: 0.6850045340401786\nSEED: 6, FOLD: 0, EPOCH: 0,train_loss: 0.4679184590269179, valid_loss: 0.024338814190455846\nSEED: 6, FOLD: 0, EPOCH: 1,train_loss: 0.02073224053385049, valid_loss: 0.01884781824690955\nSEED: 6, FOLD: 0, EPOCH: 2,train_loss: 0.019001384972710245, valid_loss: 0.01830792264746768\nSEED: 6, FOLD: 0, EPOCH: 3,train_loss: 0.01814810428632437, valid_loss: 0.017868295311927795\nSEED: 6, FOLD: 0, EPOCH: 4,train_loss: 0.01784983241971392, valid_loss: 0.017933750019541807\nSEED: 6, FOLD: 0, EPOCH: 5,train_loss: 0.017851392765713, valid_loss: 0.017838545170213493\nSEED: 6, FOLD: 0, EPOCH: 6,train_loss: 0.01780939798965289, valid_loss: 0.018217566130416734\nSEED: 6, FOLD: 0, EPOCH: 7,train_loss: 0.01787342863279755, valid_loss: 0.018268459795841147\nSEED: 6, FOLD: 0, EPOCH: 8,train_loss: 0.01786831825509341, valid_loss: 0.018295325844415598\nSEED: 6, FOLD: 0, EPOCH: 9,train_loss: 0.017832850500343056, valid_loss: 0.01822973590876375\nSEED: 6, FOLD: 0, EPOCH: 10,train_loss: 0.017842035754209888, valid_loss: 0.017810883186757564\nSEED: 6, FOLD: 0, EPOCH: 11,train_loss: 0.01776355559373424, valid_loss: 0.01804605961910316\nSEED: 6, FOLD: 0, EPOCH: 12,train_loss: 0.017670767361393374, valid_loss: 0.017750339103596552\nSEED: 6, FOLD: 0, EPOCH: 13,train_loss: 0.017600004697204942, valid_loss: 0.0180503818073443\nSEED: 6, FOLD: 0, EPOCH: 14,train_loss: 0.017416492893095433, valid_loss: 0.0177196827051895\nSEED: 6, FOLD: 0, EPOCH: 15,train_loss: 0.017303673210587813, valid_loss: 0.01769597051399095\nSEED: 6, FOLD: 0, EPOCH: 16,train_loss: 0.0171373164566764, valid_loss: 0.017652723539088453\nSEED: 6, FOLD: 0, EPOCH: 17,train_loss: 0.016846707444230134, valid_loss: 0.01745646140937294\nSEED: 6, FOLD: 0, EPOCH: 18,train_loss: 0.01659964991692644, valid_loss: 0.017489661515823433\nSEED: 6, FOLD: 0, EPOCH: 19,train_loss: 0.016270853055600266, valid_loss: 0.01752968997295414\nSEED: 6, FOLD: 0, EPOCH: 20,train_loss: 0.015819693460081614, valid_loss: 0.017500929507826057\nSEED: 6, FOLD: 0, EPOCH: 21,train_loss: 0.01541748077329928, valid_loss: 0.017459971165018424\nSEED: 6, FOLD: 0, EPOCH: 22,train_loss: 0.014897738583385944, valid_loss: 0.017394990979560782\nSEED: 6, FOLD: 0, EPOCH: 23,train_loss: 0.014462593895294806, valid_loss: 0.017419368268123694\nSEED: 6, FOLD: 0, EPOCH: 24,train_loss: 0.014237616122802244, valid_loss: 0.01741941020424877\nFOLD: 1, EPOCH: 0,train_loss: 0.7340059656163921, valid_loss: 0.6805739181382315\nSEED: 6, FOLD: 1, EPOCH: 0,train_loss: 0.4670594171958341, valid_loss: 0.023918676163469044\nSEED: 6, FOLD: 1, EPOCH: 1,train_loss: 0.021431228091967278, valid_loss: 0.02559007384947368\nSEED: 6, FOLD: 1, EPOCH: 2,train_loss: 0.021066446721121884, valid_loss: 0.019487900765878814\nSEED: 6, FOLD: 1, EPOCH: 3,train_loss: 0.019381688826757927, valid_loss: 0.018623736926487514\nSEED: 6, FOLD: 1, EPOCH: 4,train_loss: 0.01884027815464398, valid_loss: 0.018923907833439963\nSEED: 6, FOLD: 1, EPOCH: 5,train_loss: 0.01859595362043035, valid_loss: 0.018864896574190684\nSEED: 6, FOLD: 1, EPOCH: 6,train_loss: 0.018416621580557978, valid_loss: 0.018658943314637456\nSEED: 6, FOLD: 1, EPOCH: 7,train_loss: 0.018302577642211014, valid_loss: 0.01839701363018581\nSEED: 6, FOLD: 1, EPOCH: 8,train_loss: 0.018152624334924032, valid_loss: 0.018168682285717556\nSEED: 6, FOLD: 1, EPOCH: 9,train_loss: 0.018104868920762903, valid_loss: 0.018239634271178928\nSEED: 6, FOLD: 1, EPOCH: 10,train_loss: 0.01809325973516789, valid_loss: 0.018137289636901446\nSEED: 6, FOLD: 1, EPOCH: 11,train_loss: 0.017968507733304, valid_loss: 0.01874664452459131\nSEED: 6, FOLD: 1, EPOCH: 12,train_loss: 0.017961553135967773, valid_loss: 0.017915117155228342\nSEED: 6, FOLD: 1, EPOCH: 13,train_loss: 0.01770067055021291, valid_loss: 0.01803915963641235\nSEED: 6, FOLD: 1, EPOCH: 14,train_loss: 0.017662976274563782, valid_loss: 0.017962612264922687\nSEED: 6, FOLD: 1, EPOCH: 15,train_loss: 0.017504440080644428, valid_loss: 0.017918605703328337\nSEED: 6, FOLD: 1, EPOCH: 16,train_loss: 0.017285300972129124, valid_loss: 0.01773632714258773\nSEED: 6, FOLD: 1, EPOCH: 17,train_loss: 0.017069850116968155, valid_loss: 0.01766857464930841\nSEED: 6, FOLD: 1, EPOCH: 18,train_loss: 0.01673926654663207, valid_loss: 0.01755084352833884\nSEED: 6, FOLD: 1, EPOCH: 19,train_loss: 0.016447541614373524, valid_loss: 0.017581617433045593\nSEED: 6, FOLD: 1, EPOCH: 20,train_loss: 0.015955191497029602, valid_loss: 0.017375424983245985\nSEED: 6, FOLD: 1, EPOCH: 21,train_loss: 0.01544397349293897, valid_loss: 0.017466702684760093\nSEED: 6, FOLD: 1, EPOCH: 22,train_loss: 0.01505333725767939, valid_loss: 0.017364959099463055\nSEED: 6, FOLD: 1, EPOCH: 23,train_loss: 0.014709329738727083, valid_loss: 0.017435979736702783\nSEED: 6, FOLD: 1, EPOCH: 24,train_loss: 0.014382951380010101, valid_loss: 0.01741582876337426\nFOLD: 2, EPOCH: 0,train_loss: 0.7344203456474917, valid_loss: 0.6850733263151986\nSEED: 6, FOLD: 2, EPOCH: 0,train_loss: 0.4666937291078324, valid_loss: 0.024050476614918027\nSEED: 6, FOLD: 2, EPOCH: 1,train_loss: 0.0210201861676726, valid_loss: 0.020057025871106558\nSEED: 6, FOLD: 2, EPOCH: 2,train_loss: 0.018971722110779615, valid_loss: 0.01835634977157627\nSEED: 6, FOLD: 2, EPOCH: 3,train_loss: 0.018397634964517868, valid_loss: 0.01812045600797449\nSEED: 6, FOLD: 2, EPOCH: 4,train_loss: 0.018031306000575967, valid_loss: 0.018060949072241782\nSEED: 6, FOLD: 2, EPOCH: 5,train_loss: 0.017872666049558315, valid_loss: 0.01780062871319907\nSEED: 6, FOLD: 2, EPOCH: 6,train_loss: 0.01795702371882261, valid_loss: 0.0177151354561959\nSEED: 6, FOLD: 2, EPOCH: 7,train_loss: 0.01792562651672285, valid_loss: 0.018245087005198002\nSEED: 6, FOLD: 2, EPOCH: 8,train_loss: 0.0179219379558833, valid_loss: 0.018047007040253707\nSEED: 6, FOLD: 2, EPOCH: 9,train_loss: 0.017881971790734, valid_loss: 0.017762825478400503\nSEED: 6, FOLD: 2, EPOCH: 10,train_loss: 0.0178307396543287, valid_loss: 0.017933254103575436\nSEED: 6, FOLD: 2, EPOCH: 11,train_loss: 0.017826038140830766, valid_loss: 0.01768084687313863\nSEED: 6, FOLD: 2, EPOCH: 12,train_loss: 0.017782706576977333, valid_loss: 0.01824326483266694\nSEED: 6, FOLD: 2, EPOCH: 13,train_loss: 0.017655859599365806, valid_loss: 0.01745888777077198\nSEED: 6, FOLD: 2, EPOCH: 14,train_loss: 0.0174972954117795, valid_loss: 0.017515519421015466\nSEED: 6, FOLD: 2, EPOCH: 15,train_loss: 0.01741062511220901, valid_loss: 0.01745888361973422\nSEED: 6, FOLD: 2, EPOCH: 16,train_loss: 0.01716236207280716, valid_loss: 0.01735023172306163\nSEED: 6, FOLD: 2, EPOCH: 17,train_loss: 0.016947214015807115, valid_loss: 0.017267474132989135\nSEED: 6, FOLD: 2, EPOCH: 18,train_loss: 0.016663343455288967, valid_loss: 0.017081932883177484\nSEED: 6, FOLD: 2, EPOCH: 19,train_loss: 0.016320751089412364, valid_loss: 0.017149617922093185\nSEED: 6, FOLD: 2, EPOCH: 20,train_loss: 0.01594542943784138, valid_loss: 0.017129151283630302\nSEED: 6, FOLD: 2, EPOCH: 21,train_loss: 0.015407159618598266, valid_loss: 0.017029759926455362\nSEED: 6, FOLD: 2, EPOCH: 22,train_loss: 0.014910831857119163, valid_loss: 0.01694118928696428\nSEED: 6, FOLD: 2, EPOCH: 23,train_loss: 0.014515181683874043, valid_loss: 0.016978933263037885\nSEED: 6, FOLD: 2, EPOCH: 24,train_loss: 0.01425597214405119, valid_loss: 0.016986407924975667\nFOLD: 3, EPOCH: 0,train_loss: 0.7341770845046942, valid_loss: 0.6850443754877363\nSEED: 6, FOLD: 3, EPOCH: 0,train_loss: 0.46613020459324983, valid_loss: 0.0234553975718362\nSEED: 6, FOLD: 3, EPOCH: 1,train_loss: 0.0208605854920503, valid_loss: 0.019373649092657225\nSEED: 6, FOLD: 3, EPOCH: 2,train_loss: 0.019122785524181698, valid_loss: 0.01798192797494786\nSEED: 6, FOLD: 3, EPOCH: 3,train_loss: 0.018220012096445196, valid_loss: 0.017948252335190772\nSEED: 6, FOLD: 3, EPOCH: 4,train_loss: 0.01792780418569843, valid_loss: 0.018259563323642525\nSEED: 6, FOLD: 3, EPOCH: 5,train_loss: 0.0179238714804144, valid_loss: 0.017955563856022698\nSEED: 6, FOLD: 3, EPOCH: 6,train_loss: 0.017875363321407982, valid_loss: 0.01834635151816266\nSEED: 6, FOLD: 3, EPOCH: 7,train_loss: 0.017898090750626896, valid_loss: 0.017629999640796867\nSEED: 6, FOLD: 3, EPOCH: 8,train_loss: 0.017852523262895967, valid_loss: 0.017862136236258916\nSEED: 6, FOLD: 3, EPOCH: 9,train_loss: 0.01785332372115142, valid_loss: 0.01779605190136603\nSEED: 6, FOLD: 3, EPOCH: 10,train_loss: 0.01785157652625787, valid_loss: 0.017869453717555318\nSEED: 6, FOLD: 3, EPOCH: 11,train_loss: 0.017722171771785488, valid_loss: 0.0175614149708833\nSEED: 6, FOLD: 3, EPOCH: 12,train_loss: 0.01765354420395865, valid_loss: 0.01802576636629445\nSEED: 6, FOLD: 3, EPOCH: 13,train_loss: 0.017584066554580047, valid_loss: 0.01751747392117977\nSEED: 6, FOLD: 3, EPOCH: 14,train_loss: 0.017489098181165216, valid_loss: 0.017380787352366107\nSEED: 6, FOLD: 3, EPOCH: 15,train_loss: 0.01731785596685781, valid_loss: 0.017316768398242338\nSEED: 6, FOLD: 3, EPOCH: 16,train_loss: 0.0171246861944488, valid_loss: 0.01749992791031088\nSEED: 6, FOLD: 3, EPOCH: 17,train_loss: 0.016956957090861986, valid_loss: 0.017288583596902236\nSEED: 6, FOLD: 3, EPOCH: 18,train_loss: 0.016664708201921938, valid_loss: 0.01712791927691017\nSEED: 6, FOLD: 3, EPOCH: 19,train_loss: 0.0162980522946927, valid_loss: 0.017219970082598072\nSEED: 6, FOLD: 3, EPOCH: 20,train_loss: 0.015837408183817413, valid_loss: 0.0171152048345123\nSEED: 6, FOLD: 3, EPOCH: 21,train_loss: 0.015319470491638218, valid_loss: 0.01701584817575557\nSEED: 6, FOLD: 3, EPOCH: 22,train_loss: 0.01479149374274024, valid_loss: 0.01707989868841001\nSEED: 6, FOLD: 3, EPOCH: 23,train_loss: 0.014340540394186974, valid_loss: 0.017048647707062107\nSEED: 6, FOLD: 3, EPOCH: 24,train_loss: 0.014121796713089165, valid_loss: 0.01704616756843669\nFOLD: 4, EPOCH: 0,train_loss: 0.7338414926459824, valid_loss: 0.686134382205851\nSEED: 6, FOLD: 4, EPOCH: 0,train_loss: 0.46767125323252834, valid_loss: 0.024326320682816645\nSEED: 6, FOLD: 4, EPOCH: 1,train_loss: 0.021162195860043816, valid_loss: 0.018911791691447005\nSEED: 6, FOLD: 4, EPOCH: 2,train_loss: 0.01899964799699576, valid_loss: 0.018008618177298236\nSEED: 6, FOLD: 4, EPOCH: 3,train_loss: 0.018340058030857555, valid_loss: 0.018074772676781696\nSEED: 6, FOLD: 4, EPOCH: 4,train_loss: 0.018088752957249897, valid_loss: 0.017920879126690766\nSEED: 6, FOLD: 4, EPOCH: 5,train_loss: 0.01787576788658465, valid_loss: 0.01828440243159147\nSEED: 6, FOLD: 4, EPOCH: 6,train_loss: 0.017978323960973732, valid_loss: 0.017847076962318492\nSEED: 6, FOLD: 4, EPOCH: 7,train_loss: 0.01790434678854502, valid_loss: 0.01787357506177881\nSEED: 6, FOLD: 4, EPOCH: 8,train_loss: 0.017911256574418232, valid_loss: 0.01799008803551688\nSEED: 6, FOLD: 4, EPOCH: 9,train_loss: 0.017858818058680365, valid_loss: 0.018026116824544528\nSEED: 6, FOLD: 4, EPOCH: 10,train_loss: 0.017836224341738052, valid_loss: 0.017667533857200074\nSEED: 6, FOLD: 4, EPOCH: 11,train_loss: 0.01778348191789743, valid_loss: 0.01761901953860241\nSEED: 6, FOLD: 4, EPOCH: 12,train_loss: 0.017750174859943596, valid_loss: 0.017706939074046472\nSEED: 6, FOLD: 4, EPOCH: 13,train_loss: 0.017626258045218994, valid_loss: 0.017557103214237618\nSEED: 6, FOLD: 4, EPOCH: 14,train_loss: 0.017470343483854896, valid_loss: 0.01756987991907141\nSEED: 6, FOLD: 4, EPOCH: 15,train_loss: 0.01736695764154412, valid_loss: 0.017373181578210172\nSEED: 6, FOLD: 4, EPOCH: 16,train_loss: 0.017207945103122704, valid_loss: 0.017396483679904658\nSEED: 6, FOLD: 4, EPOCH: 17,train_loss: 0.016971958193766033, valid_loss: 0.01734475145006881\nSEED: 6, FOLD: 4, EPOCH: 18,train_loss: 0.016706658776957487, valid_loss: 0.017164957134381813\nSEED: 6, FOLD: 4, EPOCH: 19,train_loss: 0.016387802008809387, valid_loss: 0.01716563675333472\nSEED: 6, FOLD: 4, EPOCH: 20,train_loss: 0.015953303375483854, valid_loss: 0.017078107085955495\nSEED: 6, FOLD: 4, EPOCH: 21,train_loss: 0.015502114334832067, valid_loss: 0.017040325438275057\nSEED: 6, FOLD: 4, EPOCH: 22,train_loss: 0.014972062659976275, valid_loss: 0.017035484615275088\nSEED: 6, FOLD: 4, EPOCH: 23,train_loss: 0.01455447576481147, valid_loss: 0.017066781902137923\nSEED: 6, FOLD: 4, EPOCH: 24,train_loss: 0.014298797402854847, valid_loss: 0.017073141383555007\nFOLD: 0, EPOCH: 0,train_loss: 0.7359367125276206, valid_loss: 0.6922763858522688\nSEED: 7, FOLD: 0, EPOCH: 0,train_loss: 0.4658563231671418, valid_loss: 0.027605828855718884\nSEED: 7, FOLD: 0, EPOCH: 1,train_loss: 0.02114507283313551, valid_loss: 0.0230535216363413\nSEED: 7, FOLD: 0, EPOCH: 2,train_loss: 0.01915027931386578, valid_loss: 0.01779465853635754\nSEED: 7, FOLD: 0, EPOCH: 3,train_loss: 0.018416484574908795, valid_loss: 0.018493306104625976\nSEED: 7, FOLD: 0, EPOCH: 4,train_loss: 0.018231505858779386, valid_loss: 0.017796490155160428\nSEED: 7, FOLD: 0, EPOCH: 5,train_loss: 0.017940122404716152, valid_loss: 0.017950719222426414\nSEED: 7, FOLD: 0, EPOCH: 6,train_loss: 0.01800517393681018, valid_loss: 0.01770523658820561\nSEED: 7, FOLD: 0, EPOCH: 7,train_loss: 0.017914867453763018, valid_loss: 0.01740048091326441\nSEED: 7, FOLD: 0, EPOCH: 8,train_loss: 0.017897328760043, valid_loss: 0.017730335438890115\nSEED: 7, FOLD: 0, EPOCH: 9,train_loss: 0.017876573311893837, valid_loss: 0.018155931974095957\nSEED: 7, FOLD: 0, EPOCH: 10,train_loss: 0.017866714823775103, valid_loss: 0.017342822147267206\nSEED: 7, FOLD: 0, EPOCH: 11,train_loss: 0.017856982725577942, valid_loss: 0.017609735312206404\nSEED: 7, FOLD: 0, EPOCH: 12,train_loss: 0.017764507691659357, valid_loss: 0.017388252301939897\nSEED: 7, FOLD: 0, EPOCH: 13,train_loss: 0.017709822663902374, valid_loss: 0.017243279170777115\nSEED: 7, FOLD: 0, EPOCH: 14,train_loss: 0.01756090498731836, valid_loss: 0.01733687307153429\nSEED: 7, FOLD: 0, EPOCH: 15,train_loss: 0.017383377013755016, valid_loss: 0.0171231158343809\nSEED: 7, FOLD: 0, EPOCH: 16,train_loss: 0.017201999202370644, valid_loss: 0.01719090526125261\nSEED: 7, FOLD: 0, EPOCH: 17,train_loss: 0.016973748020287872, valid_loss: 0.01706037673034838\nSEED: 7, FOLD: 0, EPOCH: 18,train_loss: 0.0166499104782723, valid_loss: 0.017061099090746473\nSEED: 7, FOLD: 0, EPOCH: 19,train_loss: 0.016358108064024778, valid_loss: 0.016890779377094337\nSEED: 7, FOLD: 0, EPOCH: 20,train_loss: 0.01593339666589231, valid_loss: 0.016826829154576575\nSEED: 7, FOLD: 0, EPOCH: 21,train_loss: 0.01547768625660219, valid_loss: 0.016800544570599284\nSEED: 7, FOLD: 0, EPOCH: 22,train_loss: 0.014977594189669775, valid_loss: 0.016783002604331288\nSEED: 7, FOLD: 0, EPOCH: 23,train_loss: 0.014572528406869675, valid_loss: 0.01680124955517905\nSEED: 7, FOLD: 0, EPOCH: 24,train_loss: 0.014338108292524365, valid_loss: 0.016791765205562116\nFOLD: 1, EPOCH: 0,train_loss: 0.736430509366851, valid_loss: 0.6900659969874791\nSEED: 7, FOLD: 1, EPOCH: 0,train_loss: 0.4651431859592381, valid_loss: 0.02383012574698244\nSEED: 7, FOLD: 1, EPOCH: 1,train_loss: 0.02086665338256221, valid_loss: 0.01872849105192082\nSEED: 7, FOLD: 1, EPOCH: 2,train_loss: 0.01889856181282928, valid_loss: 0.018637306189962795\nSEED: 7, FOLD: 1, EPOCH: 3,train_loss: 0.018180410546399114, valid_loss: 0.01854980925896338\nSEED: 7, FOLD: 1, EPOCH: 4,train_loss: 0.017830634260199207, valid_loss: 0.0179166994456734\nSEED: 7, FOLD: 1, EPOCH: 5,train_loss: 0.017779630622354107, valid_loss: 0.018146889204425472\nSEED: 7, FOLD: 1, EPOCH: 6,train_loss: 0.017746804403546063, valid_loss: 0.019859636042799268\nSEED: 7, FOLD: 1, EPOCH: 7,train_loss: 0.017875460685109316, valid_loss: 0.018025322231863226\nSEED: 7, FOLD: 1, EPOCH: 8,train_loss: 0.01780465564461074, valid_loss: 0.01790703734649079\nSEED: 7, FOLD: 1, EPOCH: 9,train_loss: 0.017805105979567852, valid_loss: 0.018279123598975794\nSEED: 7, FOLD: 1, EPOCH: 10,train_loss: 0.017791861411777958, valid_loss: 0.018135206161865165\nSEED: 7, FOLD: 1, EPOCH: 11,train_loss: 0.017698261711368526, valid_loss: 0.017766222836715834\nSEED: 7, FOLD: 1, EPOCH: 12,train_loss: 0.017638831925780876, valid_loss: 0.01827875096350908\nSEED: 7, FOLD: 1, EPOCH: 13,train_loss: 0.017598623254646856, valid_loss: 0.01793354225478002\nSEED: 7, FOLD: 1, EPOCH: 14,train_loss: 0.017424669029002172, valid_loss: 0.018122530595532486\nSEED: 7, FOLD: 1, EPOCH: 15,train_loss: 0.01733236857757404, valid_loss: 0.017759882605501584\nSEED: 7, FOLD: 1, EPOCH: 16,train_loss: 0.01712750076599743, valid_loss: 0.017879123027835574\nSEED: 7, FOLD: 1, EPOCH: 17,train_loss: 0.01692787250098975, valid_loss: 0.017749526378299508\nSEED: 7, FOLD: 1, EPOCH: 18,train_loss: 0.01660037781044409, valid_loss: 0.017645442113280296\nSEED: 7, FOLD: 1, EPOCH: 19,train_loss: 0.016274944764386484, valid_loss: 0.017497928174478667\nSEED: 7, FOLD: 1, EPOCH: 20,train_loss: 0.015894703742494617, valid_loss: 0.017452908759670597\nSEED: 7, FOLD: 1, EPOCH: 21,train_loss: 0.015452884974471037, valid_loss: 0.017305771713810307\nSEED: 7, FOLD: 1, EPOCH: 22,train_loss: 0.01493190598093729, valid_loss: 0.017388480768672058\nSEED: 7, FOLD: 1, EPOCH: 23,train_loss: 0.014465630202945591, valid_loss: 0.017313317927931036\nSEED: 7, FOLD: 1, EPOCH: 24,train_loss: 0.014270134020488764, valid_loss: 0.017345836386084557\nFOLD: 2, EPOCH: 0,train_loss: 0.7358371481515359, valid_loss: 0.6923387782914298\nSEED: 7, FOLD: 2, EPOCH: 0,train_loss: 0.4661543395748173, valid_loss: 0.045846949091979436\nSEED: 7, FOLD: 2, EPOCH: 1,train_loss: 0.02086117466830689, valid_loss: 0.018397382167833192\nSEED: 7, FOLD: 2, EPOCH: 2,train_loss: 0.019102444514578234, valid_loss: 0.01791147275694779\nSEED: 7, FOLD: 2, EPOCH: 3,train_loss: 0.018275234180138163, valid_loss: 0.018743867693202836\nSEED: 7, FOLD: 2, EPOCH: 4,train_loss: 0.01797214642410045, valid_loss: 0.017649222750748907\nSEED: 7, FOLD: 2, EPOCH: 5,train_loss: 0.017862206250699102, valid_loss: 0.01746819285409791\nSEED: 7, FOLD: 2, EPOCH: 6,train_loss: 0.017899468682868326, valid_loss: 0.017853390797972678\nSEED: 7, FOLD: 2, EPOCH: 7,train_loss: 0.017918206191203302, valid_loss: 0.01791554907602923\nSEED: 7, FOLD: 2, EPOCH: 8,train_loss: 0.017873900780535263, valid_loss: 0.01786634275423629\nSEED: 7, FOLD: 2, EPOCH: 9,train_loss: 0.017979051958283653, valid_loss: 0.017951905275029795\nSEED: 7, FOLD: 2, EPOCH: 10,train_loss: 0.017915431551797235, valid_loss: 0.01737862205398934\nSEED: 7, FOLD: 2, EPOCH: 11,train_loss: 0.017833190153528383, valid_loss: 0.017474573824022496\nSEED: 7, FOLD: 2, EPOCH: 12,train_loss: 0.017760578866886055, valid_loss: 0.017574340450976576\nSEED: 7, FOLD: 2, EPOCH: 13,train_loss: 0.017683432235018066, valid_loss: 0.017545540338116034\nSEED: 7, FOLD: 2, EPOCH: 14,train_loss: 0.01753504035751457, valid_loss: 0.017347733569996696\nSEED: 7, FOLD: 2, EPOCH: 15,train_loss: 0.017435994775344927, valid_loss: 0.017252833502633232\nSEED: 7, FOLD: 2, EPOCH: 16,train_loss: 0.01723871742496672, valid_loss: 0.01715346492294754\nSEED: 7, FOLD: 2, EPOCH: 17,train_loss: 0.01698489595150602, valid_loss: 0.01713537291756698\nSEED: 7, FOLD: 2, EPOCH: 18,train_loss: 0.0167002583367993, valid_loss: 0.01696238001542432\nSEED: 7, FOLD: 2, EPOCH: 19,train_loss: 0.016374428952247767, valid_loss: 0.01686549186706543\nSEED: 7, FOLD: 2, EPOCH: 20,train_loss: 0.016001826624615467, valid_loss: 0.016870685507144247\nSEED: 7, FOLD: 2, EPOCH: 21,train_loss: 0.015450298037056042, valid_loss: 0.01677269499216761\nSEED: 7, FOLD: 2, EPOCH: 22,train_loss: 0.014959239029743965, valid_loss: 0.016743677641664234\nSEED: 7, FOLD: 2, EPOCH: 23,train_loss: 0.014513188946074333, valid_loss: 0.016772379273814815\nSEED: 7, FOLD: 2, EPOCH: 24,train_loss: 0.014290948135211416, valid_loss: 0.016750861039119106\nFOLD: 3, EPOCH: 0,train_loss: 0.7361041907846493, valid_loss: 0.6924643686839512\nSEED: 7, FOLD: 3, EPOCH: 0,train_loss: 0.46701573870097196, valid_loss: 0.025506161632282393\nSEED: 7, FOLD: 3, EPOCH: 1,train_loss: 0.020662009770417735, valid_loss: 0.019248548416154726\nSEED: 7, FOLD: 3, EPOCH: 2,train_loss: 0.018691454354646433, valid_loss: 0.01855428580726896\nSEED: 7, FOLD: 3, EPOCH: 3,train_loss: 0.01804024463750585, valid_loss: 0.018120663267161163\nSEED: 7, FOLD: 3, EPOCH: 4,train_loss: 0.017610956574824168, valid_loss: 0.018279091428433147\nSEED: 7, FOLD: 3, EPOCH: 5,train_loss: 0.017616512818112426, valid_loss: 0.018742349983326027\nSEED: 7, FOLD: 3, EPOCH: 6,train_loss: 0.017657495946725353, valid_loss: 0.01850235749568258\nSEED: 7, FOLD: 3, EPOCH: 7,train_loss: 0.017672466637607475, valid_loss: 0.01820535896612065\nSEED: 7, FOLD: 3, EPOCH: 8,train_loss: 0.01763343327699134, valid_loss: 0.018146044627896377\nSEED: 7, FOLD: 3, EPOCH: 9,train_loss: 0.0176509632966923, valid_loss: 0.018420871719717978\nSEED: 7, FOLD: 3, EPOCH: 10,train_loss: 0.017649364175043838, valid_loss: 0.018134732943560397\nSEED: 7, FOLD: 3, EPOCH: 11,train_loss: 0.017593029301858295, valid_loss: 0.018197442404925823\nSEED: 7, FOLD: 3, EPOCH: 12,train_loss: 0.017496291167327087, valid_loss: 0.018080026470124723\nSEED: 7, FOLD: 3, EPOCH: 13,train_loss: 0.017366480075475508, valid_loss: 0.01800400683922427\nSEED: 7, FOLD: 3, EPOCH: 14,train_loss: 0.017320566973818913, valid_loss: 0.017869470667626175\nSEED: 7, FOLD: 3, EPOCH: 15,train_loss: 0.017137394388661766, valid_loss: 0.017926723962383612\nSEED: 7, FOLD: 3, EPOCH: 16,train_loss: 0.016923222459689545, valid_loss: 0.017806964367628096\nSEED: 7, FOLD: 3, EPOCH: 17,train_loss: 0.01668809724115107, valid_loss: 0.017890187592378686\nSEED: 7, FOLD: 3, EPOCH: 18,train_loss: 0.016417064438879924, valid_loss: 0.01775185436542545\nSEED: 7, FOLD: 3, EPOCH: 19,train_loss: 0.016065501172884102, valid_loss: 0.017644782124885492\nSEED: 7, FOLD: 3, EPOCH: 20,train_loss: 0.015614885034678627, valid_loss: 0.01777040921151638\nSEED: 7, FOLD: 3, EPOCH: 21,train_loss: 0.01511277911681546, valid_loss: 0.01771373546549252\nSEED: 7, FOLD: 3, EPOCH: 22,train_loss: 0.014532832925065155, valid_loss: 0.017624240395213875\nSEED: 7, FOLD: 3, EPOCH: 23,train_loss: 0.014041484224807173, valid_loss: 0.01766579850975956\nSEED: 7, FOLD: 3, EPOCH: 24,train_loss: 0.013753908278461355, valid_loss: 0.0176660830155015\nFOLD: 4, EPOCH: 0,train_loss: 0.7358005586741627, valid_loss: 0.692175441128867\nSEED: 7, FOLD: 4, EPOCH: 0,train_loss: 0.46632124146149645, valid_loss: 0.023750959815723557\nSEED: 7, FOLD: 4, EPOCH: 1,train_loss: 0.02071269982210968, valid_loss: 0.018891984410583974\nSEED: 7, FOLD: 4, EPOCH: 2,train_loss: 0.01892738017267075, valid_loss: 0.018149991386703083\nSEED: 7, FOLD: 4, EPOCH: 3,train_loss: 0.018144604480029015, valid_loss: 0.01833663824945688\nSEED: 7, FOLD: 4, EPOCH: 4,train_loss: 0.01787564389920537, valid_loss: 0.018098165307726177\nSEED: 7, FOLD: 4, EPOCH: 5,train_loss: 0.017760234506989735, valid_loss: 0.018112472790692533\nSEED: 7, FOLD: 4, EPOCH: 6,train_loss: 0.0177303664656221, valid_loss: 0.01781768897282226\nSEED: 7, FOLD: 4, EPOCH: 7,train_loss: 0.017825487697416025, valid_loss: 0.01809495612978935\nSEED: 7, FOLD: 4, EPOCH: 8,train_loss: 0.017740644541555557, valid_loss: 0.018008984518902642\nSEED: 7, FOLD: 4, EPOCH: 9,train_loss: 0.01774766732790116, valid_loss: 0.01769262874232871\nSEED: 7, FOLD: 4, EPOCH: 10,train_loss: 0.017750692817018084, valid_loss: 0.017801767215132713\nSEED: 7, FOLD: 4, EPOCH: 11,train_loss: 0.017697315285171288, valid_loss: 0.018170192358749254\nSEED: 7, FOLD: 4, EPOCH: 12,train_loss: 0.01759789483891665, valid_loss: 0.017821590495961052\nSEED: 7, FOLD: 4, EPOCH: 13,train_loss: 0.017526179835524246, valid_loss: 0.017600221798888274\nSEED: 7, FOLD: 4, EPOCH: 14,train_loss: 0.017411938564770895, valid_loss: 0.017610314009445054\nSEED: 7, FOLD: 4, EPOCH: 15,train_loss: 0.01727882203767481, valid_loss: 0.017513045322682178\nSEED: 7, FOLD: 4, EPOCH: 16,train_loss: 0.017027838931729395, valid_loss: 0.017459913449628012\nSEED: 7, FOLD: 4, EPOCH: 17,train_loss: 0.016856519802325012, valid_loss: 0.017451596313289235\nSEED: 7, FOLD: 4, EPOCH: 18,train_loss: 0.016547119514881702, valid_loss: 0.017295378952154092\nSEED: 7, FOLD: 4, EPOCH: 19,train_loss: 0.016183564338185217, valid_loss: 0.0172961452709777\nSEED: 7, FOLD: 4, EPOCH: 20,train_loss: 0.015734184256660334, valid_loss: 0.01725142196352993\nSEED: 7, FOLD: 4, EPOCH: 21,train_loss: 0.015237878765101019, valid_loss: 0.01723537966609001\nSEED: 7, FOLD: 4, EPOCH: 22,train_loss: 0.014738503512858913, valid_loss: 0.017206388525664806\nSEED: 7, FOLD: 4, EPOCH: 23,train_loss: 0.014258525685231754, valid_loss: 0.017228680130626475\nSEED: 7, FOLD: 4, EPOCH: 24,train_loss: 0.01401418734314865, valid_loss: 0.01722506196903331\nFOLD: 0, EPOCH: 0,train_loss: 0.7356072860042544, valid_loss: 0.700561819757734\nSEED: 8, FOLD: 0, EPOCH: 0,train_loss: 0.46673797306190007, valid_loss: 0.023924785905650683\nSEED: 8, FOLD: 0, EPOCH: 1,train_loss: 0.020825505406208283, valid_loss: 0.01878284364938736\nSEED: 8, FOLD: 0, EPOCH: 2,train_loss: 0.01894899301339675, valid_loss: 0.018203332674290452\nSEED: 8, FOLD: 0, EPOCH: 3,train_loss: 0.01825421461903483, valid_loss: 0.018200798918093952\nSEED: 8, FOLD: 0, EPOCH: 4,train_loss: 0.017930125715686893, valid_loss: 0.018148818612098695\nSEED: 8, FOLD: 0, EPOCH: 5,train_loss: 0.01782552664759603, valid_loss: 0.018230666539498737\nSEED: 8, FOLD: 0, EPOCH: 6,train_loss: 0.017810827923299622, valid_loss: 0.01818685159087181\nSEED: 8, FOLD: 0, EPOCH: 7,train_loss: 0.017807477405362756, valid_loss: 0.018600335557545936\nSEED: 8, FOLD: 0, EPOCH: 8,train_loss: 0.017825270445514334, valid_loss: 0.01820893654865878\nSEED: 8, FOLD: 0, EPOCH: 9,train_loss: 0.017788323560172188, valid_loss: 0.01803794660206352\nSEED: 8, FOLD: 0, EPOCH: 10,train_loss: 0.017779289887551845, valid_loss: 0.018155763910285064\nSEED: 8, FOLD: 0, EPOCH: 11,train_loss: 0.017800579024274853, valid_loss: 0.017654202399509294\nSEED: 8, FOLD: 0, EPOCH: 12,train_loss: 0.017638618160501447, valid_loss: 0.017771073138075216\nSEED: 8, FOLD: 0, EPOCH: 13,train_loss: 0.017530565564758585, valid_loss: 0.01787975515638079\nSEED: 8, FOLD: 0, EPOCH: 14,train_loss: 0.01739978432029921, valid_loss: 0.01786363601152386\nSEED: 8, FOLD: 0, EPOCH: 15,train_loss: 0.01723362010543364, valid_loss: 0.017615250471447196\nSEED: 8, FOLD: 0, EPOCH: 16,train_loss: 0.017078347041876645, valid_loss: 0.017777288252753872\nSEED: 8, FOLD: 0, EPOCH: 17,train_loss: 0.01681400591466766, valid_loss: 0.01740653184907777\nSEED: 8, FOLD: 0, EPOCH: 18,train_loss: 0.01652449359913377, valid_loss: 0.017524889989623\nSEED: 8, FOLD: 0, EPOCH: 19,train_loss: 0.016181924067655184, valid_loss: 0.017427152980651173\nSEED: 8, FOLD: 0, EPOCH: 20,train_loss: 0.015745426514559853, valid_loss: 0.017474204541317054\nSEED: 8, FOLD: 0, EPOCH: 21,train_loss: 0.015242645245072616, valid_loss: 0.017416460599218097\nSEED: 8, FOLD: 0, EPOCH: 22,train_loss: 0.01471561262125734, valid_loss: 0.017448320372828414\nSEED: 8, FOLD: 0, EPOCH: 23,train_loss: 0.01425646592856106, valid_loss: 0.017423856418047633\nSEED: 8, FOLD: 0, EPOCH: 24,train_loss: 0.01396904849739623, valid_loss: 0.017430945326175007\nFOLD: 1, EPOCH: 0,train_loss: 0.735147692155147, valid_loss: 0.6972033790179661\nSEED: 8, FOLD: 1, EPOCH: 0,train_loss: 0.4673015151604794, valid_loss: 0.024153126297252518\nSEED: 8, FOLD: 1, EPOCH: 1,train_loss: 0.020770340118611206, valid_loss: 0.01890219050858702\nSEED: 8, FOLD: 1, EPOCH: 2,train_loss: 0.018987581741226757, valid_loss: 0.019178061240485735\nSEED: 8, FOLD: 1, EPOCH: 3,train_loss: 0.0181736393791178, valid_loss: 0.018081311987979073\nSEED: 8, FOLD: 1, EPOCH: 4,train_loss: 0.017870194481118866, valid_loss: 0.01809252535126039\nSEED: 8, FOLD: 1, EPOCH: 5,train_loss: 0.0177922450221967, valid_loss: 0.019321390826787268\nSEED: 8, FOLD: 1, EPOCH: 6,train_loss: 0.017763219827759094, valid_loss: 0.01838514568018062\nSEED: 8, FOLD: 1, EPOCH: 7,train_loss: 0.017823370909183355, valid_loss: 0.018082326118435178\nSEED: 8, FOLD: 1, EPOCH: 8,train_loss: 0.017787358129693977, valid_loss: 0.017839678776051318\nSEED: 8, FOLD: 1, EPOCH: 9,train_loss: 0.017805895673623985, valid_loss: 0.018555259624762194\nSEED: 8, FOLD: 1, EPOCH: 10,train_loss: 0.017782910666226046, valid_loss: 0.018044696588601385\nSEED: 8, FOLD: 1, EPOCH: 11,train_loss: 0.01767050855509613, valid_loss: 0.017824697867035867\nSEED: 8, FOLD: 1, EPOCH: 12,train_loss: 0.01761647472428023, valid_loss: 0.01779207725610052\nSEED: 8, FOLD: 1, EPOCH: 13,train_loss: 0.017507889220302088, valid_loss: 0.017766571630324635\nSEED: 8, FOLD: 1, EPOCH: 14,train_loss: 0.017386308581014906, valid_loss: 0.017605417487876755\nSEED: 8, FOLD: 1, EPOCH: 15,train_loss: 0.017264908071661342, valid_loss: 0.017459292603390558\nSEED: 8, FOLD: 1, EPOCH: 16,train_loss: 0.017055051009832085, valid_loss: 0.01753146754843848\nSEED: 8, FOLD: 1, EPOCH: 17,train_loss: 0.016824177392097055, valid_loss: 0.01750749969588859\nSEED: 8, FOLD: 1, EPOCH: 18,train_loss: 0.016552437083336754, valid_loss: 0.01735015133661883\nSEED: 8, FOLD: 1, EPOCH: 19,train_loss: 0.016191066566692745, valid_loss: 0.01740962602198124\nSEED: 8, FOLD: 1, EPOCH: 20,train_loss: 0.01580728877308792, valid_loss: 0.017291143483349255\nSEED: 8, FOLD: 1, EPOCH: 21,train_loss: 0.01530882487397479, valid_loss: 0.017270460831267494\nSEED: 8, FOLD: 1, EPOCH: 22,train_loss: 0.014760156641241865, valid_loss: 0.017368366702326707\nSEED: 8, FOLD: 1, EPOCH: 23,train_loss: 0.014325207241041504, valid_loss: 0.017313287327332155\nSEED: 8, FOLD: 1, EPOCH: 24,train_loss: 0.014049023707005857, valid_loss: 0.017337492001908168\nFOLD: 2, EPOCH: 0,train_loss: 0.7352643639281176, valid_loss: 0.7011832935469491\nSEED: 8, FOLD: 2, EPOCH: 0,train_loss: 0.4670899900459293, valid_loss: 0.02614409157208034\nSEED: 8, FOLD: 2, EPOCH: 1,train_loss: 0.021354735100074955, valid_loss: 0.01929136509341853\nSEED: 8, FOLD: 2, EPOCH: 2,train_loss: 0.018951359515388806, valid_loss: 0.018246358526604518\nSEED: 8, FOLD: 2, EPOCH: 3,train_loss: 0.018178089946994314, valid_loss: 0.018066438048013618\nSEED: 8, FOLD: 2, EPOCH: 4,train_loss: 0.017870525006150852, valid_loss: 0.01812314758343356\nSEED: 8, FOLD: 2, EPOCH: 5,train_loss: 0.017771123800480713, valid_loss: 0.01791885332869632\nSEED: 8, FOLD: 2, EPOCH: 6,train_loss: 0.0178267666530134, valid_loss: 0.018084717994289738\nSEED: 8, FOLD: 2, EPOCH: 7,train_loss: 0.017849274445325136, valid_loss: 0.017941164172121455\nSEED: 8, FOLD: 2, EPOCH: 8,train_loss: 0.017872993118953014, valid_loss: 0.018502052527453218\nSEED: 8, FOLD: 2, EPOCH: 9,train_loss: 0.017886204361591652, valid_loss: 0.017968056537210942\nSEED: 8, FOLD: 2, EPOCH: 10,train_loss: 0.017853739522937416, valid_loss: 0.01791409006608384\nSEED: 8, FOLD: 2, EPOCH: 11,train_loss: 0.017788458311849314, valid_loss: 0.01766612340829202\nSEED: 8, FOLD: 2, EPOCH: 12,train_loss: 0.01768503380615426, valid_loss: 0.018021817744842596\nSEED: 8, FOLD: 2, EPOCH: 13,train_loss: 0.01760644643176077, valid_loss: 0.017838181156132903\nSEED: 8, FOLD: 2, EPOCH: 14,train_loss: 0.017514186769561922, valid_loss: 0.017758400844676153\nSEED: 8, FOLD: 2, EPOCH: 15,train_loss: 0.017356967013599216, valid_loss: 0.01763615169163261\nSEED: 8, FOLD: 2, EPOCH: 16,train_loss: 0.01718602190469054, valid_loss: 0.017409333879394192\nSEED: 8, FOLD: 2, EPOCH: 17,train_loss: 0.016964512175299984, valid_loss: 0.01730595010199717\nSEED: 8, FOLD: 2, EPOCH: 18,train_loss: 0.016622351415023422, valid_loss: 0.017457590944000654\nSEED: 8, FOLD: 2, EPOCH: 19,train_loss: 0.01639004510597906, valid_loss: 0.017312571007226194\nSEED: 8, FOLD: 2, EPOCH: 20,train_loss: 0.015920214503463627, valid_loss: 0.017158984898456506\nSEED: 8, FOLD: 2, EPOCH: 21,train_loss: 0.015429162595799004, valid_loss: 0.0171811736321875\nSEED: 8, FOLD: 2, EPOCH: 22,train_loss: 0.014947136479389408, valid_loss: 0.017173597562525955\nSEED: 8, FOLD: 2, EPOCH: 23,train_loss: 0.014511652182841646, valid_loss: 0.01718401350080967\nSEED: 8, FOLD: 2, EPOCH: 24,train_loss: 0.014257184465996164, valid_loss: 0.017162492126226427\nFOLD: 3, EPOCH: 0,train_loss: 0.7355087261269058, valid_loss: 0.6986959712845938\nSEED: 8, FOLD: 3, EPOCH: 0,train_loss: 0.46701054432955774, valid_loss: 0.02335335165262222\nSEED: 8, FOLD: 3, EPOCH: 1,train_loss: 0.02100361984871004, valid_loss: 0.0187792945387108\nSEED: 8, FOLD: 3, EPOCH: 2,train_loss: 0.019050639736857534, valid_loss: 0.017950198825980937\nSEED: 8, FOLD: 3, EPOCH: 3,train_loss: 0.018228112645717203, valid_loss: 0.01765317323484591\nSEED: 8, FOLD: 3, EPOCH: 4,train_loss: 0.017890949524345175, valid_loss: 0.01759836245328188\nSEED: 8, FOLD: 3, EPOCH: 5,train_loss: 0.017854639477487923, valid_loss: 0.017738086198057446\nSEED: 8, FOLD: 3, EPOCH: 6,train_loss: 0.01784971755915794, valid_loss: 0.01804628268416439\nSEED: 8, FOLD: 3, EPOCH: 7,train_loss: 0.017826033762885607, valid_loss: 0.017729062028229235\nSEED: 8, FOLD: 3, EPOCH: 8,train_loss: 0.017865440470800884, valid_loss: 0.017703781090676784\nSEED: 8, FOLD: 3, EPOCH: 9,train_loss: 0.017880016330467617, valid_loss: 0.017735221423208714\nSEED: 8, FOLD: 3, EPOCH: 10,train_loss: 0.017865651293887175, valid_loss: 0.01781427189707756\nSEED: 8, FOLD: 3, EPOCH: 11,train_loss: 0.017802005201794098, valid_loss: 0.017581038203622612\nSEED: 8, FOLD: 3, EPOCH: 12,train_loss: 0.017661075141496847, valid_loss: 0.017469097806939057\nSEED: 8, FOLD: 3, EPOCH: 13,train_loss: 0.017572081344121176, valid_loss: 0.0177882280466812\nSEED: 8, FOLD: 3, EPOCH: 14,train_loss: 0.017518406787860222, valid_loss: 0.017352711116628988\nSEED: 8, FOLD: 3, EPOCH: 15,train_loss: 0.017331583101464355, valid_loss: 0.01737997159361839\nSEED: 8, FOLD: 3, EPOCH: 16,train_loss: 0.017168758248073467, valid_loss: 0.017527659397040096\nSEED: 8, FOLD: 3, EPOCH: 17,train_loss: 0.01692115860329806, valid_loss: 0.01723207136882203\nSEED: 8, FOLD: 3, EPOCH: 18,train_loss: 0.016650409930372152, valid_loss: 0.01716717973883663\nSEED: 8, FOLD: 3, EPOCH: 19,train_loss: 0.016317272592551897, valid_loss: 0.01712580264679023\nSEED: 8, FOLD: 3, EPOCH: 20,train_loss: 0.015912632532147825, valid_loss: 0.017090180250150817\nSEED: 8, FOLD: 3, EPOCH: 21,train_loss: 0.015434734597532213, valid_loss: 0.017057473052825248\nSEED: 8, FOLD: 3, EPOCH: 22,train_loss: 0.014928124041930921, valid_loss: 0.016925052420369218\nSEED: 8, FOLD: 3, EPOCH: 23,train_loss: 0.014497802417347397, valid_loss: 0.01703327644084181\nSEED: 8, FOLD: 3, EPOCH: 24,train_loss: 0.014266613054264715, valid_loss: 0.017028408949928624\nFOLD: 4, EPOCH: 0,train_loss: 0.7356057180010754, valid_loss: 0.701486337184906\nSEED: 8, FOLD: 4, EPOCH: 0,train_loss: 0.4655963025474246, valid_loss: 0.023416614372815406\nSEED: 8, FOLD: 4, EPOCH: 1,train_loss: 0.020811862244770146, valid_loss: 0.01902759684515851\nSEED: 8, FOLD: 4, EPOCH: 2,train_loss: 0.019045220951185278, valid_loss: 0.018703741314155715\nSEED: 8, FOLD: 4, EPOCH: 3,train_loss: 0.018245001971397713, valid_loss: 0.018083832333130496\nSEED: 8, FOLD: 4, EPOCH: 4,train_loss: 0.017974372305299923, valid_loss: 0.017895456084183286\nSEED: 8, FOLD: 4, EPOCH: 5,train_loss: 0.017940660526948995, valid_loss: 0.017731092870235443\nSEED: 8, FOLD: 4, EPOCH: 6,train_loss: 0.017947793371327545, valid_loss: 0.01861857676080295\nSEED: 8, FOLD: 4, EPOCH: 7,train_loss: 0.017969171131920557, valid_loss: 0.01820842283112662\nSEED: 8, FOLD: 4, EPOCH: 8,train_loss: 0.017978879515135635, valid_loss: 0.017808202813778606\nSEED: 8, FOLD: 4, EPOCH: 9,train_loss: 0.017914860759038424, valid_loss: 0.017583609239331315\nSEED: 8, FOLD: 4, EPOCH: 10,train_loss: 0.017864257367192837, valid_loss: 0.01780960126114743\nSEED: 8, FOLD: 4, EPOCH: 11,train_loss: 0.01782042097867183, valid_loss: 0.01791394909045526\nSEED: 8, FOLD: 4, EPOCH: 12,train_loss: 0.017781998725958925, valid_loss: 0.017637642366545542\nSEED: 8, FOLD: 4, EPOCH: 13,train_loss: 0.01767244940434677, valid_loss: 0.017893291930002827\nSEED: 8, FOLD: 4, EPOCH: 14,train_loss: 0.017566954514578632, valid_loss: 0.0174483059240239\nSEED: 8, FOLD: 4, EPOCH: 15,train_loss: 0.01743970749278863, valid_loss: 0.017403487328972136\nSEED: 8, FOLD: 4, EPOCH: 16,train_loss: 0.017242635640761127, valid_loss: 0.017188010231724806\nSEED: 8, FOLD: 4, EPOCH: 17,train_loss: 0.01702831465534974, valid_loss: 0.017234831276748862\nSEED: 8, FOLD: 4, EPOCH: 18,train_loss: 0.016728441284942455, valid_loss: 0.017144486414534706\nSEED: 8, FOLD: 4, EPOCH: 19,train_loss: 0.01649043367554744, valid_loss: 0.01694198716431856\nSEED: 8, FOLD: 4, EPOCH: 20,train_loss: 0.016010645459797503, valid_loss: 0.01695406495460442\nSEED: 8, FOLD: 4, EPOCH: 21,train_loss: 0.015545766901872728, valid_loss: 0.016974758197154317\nSEED: 8, FOLD: 4, EPOCH: 22,train_loss: 0.015059012062577665, valid_loss: 0.016894142702221872\nSEED: 8, FOLD: 4, EPOCH: 23,train_loss: 0.014660074746749107, valid_loss: 0.016906079676534447\nSEED: 8, FOLD: 4, EPOCH: 24,train_loss: 0.014399465159985466, valid_loss: 0.01689590077315058\nFOLD: 0, EPOCH: 0,train_loss: 0.7354797280353048, valid_loss: 0.7026144453457424\nSEED: 9, FOLD: 0, EPOCH: 0,train_loss: 0.4670643887172143, valid_loss: 0.02442635212625776\nSEED: 9, FOLD: 0, EPOCH: 1,train_loss: 0.021194402992293453, valid_loss: 0.01873366329818964\nSEED: 9, FOLD: 0, EPOCH: 2,train_loss: 0.01940161208419696, valid_loss: 0.018093398426260267\nSEED: 9, FOLD: 0, EPOCH: 3,train_loss: 0.018554877186113077, valid_loss: 0.017869629418211325\nSEED: 9, FOLD: 0, EPOCH: 4,train_loss: 0.017948186389454033, valid_loss: 0.018210870080760548\nSEED: 9, FOLD: 0, EPOCH: 5,train_loss: 0.017959931480657797, valid_loss: 0.018264250217803885\nSEED: 9, FOLD: 0, EPOCH: 6,train_loss: 0.01793923960539742, valid_loss: 0.01760462237788098\nSEED: 9, FOLD: 0, EPOCH: 7,train_loss: 0.01788007411295953, valid_loss: 0.01819910742342472\nSEED: 9, FOLD: 0, EPOCH: 8,train_loss: 0.017918306328626215, valid_loss: 0.017848346222724232\nSEED: 9, FOLD: 0, EPOCH: 9,train_loss: 0.01782957002169628, valid_loss: 0.017831979691982268\nSEED: 9, FOLD: 0, EPOCH: 10,train_loss: 0.017836725379785767, valid_loss: 0.017694744387907642\nSEED: 9, FOLD: 0, EPOCH: 11,train_loss: 0.01775338411655115, valid_loss: 0.017573812470904417\nSEED: 9, FOLD: 0, EPOCH: 12,train_loss: 0.017700537094387455, valid_loss: 0.01769630347511598\nSEED: 9, FOLD: 0, EPOCH: 13,train_loss: 0.01763704105320832, valid_loss: 0.017575750633009844\nSEED: 9, FOLD: 0, EPOCH: 14,train_loss: 0.01751667597884501, valid_loss: 0.017593975897346223\nSEED: 9, FOLD: 0, EPOCH: 15,train_loss: 0.017396490400036175, valid_loss: 0.017616434155830314\nSEED: 9, FOLD: 0, EPOCH: 16,train_loss: 0.017164439752535975, valid_loss: 0.01746917116854872\nSEED: 9, FOLD: 0, EPOCH: 17,train_loss: 0.016966302285267822, valid_loss: 0.017473210234727178\nSEED: 9, FOLD: 0, EPOCH: 18,train_loss: 0.0167028295227151, valid_loss: 0.017152578011155127\nSEED: 9, FOLD: 0, EPOCH: 19,train_loss: 0.016370923332600058, valid_loss: 0.017226645696376053\nSEED: 9, FOLD: 0, EPOCH: 20,train_loss: 0.01594582123115011, valid_loss: 0.017293568567505906\nSEED: 9, FOLD: 0, EPOCH: 21,train_loss: 0.01551791881143615, valid_loss: 0.01713459502373423\nSEED: 9, FOLD: 0, EPOCH: 22,train_loss: 0.014990996711118065, valid_loss: 0.017137648990111692\nSEED: 9, FOLD: 0, EPOCH: 23,train_loss: 0.014586738803410444, valid_loss: 0.01714634405715125\nSEED: 9, FOLD: 0, EPOCH: 24,train_loss: 0.014349956004677908, valid_loss: 0.017176157608628274\nFOLD: 1, EPOCH: 0,train_loss: 0.7355779043949433, valid_loss: 0.7027910266603742\nSEED: 9, FOLD: 1, EPOCH: 0,train_loss: 0.46750690888640656, valid_loss: 0.02345428371003696\nSEED: 9, FOLD: 1, EPOCH: 1,train_loss: 0.020926080793686158, valid_loss: 0.01915691452366965\nSEED: 9, FOLD: 1, EPOCH: 2,train_loss: 0.01909914658316513, valid_loss: 0.01837432102433273\nSEED: 9, FOLD: 1, EPOCH: 3,train_loss: 0.018168802447888974, valid_loss: 0.018143319711089134\nSEED: 9, FOLD: 1, EPOCH: 4,train_loss: 0.017931652860376086, valid_loss: 0.018018182792833872\nSEED: 9, FOLD: 1, EPOCH: 5,train_loss: 0.017882975960408685, valid_loss: 0.017954085447958536\nSEED: 9, FOLD: 1, EPOCH: 6,train_loss: 0.01791356213689938, valid_loss: 0.018067332676478795\nSEED: 9, FOLD: 1, EPOCH: 7,train_loss: 0.01796154205408627, valid_loss: 0.017957504998360362\nSEED: 9, FOLD: 1, EPOCH: 8,train_loss: 0.01795931571727469, valid_loss: 0.018081026338040828\nSEED: 9, FOLD: 1, EPOCH: 9,train_loss: 0.017928340261543753, valid_loss: 0.0177639225763934\nSEED: 9, FOLD: 1, EPOCH: 10,train_loss: 0.01783448386339158, valid_loss: 0.018007919458406314\nSEED: 9, FOLD: 1, EPOCH: 11,train_loss: 0.017790282253910154, valid_loss: 0.017756416488971027\nSEED: 9, FOLD: 1, EPOCH: 12,train_loss: 0.017706310770807476, valid_loss: 0.01781411197568689\nSEED: 9, FOLD: 1, EPOCH: 13,train_loss: 0.017627976773592242, valid_loss: 0.017625004798173905\nSEED: 9, FOLD: 1, EPOCH: 14,train_loss: 0.017503775941738246, valid_loss: 0.017549726393605983\nSEED: 9, FOLD: 1, EPOCH: 15,train_loss: 0.017363469340722925, valid_loss: 0.017767291170145784\nSEED: 9, FOLD: 1, EPOCH: 16,train_loss: 0.017150241636881863, valid_loss: 0.017606096634907382\nSEED: 9, FOLD: 1, EPOCH: 17,train_loss: 0.01699548303047671, valid_loss: 0.017341961871300424\nSEED: 9, FOLD: 1, EPOCH: 18,train_loss: 0.01668929668265755, valid_loss: 0.017271200780357633\nSEED: 9, FOLD: 1, EPOCH: 19,train_loss: 0.016362575515017023, valid_loss: 0.01728434568004949\nSEED: 9, FOLD: 1, EPOCH: 20,train_loss: 0.015904981690547326, valid_loss: 0.017272270710340567\nSEED: 9, FOLD: 1, EPOCH: 21,train_loss: 0.015442091686120868, valid_loss: 0.01727974811302764\nSEED: 9, FOLD: 1, EPOCH: 22,train_loss: 0.014952334208264403, valid_loss: 0.017236443050205708\nSEED: 9, FOLD: 1, EPOCH: 23,train_loss: 0.014540559653002416, valid_loss: 0.017247832247189114\nSEED: 9, FOLD: 1, EPOCH: 24,train_loss: 0.014295373445064046, valid_loss: 0.017257260903716088\nFOLD: 2, EPOCH: 0,train_loss: 0.7358072896798452, valid_loss: 0.7063391055379595\nSEED: 9, FOLD: 2, EPOCH: 0,train_loss: 0.46652523048923933, valid_loss: 0.023053203469940595\nSEED: 9, FOLD: 2, EPOCH: 1,train_loss: 0.021089744322217892, valid_loss: 0.01927791264440332\nSEED: 9, FOLD: 2, EPOCH: 2,train_loss: 0.019158143705377977, valid_loss: 0.018354257568717003\nSEED: 9, FOLD: 2, EPOCH: 3,train_loss: 0.01821031345837358, valid_loss: 0.01816156841814518\nSEED: 9, FOLD: 2, EPOCH: 4,train_loss: 0.017842253312414538, valid_loss: 0.01820169857570103\nSEED: 9, FOLD: 2, EPOCH: 5,train_loss: 0.017918522550683956, valid_loss: 0.018555782522474015\nSEED: 9, FOLD: 2, EPOCH: 6,train_loss: 0.017946023905676775, valid_loss: 0.017914316191204958\nSEED: 9, FOLD: 2, EPOCH: 7,train_loss: 0.017879689638705357, valid_loss: 0.01813406374837671\nSEED: 9, FOLD: 2, EPOCH: 8,train_loss: 0.017959138371752226, valid_loss: 0.01811481916478702\nSEED: 9, FOLD: 2, EPOCH: 9,train_loss: 0.01793065071240931, valid_loss: 0.017877178905265672\nSEED: 9, FOLD: 2, EPOCH: 10,train_loss: 0.01787792971573662, valid_loss: 0.018524715091500964\nSEED: 9, FOLD: 2, EPOCH: 11,train_loss: 0.01784768681028399, valid_loss: 0.01793638656714133\nSEED: 9, FOLD: 2, EPOCH: 12,train_loss: 0.01774384142102107, valid_loss: 0.01769783164241484\nSEED: 9, FOLD: 2, EPOCH: 13,train_loss: 0.017670129999464403, valid_loss: 0.017686942352780274\nSEED: 9, FOLD: 2, EPOCH: 14,train_loss: 0.017545571233537317, valid_loss: 0.017725772836378644\nSEED: 9, FOLD: 2, EPOCH: 15,train_loss: 0.01738509838806762, valid_loss: 0.017572694724159583\nSEED: 9, FOLD: 2, EPOCH: 16,train_loss: 0.01725568330131363, valid_loss: 0.017609440934445178\nSEED: 9, FOLD: 2, EPOCH: 17,train_loss: 0.01705193085649955, valid_loss: 0.017252216168812343\nSEED: 9, FOLD: 2, EPOCH: 18,train_loss: 0.016705049728245838, valid_loss: 0.017218729720583983\nSEED: 9, FOLD: 2, EPOCH: 19,train_loss: 0.016362252213276814, valid_loss: 0.017207986169627734\nSEED: 9, FOLD: 2, EPOCH: 20,train_loss: 0.016042927853709112, valid_loss: 0.01724352974976812\nSEED: 9, FOLD: 2, EPOCH: 21,train_loss: 0.015575094836885515, valid_loss: 0.017124888566987854\nSEED: 9, FOLD: 2, EPOCH: 22,train_loss: 0.015078321267999168, valid_loss: 0.017093066950993878\nSEED: 9, FOLD: 2, EPOCH: 23,train_loss: 0.01466555249593828, valid_loss: 0.01713842209428549\nSEED: 9, FOLD: 2, EPOCH: 24,train_loss: 0.014417066630245983, valid_loss: 0.017127615931843008\nFOLD: 3, EPOCH: 0,train_loss: 0.7357607695503511, valid_loss: 0.7039754268001107\nSEED: 9, FOLD: 3, EPOCH: 0,train_loss: 0.46692669133831194, valid_loss: 0.02353850198800073\nSEED: 9, FOLD: 3, EPOCH: 1,train_loss: 0.020716701593735943, valid_loss: 0.018719997804831055\nSEED: 9, FOLD: 3, EPOCH: 2,train_loss: 0.01889242561183114, valid_loss: 0.018318229300134322\nSEED: 9, FOLD: 3, EPOCH: 3,train_loss: 0.017982685013903654, valid_loss: 0.01822973196120823\nSEED: 9, FOLD: 3, EPOCH: 4,train_loss: 0.0178809172635817, valid_loss: 0.018292818054118577\nSEED: 9, FOLD: 3, EPOCH: 5,train_loss: 0.017838251594777987, valid_loss: 0.01887446302263176\nSEED: 9, FOLD: 3, EPOCH: 6,train_loss: 0.017766532447675, valid_loss: 0.01819071705069612\nSEED: 9, FOLD: 3, EPOCH: 7,train_loss: 0.017743092043784218, valid_loss: 0.018077440450296682\nSEED: 9, FOLD: 3, EPOCH: 8,train_loss: 0.01775644008961061, valid_loss: 0.01810489099144059\nSEED: 9, FOLD: 3, EPOCH: 9,train_loss: 0.017737147445534018, valid_loss: 0.01803460900726564\nSEED: 9, FOLD: 3, EPOCH: 10,train_loss: 0.017731866684566805, valid_loss: 0.018138960770824376\nSEED: 9, FOLD: 3, EPOCH: 11,train_loss: 0.017683456793589437, valid_loss: 0.01814645156264305\nSEED: 9, FOLD: 3, EPOCH: 12,train_loss: 0.017666853586400764, valid_loss: 0.01798402635818895\nSEED: 9, FOLD: 3, EPOCH: 13,train_loss: 0.017503045701786228, valid_loss: 0.0180007869596867\nSEED: 9, FOLD: 3, EPOCH: 14,train_loss: 0.01738889203609332, valid_loss: 0.017866676536333913\nSEED: 9, FOLD: 3, EPOCH: 15,train_loss: 0.0172482172459148, valid_loss: 0.017778926967259717\nSEED: 9, FOLD: 3, EPOCH: 16,train_loss: 0.01709473818756532, valid_loss: 0.01766644010101171\nSEED: 9, FOLD: 3, EPOCH: 17,train_loss: 0.016876113722505776, valid_loss: 0.017613861463306582\nSEED: 9, FOLD: 3, EPOCH: 18,train_loss: 0.016530182792980602, valid_loss: 0.017585630610804346\nSEED: 9, FOLD: 3, EPOCH: 19,train_loss: 0.01624455551981278, valid_loss: 0.017737577121485684\nSEED: 9, FOLD: 3, EPOCH: 20,train_loss: 0.015831548713849508, valid_loss: 0.017494009314652753\nSEED: 9, FOLD: 3, EPOCH: 21,train_loss: 0.015352452045603506, valid_loss: 0.017478207208435324\nSEED: 9, FOLD: 3, EPOCH: 22,train_loss: 0.014860340238859257, valid_loss: 0.017463588320157108\nSEED: 9, FOLD: 3, EPOCH: 23,train_loss: 0.01443924496382259, valid_loss: 0.017470941687112346\nSEED: 9, FOLD: 3, EPOCH: 24,train_loss: 0.014191195044828497, valid_loss: 0.017463221324279028\nFOLD: 4, EPOCH: 0,train_loss: 0.7358433756515057, valid_loss: 0.7041940314429147\nSEED: 9, FOLD: 4, EPOCH: 0,train_loss: 0.4680235726065444, valid_loss: 0.023747898372156278\nSEED: 9, FOLD: 4, EPOCH: 1,train_loss: 0.020990130375989163, valid_loss: 0.01884049219744546\nSEED: 9, FOLD: 4, EPOCH: 2,train_loss: 0.01901303575693691, valid_loss: 0.01838291526905128\nSEED: 9, FOLD: 4, EPOCH: 3,train_loss: 0.018300949371535414, valid_loss: 0.018207542119281633\nSEED: 9, FOLD: 4, EPOCH: 4,train_loss: 0.017902498106288647, valid_loss: 0.018182423497949327\nSEED: 9, FOLD: 4, EPOCH: 5,train_loss: 0.017968351538055136, valid_loss: 0.017986882052251272\nSEED: 9, FOLD: 4, EPOCH: 6,train_loss: 0.01791132359772268, valid_loss: 0.017844694959265845\nSEED: 9, FOLD: 4, EPOCH: 7,train_loss: 0.01792573749366468, valid_loss: 0.01769905085010188\nSEED: 9, FOLD: 4, EPOCH: 8,train_loss: 0.017905865557981234, valid_loss: 0.017714029071586472\nSEED: 9, FOLD: 4, EPOCH: 9,train_loss: 0.017893048207255177, valid_loss: 0.017890050155775886\nSEED: 9, FOLD: 4, EPOCH: 10,train_loss: 0.01787322449640636, valid_loss: 0.017613728929843222\nSEED: 9, FOLD: 4, EPOCH: 11,train_loss: 0.017809463719273135, valid_loss: 0.017757723586899893\nSEED: 9, FOLD: 4, EPOCH: 12,train_loss: 0.017798735603798917, valid_loss: 0.017570759329412666\nSEED: 9, FOLD: 4, EPOCH: 13,train_loss: 0.01761450422723798, valid_loss: 0.017389539230082716\nSEED: 9, FOLD: 4, EPOCH: 14,train_loss: 0.017562343324296667, valid_loss: 0.017467229733509677\nSEED: 9, FOLD: 4, EPOCH: 15,train_loss: 0.01737228595400161, valid_loss: 0.01738234090485743\nSEED: 9, FOLD: 4, EPOCH: 16,train_loss: 0.017186525821631406, valid_loss: 0.017251967000109808\nSEED: 9, FOLD: 4, EPOCH: 17,train_loss: 0.016936379960690535, valid_loss: 0.017327262780496053\nSEED: 9, FOLD: 4, EPOCH: 18,train_loss: 0.016608479262812295, valid_loss: 0.017335031633930548\nSEED: 9, FOLD: 4, EPOCH: 19,train_loss: 0.016311339687311303, valid_loss: 0.01719209173960345\nSEED: 9, FOLD: 4, EPOCH: 20,train_loss: 0.015867283336655068, valid_loss: 0.017192155122756958\nSEED: 9, FOLD: 4, EPOCH: 21,train_loss: 0.0153989047219936, valid_loss: 0.01707347014120647\nSEED: 9, FOLD: 4, EPOCH: 22,train_loss: 0.014859003137226087, valid_loss: 0.01704621370881796\nSEED: 9, FOLD: 4, EPOCH: 23,train_loss: 0.014453198624788409, valid_loss: 0.017015469154076916\nSEED: 9, FOLD: 4, EPOCH: 24,train_loss: 0.01419620976586194, valid_loss: 0.016998186042266234\nFOLD: 0, EPOCH: 0,train_loss: 0.7348106287527776, valid_loss: 0.7064803856260636\nSEED: 10, FOLD: 0, EPOCH: 0,train_loss: 0.46611945734669763, valid_loss: 0.02390553287285216\nSEED: 10, FOLD: 0, EPOCH: 1,train_loss: 0.020717729503909748, valid_loss: 0.01910296589245691\nSEED: 10, FOLD: 0, EPOCH: 2,train_loss: 0.01888080200423365, valid_loss: 0.018549432074103284\nSEED: 10, FOLD: 0, EPOCH: 3,train_loss: 0.01820930505198413, valid_loss: 0.019288804601220524\nSEED: 10, FOLD: 0, EPOCH: 4,train_loss: 0.01790676480564086, valid_loss: 0.018769742784035558\nSEED: 10, FOLD: 0, EPOCH: 5,train_loss: 0.017787766825083807, valid_loss: 0.018194130019230002\nSEED: 10, FOLD: 0, EPOCH: 6,train_loss: 0.017824083492429792, valid_loss: 0.018163382075726986\nSEED: 10, FOLD: 0, EPOCH: 7,train_loss: 0.017790610058422106, valid_loss: 0.019116988898638415\nSEED: 10, FOLD: 0, EPOCH: 8,train_loss: 0.01785684205537689, valid_loss: 0.018902227939928278\nSEED: 10, FOLD: 0, EPOCH: 9,train_loss: 0.017823834181425795, valid_loss: 0.018433784819482005\nSEED: 10, FOLD: 0, EPOCH: 10,train_loss: 0.01775058935922773, valid_loss: 0.018239006180973613\nSEED: 10, FOLD: 0, EPOCH: 11,train_loss: 0.017726487689314112, valid_loss: 0.01827583637307672\nSEED: 10, FOLD: 0, EPOCH: 12,train_loss: 0.017656570246470146, valid_loss: 0.018001912380842602\nSEED: 10, FOLD: 0, EPOCH: 13,train_loss: 0.017584553912983858, valid_loss: 0.018083773443804067\nSEED: 10, FOLD: 0, EPOCH: 14,train_loss: 0.01747954190047323, valid_loss: 0.01790727727005587\nSEED: 10, FOLD: 0, EPOCH: 15,train_loss: 0.017325068007398775, valid_loss: 0.018002703511977896\nSEED: 10, FOLD: 0, EPOCH: 16,train_loss: 0.017107301870819883, valid_loss: 0.017745467505472547\nSEED: 10, FOLD: 0, EPOCH: 17,train_loss: 0.016917732537494623, valid_loss: 0.017541509422966662\nSEED: 10, FOLD: 0, EPOCH: 18,train_loss: 0.016562306659593098, valid_loss: 0.017663479782640934\nSEED: 10, FOLD: 0, EPOCH: 19,train_loss: 0.016204957269887993, valid_loss: 0.01766219491358189\nSEED: 10, FOLD: 0, EPOCH: 20,train_loss: 0.015851812187474276, valid_loss: 0.017571751165258533\nSEED: 10, FOLD: 0, EPOCH: 21,train_loss: 0.015335232059916725, valid_loss: 0.017516057280933157\nSEED: 10, FOLD: 0, EPOCH: 22,train_loss: 0.014850971248486767, valid_loss: 0.017529814613654333\nSEED: 10, FOLD: 0, EPOCH: 23,train_loss: 0.014411749122529358, valid_loss: 0.017475922756335315\nSEED: 10, FOLD: 0, EPOCH: 24,train_loss: 0.014166360349812801, valid_loss: 0.017483681440353394\nFOLD: 1, EPOCH: 0,train_loss: 0.7344339141880509, valid_loss: 0.7066689845588472\nSEED: 10, FOLD: 1, EPOCH: 0,train_loss: 0.46853696886640395, valid_loss: 0.02351305576869183\nSEED: 10, FOLD: 1, EPOCH: 1,train_loss: 0.020734932803868376, valid_loss: 0.01877791253435943\nSEED: 10, FOLD: 1, EPOCH: 2,train_loss: 0.01896899464084719, valid_loss: 0.018268760966344014\nSEED: 10, FOLD: 1, EPOCH: 3,train_loss: 0.018299544787537442, valid_loss: 0.017815887617568176\nSEED: 10, FOLD: 1, EPOCH: 4,train_loss: 0.017957237603509948, valid_loss: 0.018234221083629463\nSEED: 10, FOLD: 1, EPOCH: 5,train_loss: 0.01802379214442777, valid_loss: 0.017892285172517102\nSEED: 10, FOLD: 1, EPOCH: 6,train_loss: 0.017941595463041405, valid_loss: 0.01774620275116629\nSEED: 10, FOLD: 1, EPOCH: 7,train_loss: 0.01794303736792211, valid_loss: 0.017660776592998043\nSEED: 10, FOLD: 1, EPOCH: 8,train_loss: 0.01795817696129101, valid_loss: 0.018063846639254026\nSEED: 10, FOLD: 1, EPOCH: 9,train_loss: 0.017996652616038375, valid_loss: 0.017893742019724514\nSEED: 10, FOLD: 1, EPOCH: 10,train_loss: 0.017950847146719913, valid_loss: 0.018005995079874992\nSEED: 10, FOLD: 1, EPOCH: 11,train_loss: 0.017847911563504786, valid_loss: 0.017894700764574938\nSEED: 10, FOLD: 1, EPOCH: 12,train_loss: 0.017767505808631436, valid_loss: 0.018187304286079273\nSEED: 10, FOLD: 1, EPOCH: 13,train_loss: 0.01772335053414759, valid_loss: 0.01765547739341855\nSEED: 10, FOLD: 1, EPOCH: 14,train_loss: 0.017601339826292365, valid_loss: 0.017900868577675685\nSEED: 10, FOLD: 1, EPOCH: 15,train_loss: 0.01739878311454162, valid_loss: 0.01746787174811794\nSEED: 10, FOLD: 1, EPOCH: 16,train_loss: 0.017316167270016933, valid_loss: 0.01740545880359908\nSEED: 10, FOLD: 1, EPOCH: 17,train_loss: 0.017080216267465673, valid_loss: 0.017378549117387995\nSEED: 10, FOLD: 1, EPOCH: 18,train_loss: 0.016741649315685687, valid_loss: 0.017357351413617533\nSEED: 10, FOLD: 1, EPOCH: 19,train_loss: 0.016436830332951388, valid_loss: 0.017161849239427183\nSEED: 10, FOLD: 1, EPOCH: 20,train_loss: 0.016019086652591715, valid_loss: 0.017101509315479133\nSEED: 10, FOLD: 1, EPOCH: 21,train_loss: 0.01556046560651412, valid_loss: 0.01704715538976921\nSEED: 10, FOLD: 1, EPOCH: 22,train_loss: 0.015065633311160724, valid_loss: 0.017081687226891518\nSEED: 10, FOLD: 1, EPOCH: 23,train_loss: 0.014660105687042657, valid_loss: 0.017105034888825484\nSEED: 10, FOLD: 1, EPOCH: 24,train_loss: 0.014398444913001391, valid_loss: 0.017096496626941696\nFOLD: 2, EPOCH: 0,train_loss: 0.7338760456313258, valid_loss: 0.7030700547354561\nSEED: 10, FOLD: 2, EPOCH: 0,train_loss: 0.4675271331427106, valid_loss: 0.02353462523647717\nSEED: 10, FOLD: 2, EPOCH: 1,train_loss: 0.021161221035256767, valid_loss: 0.018672038135784014\nSEED: 10, FOLD: 2, EPOCH: 2,train_loss: 0.018925914216948593, valid_loss: 0.018182597043258805\nSEED: 10, FOLD: 2, EPOCH: 3,train_loss: 0.01801973908626731, valid_loss: 0.017934346411909375\nSEED: 10, FOLD: 2, EPOCH: 4,train_loss: 0.017812360881193392, valid_loss: 0.018802500143647195\nSEED: 10, FOLD: 2, EPOCH: 5,train_loss: 0.017900344611995894, valid_loss: 0.02216718484248434\nSEED: 10, FOLD: 2, EPOCH: 6,train_loss: 0.017741532564379166, valid_loss: 0.018045286940676825\nSEED: 10, FOLD: 2, EPOCH: 7,train_loss: 0.01779422616802048, valid_loss: 0.01799632917557444\nSEED: 10, FOLD: 2, EPOCH: 8,train_loss: 0.017787555084172367, valid_loss: 0.01821353491395712\nSEED: 10, FOLD: 2, EPOCH: 9,train_loss: 0.017741226638410833, valid_loss: 0.017977745405265262\nSEED: 10, FOLD: 2, EPOCH: 10,train_loss: 0.0177272233126712, valid_loss: 0.017927730243120873\nSEED: 10, FOLD: 2, EPOCH: 11,train_loss: 0.01768137055678644, valid_loss: 0.01803554200700351\nSEED: 10, FOLD: 2, EPOCH: 12,train_loss: 0.017632240584741037, valid_loss: 0.01842866593173572\nSEED: 10, FOLD: 2, EPOCH: 13,train_loss: 0.017525814939290285, valid_loss: 0.017759073046701296\nSEED: 10, FOLD: 2, EPOCH: 14,train_loss: 0.017421988716376, valid_loss: 0.0176163824275136\nSEED: 10, FOLD: 2, EPOCH: 15,train_loss: 0.017217026564522064, valid_loss: 0.01768573144716876\nSEED: 10, FOLD: 2, EPOCH: 16,train_loss: 0.01709370557353764, valid_loss: 0.017572808771261147\nSEED: 10, FOLD: 2, EPOCH: 17,train_loss: 0.01679277452437774, valid_loss: 0.017567909375897476\nSEED: 10, FOLD: 2, EPOCH: 18,train_loss: 0.01650963341007414, valid_loss: 0.017354240162031992\nSEED: 10, FOLD: 2, EPOCH: 19,train_loss: 0.0161677407897145, valid_loss: 0.01727579797485045\nSEED: 10, FOLD: 2, EPOCH: 20,train_loss: 0.015748496457556452, valid_loss: 0.017369031852909497\nSEED: 10, FOLD: 2, EPOCH: 21,train_loss: 0.015284254445113998, valid_loss: 0.017315724518682275\nSEED: 10, FOLD: 2, EPOCH: 22,train_loss: 0.014748661353698244, valid_loss: 0.017327057091253144\nSEED: 10, FOLD: 2, EPOCH: 23,train_loss: 0.014299678609477005, valid_loss: 0.017329009382852485\nSEED: 10, FOLD: 2, EPOCH: 24,train_loss: 0.014026425839604242, valid_loss: 0.017338252040956702\nFOLD: 3, EPOCH: 0,train_loss: 0.7343437395234039, valid_loss: 0.7032661472048078\nSEED: 10, FOLD: 3, EPOCH: 0,train_loss: 0.4677891261416717, valid_loss: 0.026968024564640862\nSEED: 10, FOLD: 3, EPOCH: 1,train_loss: 0.020807195535820465, valid_loss: 0.018923397787979673\nSEED: 10, FOLD: 3, EPOCH: 2,train_loss: 0.01962638294081325, valid_loss: 0.01804031194852931\nSEED: 10, FOLD: 3, EPOCH: 3,train_loss: 0.01816392394349627, valid_loss: 0.017892546951770782\nSEED: 10, FOLD: 3, EPOCH: 4,train_loss: 0.01786088379288929, valid_loss: 0.017896341904997826\nSEED: 10, FOLD: 3, EPOCH: 5,train_loss: 0.017897384045510622, valid_loss: 0.0177837999271495\nSEED: 10, FOLD: 3, EPOCH: 6,train_loss: 0.017775475364718317, valid_loss: 0.017990127950906754\nSEED: 10, FOLD: 3, EPOCH: 7,train_loss: 0.017884772176435894, valid_loss: 0.017769559738891466\nSEED: 10, FOLD: 3, EPOCH: 8,train_loss: 0.01787071924764609, valid_loss: 0.017808786247457777\nSEED: 10, FOLD: 3, EPOCH: 9,train_loss: 0.017810688779243956, valid_loss: 0.017882760348064557\nSEED: 10, FOLD: 3, EPOCH: 10,train_loss: 0.01779792908633101, valid_loss: 0.018108171171375684\nSEED: 10, FOLD: 3, EPOCH: 11,train_loss: 0.01774050499164108, valid_loss: 0.017713695125920432\nSEED: 10, FOLD: 3, EPOCH: 12,train_loss: 0.01764643091060545, valid_loss: 0.017744480978165354\nSEED: 10, FOLD: 3, EPOCH: 13,train_loss: 0.01753373510217753, valid_loss: 0.017551081042204583\nSEED: 10, FOLD: 3, EPOCH: 14,train_loss: 0.017557736013786518, valid_loss: 0.017493534327617712\nSEED: 10, FOLD: 3, EPOCH: 15,train_loss: 0.01729282184733429, valid_loss: 0.017479371625397887\nSEED: 10, FOLD: 3, EPOCH: 16,train_loss: 0.017150875221451988, valid_loss: 0.017267615374709878\nSEED: 10, FOLD: 3, EPOCH: 17,train_loss: 0.016890741115354973, valid_loss: 0.017258150103901113\nSEED: 10, FOLD: 3, EPOCH: 18,train_loss: 0.01658462632474476, valid_loss: 0.017055414670280048\nSEED: 10, FOLD: 3, EPOCH: 19,train_loss: 0.016245055052897205, valid_loss: 0.01712925418147019\nSEED: 10, FOLD: 3, EPOCH: 20,train_loss: 0.015830716118216515, valid_loss: 0.01713724649910416\nSEED: 10, FOLD: 3, EPOCH: 21,train_loss: 0.015381847008846808, valid_loss: 0.017029205949178765\nSEED: 10, FOLD: 3, EPOCH: 22,train_loss: 0.014867778165616852, valid_loss: 0.01701419223099947\nSEED: 10, FOLD: 3, EPOCH: 23,train_loss: 0.01442250909715675, valid_loss: 0.017054767613964423\nSEED: 10, FOLD: 3, EPOCH: 24,train_loss: 0.01416266063714157, valid_loss: 0.01704355390476329\nFOLD: 4, EPOCH: 0,train_loss: 0.7348614248676576, valid_loss: 0.7037947910172598\nSEED: 10, FOLD: 4, EPOCH: 0,train_loss: 0.4658262456861743, valid_loss: 0.02355283812752792\nSEED: 10, FOLD: 4, EPOCH: 1,train_loss: 0.020676282288479633, valid_loss: 0.01987413748034409\nSEED: 10, FOLD: 4, EPOCH: 2,train_loss: 0.019222463265169357, valid_loss: 0.018069226507629668\nSEED: 10, FOLD: 4, EPOCH: 3,train_loss: 0.018226189417359623, valid_loss: 0.01796661735113178\nSEED: 10, FOLD: 4, EPOCH: 4,train_loss: 0.017945024933989927, valid_loss: 0.01816432446773563\nSEED: 10, FOLD: 4, EPOCH: 5,train_loss: 0.017932810442711132, valid_loss: 0.01799957664417369\nSEED: 10, FOLD: 4, EPOCH: 6,train_loss: 0.017918802392871483, valid_loss: 0.018091959160353457\nSEED: 10, FOLD: 4, EPOCH: 7,train_loss: 0.01788923583006945, valid_loss: 0.01805783116391727\nSEED: 10, FOLD: 4, EPOCH: 8,train_loss: 0.01792604460016541, valid_loss: 0.017736888863146304\nSEED: 10, FOLD: 4, EPOCH: 9,train_loss: 0.017904578978060814, valid_loss: 0.018077171647122928\nSEED: 10, FOLD: 4, EPOCH: 10,train_loss: 0.01779438758376932, valid_loss: 0.017563958412834577\nSEED: 10, FOLD: 4, EPOCH: 11,train_loss: 0.017831594399783924, valid_loss: 0.01766311340034008\nSEED: 10, FOLD: 4, EPOCH: 12,train_loss: 0.017732315602293915, valid_loss: 0.017732124030590057\nSEED: 10, FOLD: 4, EPOCH: 13,train_loss: 0.01759529564583647, valid_loss: 0.01755774545350245\nSEED: 10, FOLD: 4, EPOCH: 14,train_loss: 0.017477688102888456, valid_loss: 0.017427706532180308\nSEED: 10, FOLD: 4, EPOCH: 15,train_loss: 0.017278639930367903, valid_loss: 0.01748156736471823\nSEED: 10, FOLD: 4, EPOCH: 16,train_loss: 0.017145903315395117, valid_loss: 0.01724638103374413\nSEED: 10, FOLD: 4, EPOCH: 17,train_loss: 0.0169104291598542, valid_loss: 0.017421608418226243\nSEED: 10, FOLD: 4, EPOCH: 18,train_loss: 0.01665567409625088, valid_loss: 0.017132662449564254\nSEED: 10, FOLD: 4, EPOCH: 19,train_loss: 0.0163323560230218, valid_loss: 0.017071184303079332\nSEED: 10, FOLD: 4, EPOCH: 20,train_loss: 0.015901901023597387, valid_loss: 0.017143713549843856\nSEED: 10, FOLD: 4, EPOCH: 21,train_loss: 0.015362698193369568, valid_loss: 0.01704590610627617\nSEED: 10, FOLD: 4, EPOCH: 22,train_loss: 0.014829397761681374, valid_loss: 0.017043329535850457\nSEED: 10, FOLD: 4, EPOCH: 23,train_loss: 0.014389664764799501, valid_loss: 0.017015094070562294\nSEED: 10, FOLD: 4, EPOCH: 24,train_loss: 0.01411933080036787, valid_loss: 0.016975822672247887\nFOLD: 0, EPOCH: 0,train_loss: 0.7343826341456261, valid_loss: 0.696765158857618\nSEED: 11, FOLD: 0, EPOCH: 0,train_loss: 0.4663351210023182, valid_loss: 0.02688883686704295\nSEED: 11, FOLD: 0, EPOCH: 1,train_loss: 0.02117390282776045, valid_loss: 0.019306264046047416\nSEED: 11, FOLD: 0, EPOCH: 2,train_loss: 0.01941457216668388, valid_loss: 0.01876115131058863\nSEED: 11, FOLD: 0, EPOCH: 3,train_loss: 0.018869069121454075, valid_loss: 0.018102574082357544\nSEED: 11, FOLD: 0, EPOCH: 4,train_loss: 0.018251072446667196, valid_loss: 0.018538726467107025\nSEED: 11, FOLD: 0, EPOCH: 5,train_loss: 0.01808059243215383, valid_loss: 0.01786624589668853\nSEED: 11, FOLD: 0, EPOCH: 6,train_loss: 0.01806515654333044, valid_loss: 0.017795801322375026\nSEED: 11, FOLD: 0, EPOCH: 7,train_loss: 0.018033158344527084, valid_loss: 0.0178844633645245\nSEED: 11, FOLD: 0, EPOCH: 8,train_loss: 0.017871333002720192, valid_loss: 0.018048576398619582\nSEED: 11, FOLD: 0, EPOCH: 9,train_loss: 0.017986648122145645, valid_loss: 0.017808079559888158\nSEED: 11, FOLD: 0, EPOCH: 10,train_loss: 0.017872464242458776, valid_loss: 0.017644529763076986\nSEED: 11, FOLD: 0, EPOCH: 11,train_loss: 0.01789041196225562, valid_loss: 0.017738094287259237\nSEED: 11, FOLD: 0, EPOCH: 12,train_loss: 0.017747012608131205, valid_loss: 0.01851871032267809\nSEED: 11, FOLD: 0, EPOCH: 13,train_loss: 0.017824904608499746, valid_loss: 0.0174949583198343\nSEED: 11, FOLD: 0, EPOCH: 14,train_loss: 0.017524622016302917, valid_loss: 0.017656217914606843\nSEED: 11, FOLD: 0, EPOCH: 15,train_loss: 0.017331919862308365, valid_loss: 0.017296875374657766\nSEED: 11, FOLD: 0, EPOCH: 16,train_loss: 0.017159448491166466, valid_loss: 0.017398136348596643\nSEED: 11, FOLD: 0, EPOCH: 17,train_loss: 0.017029437243236578, valid_loss: 0.017178167855100974\nSEED: 11, FOLD: 0, EPOCH: 18,train_loss: 0.01679941181741331, valid_loss: 0.017280605914337294\nSEED: 11, FOLD: 0, EPOCH: 19,train_loss: 0.016573951910317377, valid_loss: 0.017061353102326392\nSEED: 11, FOLD: 0, EPOCH: 20,train_loss: 0.016170812757226868, valid_loss: 0.017148222428347383\nSEED: 11, FOLD: 0, EPOCH: 21,train_loss: 0.015636017485319273, valid_loss: 0.0170261822906988\nSEED: 11, FOLD: 0, EPOCH: 22,train_loss: 0.015160115557196348, valid_loss: 0.017005121122513497\nSEED: 11, FOLD: 0, EPOCH: 23,train_loss: 0.014823797833768354, valid_loss: 0.017040472025317804\nSEED: 11, FOLD: 0, EPOCH: 24,train_loss: 0.014671456062005482, valid_loss: 0.017011745061193195\nFOLD: 1, EPOCH: 0,train_loss: 0.734488015157589, valid_loss: 0.6971926825387137\nSEED: 11, FOLD: 1, EPOCH: 0,train_loss: 0.4670138486080628, valid_loss: 0.02363860665687493\nSEED: 11, FOLD: 1, EPOCH: 1,train_loss: 0.02113976625158735, valid_loss: 0.023708472347685267\nSEED: 11, FOLD: 1, EPOCH: 2,train_loss: 0.019348547901904236, valid_loss: 0.01833290308713913\nSEED: 11, FOLD: 1, EPOCH: 3,train_loss: 0.018283318849685398, valid_loss: 0.018111075540738448\nSEED: 11, FOLD: 1, EPOCH: 4,train_loss: 0.018134597520195486, valid_loss: 0.018056721346718926\nSEED: 11, FOLD: 1, EPOCH: 5,train_loss: 0.018009098084724468, valid_loss: 0.018667978447462832\nSEED: 11, FOLD: 1, EPOCH: 6,train_loss: 0.018023293728575758, valid_loss: 0.01822055854967662\nSEED: 11, FOLD: 1, EPOCH: 7,train_loss: 0.01793909433932192, valid_loss: 0.0178425134824855\nSEED: 11, FOLD: 1, EPOCH: 8,train_loss: 0.01800039217577896, valid_loss: 0.01786426579845803\nSEED: 11, FOLD: 1, EPOCH: 9,train_loss: 0.017933632483354944, valid_loss: 0.018077354026692253\nSEED: 11, FOLD: 1, EPOCH: 10,train_loss: 0.01796835273558247, valid_loss: 0.017825755796262197\nSEED: 11, FOLD: 1, EPOCH: 11,train_loss: 0.017960162435158872, valid_loss: 0.017632816971412727\nSEED: 11, FOLD: 1, EPOCH: 12,train_loss: 0.017764334242952907, valid_loss: 0.01774531416594982\nSEED: 11, FOLD: 1, EPOCH: 13,train_loss: 0.01769108008728295, valid_loss: 0.01790498699992895\nSEED: 11, FOLD: 1, EPOCH: 14,train_loss: 0.017553708171876875, valid_loss: 0.017722933260457856\nSEED: 11, FOLD: 1, EPOCH: 15,train_loss: 0.017387212841245142, valid_loss: 0.017404899267213687\nSEED: 11, FOLD: 1, EPOCH: 16,train_loss: 0.01729737382814072, valid_loss: 0.017222987434693745\nSEED: 11, FOLD: 1, EPOCH: 17,train_loss: 0.01711258751110754, valid_loss: 0.017292186857334205\nSEED: 11, FOLD: 1, EPOCH: 18,train_loss: 0.016820705320308174, valid_loss: 0.017260052183909077\nSEED: 11, FOLD: 1, EPOCH: 19,train_loss: 0.016533105377701744, valid_loss: 0.017148165271750518\nSEED: 11, FOLD: 1, EPOCH: 20,train_loss: 0.016154575634045876, valid_loss: 0.01717790833541325\nSEED: 11, FOLD: 1, EPOCH: 21,train_loss: 0.0156955331482965, valid_loss: 0.017099330414618766\nSEED: 11, FOLD: 1, EPOCH: 22,train_loss: 0.015243672279883986, valid_loss: 0.01700835060328245\nSEED: 11, FOLD: 1, EPOCH: 23,train_loss: 0.014886546022920073, valid_loss: 0.017011445547853197\nSEED: 11, FOLD: 1, EPOCH: 24,train_loss: 0.014719218926747208, valid_loss: 0.017019212512033328\nFOLD: 2, EPOCH: 0,train_loss: 0.7342386772667152, valid_loss: 0.6947000324726105\nSEED: 11, FOLD: 2, EPOCH: 0,train_loss: 0.4658516508567592, valid_loss: 0.023500792517819825\nSEED: 11, FOLD: 2, EPOCH: 1,train_loss: 0.020649316666674786, valid_loss: 0.018960582201971728\nSEED: 11, FOLD: 2, EPOCH: 2,train_loss: 0.018666733353250267, valid_loss: 0.018207635237451864\nSEED: 11, FOLD: 2, EPOCH: 3,train_loss: 0.01819994326248981, valid_loss: 0.018304669462582645\nSEED: 11, FOLD: 2, EPOCH: 4,train_loss: 0.01790530003094371, valid_loss: 0.01861407755709746\nSEED: 11, FOLD: 2, EPOCH: 5,train_loss: 0.017867247121867495, valid_loss: 0.018067670246476635\nSEED: 11, FOLD: 2, EPOCH: 6,train_loss: 0.01787522396720622, valid_loss: 0.01806853018591509\nSEED: 11, FOLD: 2, EPOCH: 7,train_loss: 0.01789796091211231, valid_loss: 0.01810516940210672\nSEED: 11, FOLD: 2, EPOCH: 8,train_loss: 0.01787715866162941, valid_loss: 0.018009871737483668\nSEED: 11, FOLD: 2, EPOCH: 9,train_loss: 0.01782434494437083, valid_loss: 0.018059764988720417\nSEED: 11, FOLD: 2, EPOCH: 10,train_loss: 0.017797349850930597, valid_loss: 0.01816135425777996\nSEED: 11, FOLD: 2, EPOCH: 11,train_loss: 0.01768211639769699, valid_loss: 0.01811073750586194\nSEED: 11, FOLD: 2, EPOCH: 12,train_loss: 0.017692849606923435, valid_loss: 0.017869916333652595\nSEED: 11, FOLD: 2, EPOCH: 13,train_loss: 0.01756601647703328, valid_loss: 0.017929679001955426\nSEED: 11, FOLD: 2, EPOCH: 14,train_loss: 0.01747270614799598, valid_loss: 0.01795958787860239\nSEED: 11, FOLD: 2, EPOCH: 15,train_loss: 0.017320838601638872, valid_loss: 0.01792399653726641\nSEED: 11, FOLD: 2, EPOCH: 16,train_loss: 0.017152391002931887, valid_loss: 0.017592936425524598\nSEED: 11, FOLD: 2, EPOCH: 17,train_loss: 0.016874496541593387, valid_loss: 0.01752401000874884\nSEED: 11, FOLD: 2, EPOCH: 18,train_loss: 0.01660517578188708, valid_loss: 0.017534798531628707\nSEED: 11, FOLD: 2, EPOCH: 19,train_loss: 0.016307930678021217, valid_loss: 0.01740692659993382\nSEED: 11, FOLD: 2, EPOCH: 20,train_loss: 0.015915348430744547, valid_loss: 0.017457915004342794\nSEED: 11, FOLD: 2, EPOCH: 21,train_loss: 0.015465547364421081, valid_loss: 0.017456986475735903\nSEED: 11, FOLD: 2, EPOCH: 22,train_loss: 0.014986640294554873, valid_loss: 0.017458824139526662\nSEED: 11, FOLD: 2, EPOCH: 23,train_loss: 0.014556441894745913, valid_loss: 0.017429337152005994\nSEED: 11, FOLD: 2, EPOCH: 24,train_loss: 0.014322821017138767, valid_loss: 0.01743857206448036\nFOLD: 3, EPOCH: 0,train_loss: 0.7345200034155361, valid_loss: 0.6971946954727173\nSEED: 11, FOLD: 3, EPOCH: 0,train_loss: 0.4668773202819453, valid_loss: 0.02345986206616674\nSEED: 11, FOLD: 3, EPOCH: 1,train_loss: 0.020877123202966606, valid_loss: 0.01870627584201949\nSEED: 11, FOLD: 3, EPOCH: 2,train_loss: 0.019097707855204742, valid_loss: 0.018097071216574737\nSEED: 11, FOLD: 3, EPOCH: 3,train_loss: 0.018249365912777357, valid_loss: 0.018252017934407505\nSEED: 11, FOLD: 3, EPOCH: 4,train_loss: 0.017910238119193178, valid_loss: 0.017938896135560104\nSEED: 11, FOLD: 3, EPOCH: 5,train_loss: 0.017876719819732767, valid_loss: 0.018359289238495485\nSEED: 11, FOLD: 3, EPOCH: 6,train_loss: 0.017954990038297314, valid_loss: 0.018290357956928866\nSEED: 11, FOLD: 3, EPOCH: 7,train_loss: 0.017889165447727926, valid_loss: 0.01793416113193546\nSEED: 11, FOLD: 3, EPOCH: 8,train_loss: 0.01789440371878985, valid_loss: 0.01801516293947186\nSEED: 11, FOLD: 3, EPOCH: 9,train_loss: 0.017877703694545704, valid_loss: 0.017950175196996758\nSEED: 11, FOLD: 3, EPOCH: 10,train_loss: 0.01779922575055473, valid_loss: 0.01781230199017695\nSEED: 11, FOLD: 3, EPOCH: 11,train_loss: 0.017786096828733233, valid_loss: 0.01780363970569202\nSEED: 11, FOLD: 3, EPOCH: 12,train_loss: 0.017682680596961924, valid_loss: 0.017848639882036617\nSEED: 11, FOLD: 3, EPOCH: 13,train_loss: 0.017592854541388973, valid_loss: 0.017617592162319593\nSEED: 11, FOLD: 3, EPOCH: 14,train_loss: 0.017505564841617277, valid_loss: 0.017691747152379582\nSEED: 11, FOLD: 3, EPOCH: 15,train_loss: 0.01732486374406279, valid_loss: 0.017747264009501253\nSEED: 11, FOLD: 3, EPOCH: 16,train_loss: 0.017152404513857935, valid_loss: 0.017340682313910553\nSEED: 11, FOLD: 3, EPOCH: 17,train_loss: 0.016931069002527256, valid_loss: 0.017525860001998288\nSEED: 11, FOLD: 3, EPOCH: 18,train_loss: 0.016705991815019777, valid_loss: 0.017419599874743393\nSEED: 11, FOLD: 3, EPOCH: 19,train_loss: 0.016335243197238964, valid_loss: 0.017292348561542374\nSEED: 11, FOLD: 3, EPOCH: 20,train_loss: 0.015903429533152477, valid_loss: 0.017214653694203923\nSEED: 11, FOLD: 3, EPOCH: 21,train_loss: 0.01548846093667806, valid_loss: 0.01726474477244275\nSEED: 11, FOLD: 3, EPOCH: 22,train_loss: 0.014972205233314762, valid_loss: 0.01720256470143795\nSEED: 11, FOLD: 3, EPOCH: 23,train_loss: 0.014507706425544144, valid_loss: 0.017229046167007513\nSEED: 11, FOLD: 3, EPOCH: 24,train_loss: 0.014332350248983805, valid_loss: 0.017228236182459764\nFOLD: 4, EPOCH: 0,train_loss: 0.7345989081111267, valid_loss: 0.6968394637107849\nSEED: 11, FOLD: 4, EPOCH: 0,train_loss: 0.4688407455564198, valid_loss: 0.03275649371956076\nSEED: 11, FOLD: 4, EPOCH: 1,train_loss: 0.020949188103205965, valid_loss: 0.01869474995349135\nSEED: 11, FOLD: 4, EPOCH: 2,train_loss: 0.018987022326701748, valid_loss: 0.018068463781050273\nSEED: 11, FOLD: 4, EPOCH: 3,train_loss: 0.018466225519341274, valid_loss: 0.01785925951387201\nSEED: 11, FOLD: 4, EPOCH: 4,train_loss: 0.018098485581304904, valid_loss: 0.018058958489980015\nSEED: 11, FOLD: 4, EPOCH: 5,train_loss: 0.01793527862832059, valid_loss: 0.01785528039825814\nSEED: 11, FOLD: 4, EPOCH: 6,train_loss: 0.018006316671678183, valid_loss: 0.017789805813559465\nSEED: 11, FOLD: 4, EPOCH: 7,train_loss: 0.01799062328127614, valid_loss: 0.01824713008744376\nSEED: 11, FOLD: 4, EPOCH: 8,train_loss: 0.017972862347960472, valid_loss: 0.01790774225124291\nSEED: 11, FOLD: 4, EPOCH: 9,train_loss: 0.017921125876588107, valid_loss: 0.0178110271692276\nSEED: 11, FOLD: 4, EPOCH: 10,train_loss: 0.017901225810884124, valid_loss: 0.017916372790932656\nSEED: 11, FOLD: 4, EPOCH: 11,train_loss: 0.017855708772846816, valid_loss: 0.017632474271314483\nSEED: 11, FOLD: 4, EPOCH: 12,train_loss: 0.017776369185180125, valid_loss: 0.017697851892028535\nSEED: 11, FOLD: 4, EPOCH: 13,train_loss: 0.017685050940154677, valid_loss: 0.0174197793006897\nSEED: 11, FOLD: 4, EPOCH: 14,train_loss: 0.017593822374015394, valid_loss: 0.017420071017529282\nSEED: 11, FOLD: 4, EPOCH: 15,train_loss: 0.017422058340841835, valid_loss: 0.017533746947135245\nSEED: 11, FOLD: 4, EPOCH: 16,train_loss: 0.017242714205253733, valid_loss: 0.017357487337929862\nSEED: 11, FOLD: 4, EPOCH: 17,train_loss: 0.017018939361628824, valid_loss: 0.017468543457133428\nSEED: 11, FOLD: 4, EPOCH: 18,train_loss: 0.016761504895441287, valid_loss: 0.017227910166340215\nSEED: 11, FOLD: 4, EPOCH: 19,train_loss: 0.016408995201770405, valid_loss: 0.01718227437564305\nSEED: 11, FOLD: 4, EPOCH: 20,train_loss: 0.016060850535431048, valid_loss: 0.01719695691551481\nSEED: 11, FOLD: 4, EPOCH: 21,train_loss: 0.015597115692267887, valid_loss: 0.017105532171470778\nSEED: 11, FOLD: 4, EPOCH: 22,train_loss: 0.015131555586020006, valid_loss: 0.01707478202879429\nSEED: 11, FOLD: 4, EPOCH: 23,train_loss: 0.014729342015500921, valid_loss: 0.01708466737930264\nSEED: 11, FOLD: 4, EPOCH: 24,train_loss: 0.014524080409892719, valid_loss: 0.01708244423248938\nFOLD: 0, EPOCH: 0,train_loss: 0.7350949122421984, valid_loss: 0.6982517753328595\nSEED: 12, FOLD: 0, EPOCH: 0,train_loss: 0.46659788597321167, valid_loss: 0.023453744873404504\nSEED: 12, FOLD: 0, EPOCH: 1,train_loss: 0.02090552315601836, valid_loss: 0.02089314961007663\nSEED: 12, FOLD: 0, EPOCH: 2,train_loss: 0.019153605512194874, valid_loss: 0.018395298612969263\nSEED: 12, FOLD: 0, EPOCH: 3,train_loss: 0.018299683854253828, valid_loss: 0.018357295276863233\nSEED: 12, FOLD: 0, EPOCH: 4,train_loss: 0.01789647730175352, valid_loss: 0.01823918473507677\nSEED: 12, FOLD: 0, EPOCH: 5,train_loss: 0.01783389228976507, valid_loss: 0.018346689455211163\nSEED: 12, FOLD: 0, EPOCH: 6,train_loss: 0.017762488280625446, valid_loss: 0.018105250809873852\nSEED: 12, FOLD: 0, EPOCH: 7,train_loss: 0.01778507059224058, valid_loss: 0.01802069299987384\nSEED: 12, FOLD: 0, EPOCH: 8,train_loss: 0.0177420304035363, valid_loss: 0.01803163675857442\nSEED: 12, FOLD: 0, EPOCH: 9,train_loss: 0.017756306593292866, valid_loss: 0.018438314699700902\nSEED: 12, FOLD: 0, EPOCH: 10,train_loss: 0.017775448599317366, valid_loss: 0.017962113421942507\nSEED: 12, FOLD: 0, EPOCH: 11,train_loss: 0.01769345873237952, valid_loss: 0.01792735994926521\nSEED: 12, FOLD: 0, EPOCH: 12,train_loss: 0.01759903830057685, valid_loss: 0.018323484515505178\nSEED: 12, FOLD: 0, EPOCH: 13,train_loss: 0.017458644884544006, valid_loss: 0.01817280165851116\nSEED: 12, FOLD: 0, EPOCH: 14,train_loss: 0.01738766881812742, valid_loss: 0.01800469479390553\nSEED: 12, FOLD: 0, EPOCH: 15,train_loss: 0.01722299087576676, valid_loss: 0.017908544013542787\nSEED: 12, FOLD: 0, EPOCH: 16,train_loss: 0.0170880358774161, valid_loss: 0.017779670496072087\nSEED: 12, FOLD: 0, EPOCH: 17,train_loss: 0.01684621757949176, valid_loss: 0.01762865427881479\nSEED: 12, FOLD: 0, EPOCH: 18,train_loss: 0.01653842357378723, valid_loss: 0.017650574818253516\nSEED: 12, FOLD: 0, EPOCH: 19,train_loss: 0.016235289494574503, valid_loss: 0.01751796691013234\nSEED: 12, FOLD: 0, EPOCH: 20,train_loss: 0.015792124783215317, valid_loss: 0.01756090186536312\nSEED: 12, FOLD: 0, EPOCH: 21,train_loss: 0.015309194177119196, valid_loss: 0.017498689251286642\nSEED: 12, FOLD: 0, EPOCH: 22,train_loss: 0.014784235446511404, valid_loss: 0.017457991332880087\nSEED: 12, FOLD: 0, EPOCH: 23,train_loss: 0.014335251001614159, valid_loss: 0.017490520541157042\nSEED: 12, FOLD: 0, EPOCH: 24,train_loss: 0.014085565828650759, valid_loss: 0.017471981447722232\nFOLD: 1, EPOCH: 0,train_loss: 0.7353662701620571, valid_loss: 0.7024664475637323\nSEED: 12, FOLD: 1, EPOCH: 0,train_loss: 0.46721115854123363, valid_loss: 0.023665426189408582\nSEED: 12, FOLD: 1, EPOCH: 1,train_loss: 0.02085090767376233, valid_loss: 0.01874936218647396\nSEED: 12, FOLD: 1, EPOCH: 2,train_loss: 0.019364830092999382, valid_loss: 0.01817426205996205\nSEED: 12, FOLD: 1, EPOCH: 3,train_loss: 0.018275042469410793, valid_loss: 0.018108880804742083\nSEED: 12, FOLD: 1, EPOCH: 4,train_loss: 0.017902893716118473, valid_loss: 0.01824578336056541\nSEED: 12, FOLD: 1, EPOCH: 5,train_loss: 0.017801082922496658, valid_loss: 0.018550363204935017\nSEED: 12, FOLD: 1, EPOCH: 6,train_loss: 0.0178795309966781, valid_loss: 0.018198762855985585\nSEED: 12, FOLD: 1, EPOCH: 7,train_loss: 0.01784777535341572, valid_loss: 0.018094066366115037\nSEED: 12, FOLD: 1, EPOCH: 8,train_loss: 0.017840106445162193, valid_loss: 0.017800280112115777\nSEED: 12, FOLD: 1, EPOCH: 9,train_loss: 0.01785558452019873, valid_loss: 0.017815240275333908\nSEED: 12, FOLD: 1, EPOCH: 10,train_loss: 0.017786192964168564, valid_loss: 0.017830487943309194\nSEED: 12, FOLD: 1, EPOCH: 11,train_loss: 0.017801694275028465, valid_loss: 0.017673279377905762\nSEED: 12, FOLD: 1, EPOCH: 12,train_loss: 0.017699307330168675, valid_loss: 0.01772555456880261\nSEED: 12, FOLD: 1, EPOCH: 13,train_loss: 0.01755745279049312, valid_loss: 0.017815846347195262\nSEED: 12, FOLD: 1, EPOCH: 14,train_loss: 0.017513462706752445, valid_loss: 0.01774868495104944\nSEED: 12, FOLD: 1, EPOCH: 15,train_loss: 0.01731213349579037, valid_loss: 0.017530446762547773\nSEED: 12, FOLD: 1, EPOCH: 16,train_loss: 0.017139933571435402, valid_loss: 0.017449552193284035\nSEED: 12, FOLD: 1, EPOCH: 17,train_loss: 0.016991179247481236, valid_loss: 0.017362506512333366\nSEED: 12, FOLD: 1, EPOCH: 18,train_loss: 0.016593445726818798, valid_loss: 0.01730837656513733\nSEED: 12, FOLD: 1, EPOCH: 19,train_loss: 0.016319921543902677, valid_loss: 0.017208490493323875\nSEED: 12, FOLD: 1, EPOCH: 20,train_loss: 0.015914124861845503, valid_loss: 0.01728067103335086\nSEED: 12, FOLD: 1, EPOCH: 21,train_loss: 0.01541629521365183, valid_loss: 0.017060805550392938\nSEED: 12, FOLD: 1, EPOCH: 22,train_loss: 0.014870763439145208, valid_loss: 0.01704544316538993\nSEED: 12, FOLD: 1, EPOCH: 23,train_loss: 0.014427495202508526, valid_loss: 0.017093104858170536\nSEED: 12, FOLD: 1, EPOCH: 24,train_loss: 0.014207365915881119, valid_loss: 0.01708258581621682\nFOLD: 2, EPOCH: 0,train_loss: 0.7349501704647593, valid_loss: 0.6980430313519069\nSEED: 12, FOLD: 2, EPOCH: 0,train_loss: 0.46883704896717177, valid_loss: 0.024545357695647647\nSEED: 12, FOLD: 2, EPOCH: 1,train_loss: 0.021094830543564185, valid_loss: 0.018996839438165936\nSEED: 12, FOLD: 2, EPOCH: 2,train_loss: 0.019206523419405423, valid_loss: 0.018324154083217893\nSEED: 12, FOLD: 2, EPOCH: 3,train_loss: 0.018166957817373486, valid_loss: 0.017920797797186035\nSEED: 12, FOLD: 2, EPOCH: 4,train_loss: 0.017881814471996615, valid_loss: 0.018200825953057834\nSEED: 12, FOLD: 2, EPOCH: 5,train_loss: 0.01789441106528261, valid_loss: 0.017878813669085503\nSEED: 12, FOLD: 2, EPOCH: 6,train_loss: 0.017876486056042414, valid_loss: 0.01804609772350107\nSEED: 12, FOLD: 2, EPOCH: 7,train_loss: 0.01786521089392422, valid_loss: 0.017673840240708418\nSEED: 12, FOLD: 2, EPOCH: 8,train_loss: 0.017844784807712927, valid_loss: 0.018689248551215443\nSEED: 12, FOLD: 2, EPOCH: 9,train_loss: 0.01790295763580251, valid_loss: 0.018310583010315896\nSEED: 12, FOLD: 2, EPOCH: 10,train_loss: 0.017849358315341665, valid_loss: 0.017562967831535\nSEED: 12, FOLD: 2, EPOCH: 11,train_loss: 0.017821248885869546, valid_loss: 0.017814901577574867\nSEED: 12, FOLD: 2, EPOCH: 12,train_loss: 0.017777523977586824, valid_loss: 0.017557197410081115\nSEED: 12, FOLD: 2, EPOCH: 13,train_loss: 0.0176304438470924, valid_loss: 0.017894531121211393\nSEED: 12, FOLD: 2, EPOCH: 14,train_loss: 0.017544205796762104, valid_loss: 0.01740329089973654\nSEED: 12, FOLD: 2, EPOCH: 15,train_loss: 0.017410935562131177, valid_loss: 0.017487374294017043\nSEED: 12, FOLD: 2, EPOCH: 16,train_loss: 0.01723275776191132, valid_loss: 0.01746509216193642\nSEED: 12, FOLD: 2, EPOCH: 17,train_loss: 0.017027957344522875, valid_loss: 0.017456534770982607\nSEED: 12, FOLD: 2, EPOCH: 18,train_loss: 0.01674281994737413, valid_loss: 0.01707748794662101\nSEED: 12, FOLD: 2, EPOCH: 19,train_loss: 0.016414027504731706, valid_loss: 0.017115543490009648\nSEED: 12, FOLD: 2, EPOCH: 20,train_loss: 0.015973336457607956, valid_loss: 0.01715149272765432\nSEED: 12, FOLD: 2, EPOCH: 21,train_loss: 0.015480837254465496, valid_loss: 0.017070754431188107\nSEED: 12, FOLD: 2, EPOCH: 22,train_loss: 0.01495868706545473, valid_loss: 0.017071345209011008\nSEED: 12, FOLD: 2, EPOCH: 23,train_loss: 0.014523831753563272, valid_loss: 0.017024157089846476\nSEED: 12, FOLD: 2, EPOCH: 24,train_loss: 0.01428894605487585, valid_loss: 0.017040740405874593\nFOLD: 3, EPOCH: 0,train_loss: 0.7353047555771427, valid_loss: 0.6983260459759656\nSEED: 12, FOLD: 3, EPOCH: 0,train_loss: 0.46735511821411224, valid_loss: 0.023056866765460548\nSEED: 12, FOLD: 3, EPOCH: 1,train_loss: 0.02118464229979377, valid_loss: 0.018828588757006562\nSEED: 12, FOLD: 3, EPOCH: 2,train_loss: 0.01919522730336673, valid_loss: 0.018059787367854047\nSEED: 12, FOLD: 3, EPOCH: 3,train_loss: 0.018434144205589226, valid_loss: 0.017643997883972\nSEED: 12, FOLD: 3, EPOCH: 4,train_loss: 0.018038164783755074, valid_loss: 0.01759380485643359\nSEED: 12, FOLD: 3, EPOCH: 5,train_loss: 0.017903980839511623, valid_loss: 0.017860378823517\nSEED: 12, FOLD: 3, EPOCH: 6,train_loss: 0.017908483453472887, valid_loss: 0.017966197611873642\nSEED: 12, FOLD: 3, EPOCH: 7,train_loss: 0.017866151279135458, valid_loss: 0.017557670471861082\nSEED: 12, FOLD: 3, EPOCH: 8,train_loss: 0.017864308502201155, valid_loss: 0.0176309693385573\nSEED: 12, FOLD: 3, EPOCH: 9,train_loss: 0.017793947493360527, valid_loss: 0.017509967636536148\nSEED: 12, FOLD: 3, EPOCH: 10,train_loss: 0.017815303226150034, valid_loss: 0.017653094412868515\nSEED: 12, FOLD: 3, EPOCH: 11,train_loss: 0.01775816938691381, valid_loss: 0.017477250055355185\nSEED: 12, FOLD: 3, EPOCH: 12,train_loss: 0.017707088132105444, valid_loss: 0.01749749489895561\nSEED: 12, FOLD: 3, EPOCH: 13,train_loss: 0.01757702475035752, valid_loss: 0.017397828674053446\nSEED: 12, FOLD: 3, EPOCH: 14,train_loss: 0.017491697448481253, valid_loss: 0.01726606597795206\nSEED: 12, FOLD: 3, EPOCH: 15,train_loss: 0.01726901515022568, valid_loss: 0.01731258203439853\nSEED: 12, FOLD: 3, EPOCH: 16,train_loss: 0.01710214141918265, valid_loss: 0.017182889668380514\nSEED: 12, FOLD: 3, EPOCH: 17,train_loss: 0.01687461586561108, valid_loss: 0.01723077233113787\nSEED: 12, FOLD: 3, EPOCH: 18,train_loss: 0.016579798976148384, valid_loss: 0.017139225951669848\nSEED: 12, FOLD: 3, EPOCH: 19,train_loss: 0.016209902565764343, valid_loss: 0.017068510162918007\nSEED: 12, FOLD: 3, EPOCH: 20,train_loss: 0.01582690699538891, valid_loss: 0.016948577043983865\nSEED: 12, FOLD: 3, EPOCH: 21,train_loss: 0.015251671922379646, valid_loss: 0.016970308031886816\nSEED: 12, FOLD: 3, EPOCH: 22,train_loss: 0.014705750038442404, valid_loss: 0.01700344752958592\nSEED: 12, FOLD: 3, EPOCH: 23,train_loss: 0.01424196698581395, valid_loss: 0.01701215041034362\nSEED: 12, FOLD: 3, EPOCH: 24,train_loss: 0.01399211561901198, valid_loss: 0.016993507167653125\nFOLD: 4, EPOCH: 0,train_loss: 0.7354685355276958, valid_loss: 0.7003607698849269\nSEED: 12, FOLD: 4, EPOCH: 0,train_loss: 0.46864468499637435, valid_loss: 0.025190310925245284\nSEED: 12, FOLD: 4, EPOCH: 1,train_loss: 0.020707906352995086, valid_loss: 0.019228983457599366\nSEED: 12, FOLD: 4, EPOCH: 2,train_loss: 0.01888880791672825, valid_loss: 0.01814902922404664\nSEED: 12, FOLD: 4, EPOCH: 3,train_loss: 0.018030648656787662, valid_loss: 0.018102370841162545\nSEED: 12, FOLD: 4, EPOCH: 4,train_loss: 0.017803957604252508, valid_loss: 0.01804836852742093\nSEED: 12, FOLD: 4, EPOCH: 5,train_loss: 0.017740972442076588, valid_loss: 0.01847205332347325\nSEED: 12, FOLD: 4, EPOCH: 6,train_loss: 0.01778255951638422, valid_loss: 0.01805773060768843\nSEED: 12, FOLD: 4, EPOCH: 7,train_loss: 0.017826906684106286, valid_loss: 0.017962479112403732\nSEED: 12, FOLD: 4, EPOCH: 8,train_loss: 0.017777594540567293, valid_loss: 0.018058404619140284\nSEED: 12, FOLD: 4, EPOCH: 9,train_loss: 0.017754686472896675, valid_loss: 0.017866276390850543\nSEED: 12, FOLD: 4, EPOCH: 10,train_loss: 0.017721021174024926, valid_loss: 0.01805577584143196\nSEED: 12, FOLD: 4, EPOCH: 11,train_loss: 0.017675743649040697, valid_loss: 0.01790578008762428\nSEED: 12, FOLD: 4, EPOCH: 12,train_loss: 0.01765159911129379, valid_loss: 0.018083705327340535\nSEED: 12, FOLD: 4, EPOCH: 13,train_loss: 0.0174659200515734, valid_loss: 0.017843289220971722\nSEED: 12, FOLD: 4, EPOCH: 14,train_loss: 0.017371358220757794, valid_loss: 0.017826011244739804\nSEED: 12, FOLD: 4, EPOCH: 15,train_loss: 0.017255391388533325, valid_loss: 0.01764132287353277\nSEED: 12, FOLD: 4, EPOCH: 16,train_loss: 0.017021752757965213, valid_loss: 0.017793790117970536\nSEED: 12, FOLD: 4, EPOCH: 17,train_loss: 0.016830185489443532, valid_loss: 0.017606565994875773\nSEED: 12, FOLD: 4, EPOCH: 18,train_loss: 0.01653364699089179, valid_loss: 0.01764114499092102\nSEED: 12, FOLD: 4, EPOCH: 19,train_loss: 0.016218087540762705, valid_loss: 0.017534277455082962\nSEED: 12, FOLD: 4, EPOCH: 20,train_loss: 0.01576027380180185, valid_loss: 0.017375805388603893\nSEED: 12, FOLD: 4, EPOCH: 21,train_loss: 0.01527785411933913, valid_loss: 0.01748165243438312\nSEED: 12, FOLD: 4, EPOCH: 22,train_loss: 0.014723746595482756, valid_loss: 0.017388529383710452\nSEED: 12, FOLD: 4, EPOCH: 23,train_loss: 0.0143000261762934, valid_loss: 0.017428571039012502\nSEED: 12, FOLD: 4, EPOCH: 24,train_loss: 0.014058625916984395, valid_loss: 0.017404343241027423\nFOLD: 0, EPOCH: 0,train_loss: 0.7360939081164374, valid_loss: 0.6975617732320513\nSEED: 13, FOLD: 0, EPOCH: 0,train_loss: 0.468351355281429, valid_loss: 0.0257449922817094\nSEED: 13, FOLD: 0, EPOCH: 1,train_loss: 0.021009552899910057, valid_loss: 0.020240149913089617\nSEED: 13, FOLD: 0, EPOCH: 2,train_loss: 0.019596481223361217, valid_loss: 0.018284626597804682\nSEED: 13, FOLD: 0, EPOCH: 3,train_loss: 0.018687249512236187, valid_loss: 0.019503017674599374\nSEED: 13, FOLD: 0, EPOCH: 4,train_loss: 0.0183166754162074, valid_loss: 0.018260962409632545\nSEED: 13, FOLD: 0, EPOCH: 5,train_loss: 0.018166920035213665, valid_loss: 0.01800778303295374\nSEED: 13, FOLD: 0, EPOCH: 6,train_loss: 0.018042458282054766, valid_loss: 0.017818307929805346\nSEED: 13, FOLD: 0, EPOCH: 7,train_loss: 0.018020814473646275, valid_loss: 0.01788417880556413\nSEED: 13, FOLD: 0, EPOCH: 8,train_loss: 0.01803745059431463, valid_loss: 0.018122941628098486\nSEED: 13, FOLD: 0, EPOCH: 9,train_loss: 0.017983852156802364, valid_loss: 0.017957622637706144\nSEED: 13, FOLD: 0, EPOCH: 10,train_loss: 0.018007097090931908, valid_loss: 0.01773235702088901\nSEED: 13, FOLD: 0, EPOCH: 11,train_loss: 0.017866210087431944, valid_loss: 0.018357480530227933\nSEED: 13, FOLD: 0, EPOCH: 12,train_loss: 0.01785907830260154, valid_loss: 0.017661660217813083\nSEED: 13, FOLD: 0, EPOCH: 13,train_loss: 0.017784151032675003, valid_loss: 0.017521876309599196\nSEED: 13, FOLD: 0, EPOCH: 14,train_loss: 0.01752255958221529, valid_loss: 0.017398010806313584\nSEED: 13, FOLD: 0, EPOCH: 15,train_loss: 0.017387042429460133, valid_loss: 0.01725965166198356\nSEED: 13, FOLD: 0, EPOCH: 16,train_loss: 0.01745204435850399, valid_loss: 0.017187288988913807\nSEED: 13, FOLD: 0, EPOCH: 17,train_loss: 0.01710869554106308, valid_loss: 0.017390325931566104\nSEED: 13, FOLD: 0, EPOCH: 18,train_loss: 0.016830674413105717, valid_loss: 0.01724499823259456\nSEED: 13, FOLD: 0, EPOCH: 19,train_loss: 0.01651933700170206, valid_loss: 0.0172110025371824\nSEED: 13, FOLD: 0, EPOCH: 20,train_loss: 0.016134869948407446, valid_loss: 0.017031392268836498\nSEED: 13, FOLD: 0, EPOCH: 21,train_loss: 0.015742314007619152, valid_loss: 0.017091437056660653\nSEED: 13, FOLD: 0, EPOCH: 22,train_loss: 0.015301242038823557, valid_loss: 0.017139721049794127\nSEED: 13, FOLD: 0, EPOCH: 23,train_loss: 0.014957799421002468, valid_loss: 0.017024281328277928\nSEED: 13, FOLD: 0, EPOCH: 24,train_loss: 0.014691867899365616, valid_loss: 0.017067464467670237\nFOLD: 1, EPOCH: 0,train_loss: 0.7358407157918682, valid_loss: 0.6955845215741325\nSEED: 13, FOLD: 1, EPOCH: 0,train_loss: 0.46652578540902206, valid_loss: 0.02356662004090407\nSEED: 13, FOLD: 1, EPOCH: 1,train_loss: 0.020931628262759117, valid_loss: 0.019119628102463836\nSEED: 13, FOLD: 1, EPOCH: 2,train_loss: 0.018733878545733034, valid_loss: 0.018262835055151406\nSEED: 13, FOLD: 1, EPOCH: 3,train_loss: 0.01802037148129033, valid_loss: 0.017954266684896806\nSEED: 13, FOLD: 1, EPOCH: 4,train_loss: 0.017827093506744808, valid_loss: 0.018096315071863288\nSEED: 13, FOLD: 1, EPOCH: 5,train_loss: 0.017787355072526396, valid_loss: 0.018324088469585952\nSEED: 13, FOLD: 1, EPOCH: 6,train_loss: 0.017764877487459908, valid_loss: 0.018225533504258182\nSEED: 13, FOLD: 1, EPOCH: 7,train_loss: 0.01785286919524272, valid_loss: 0.01797273596200873\nSEED: 13, FOLD: 1, EPOCH: 8,train_loss: 0.017742605387246695, valid_loss: 0.01787640658371589\nSEED: 13, FOLD: 1, EPOCH: 9,train_loss: 0.01776553740373988, valid_loss: 0.017978937255547327\nSEED: 13, FOLD: 1, EPOCH: 10,train_loss: 0.01778613577556351, valid_loss: 0.01771368642392404\nSEED: 13, FOLD: 1, EPOCH: 11,train_loss: 0.017736940003553595, valid_loss: 0.017928962102707696\nSEED: 13, FOLD: 1, EPOCH: 12,train_loss: 0.017607033677885065, valid_loss: 0.017857641858213088\nSEED: 13, FOLD: 1, EPOCH: 13,train_loss: 0.017510465008841045, valid_loss: 0.01765631971990361\nSEED: 13, FOLD: 1, EPOCH: 14,train_loss: 0.017387438403523487, valid_loss: 0.017845784916597253\nSEED: 13, FOLD: 1, EPOCH: 15,train_loss: 0.017258044473988855, valid_loss: 0.017684142269632396\nSEED: 13, FOLD: 1, EPOCH: 16,train_loss: 0.01705809850650637, valid_loss: 0.017717647749711487\nSEED: 13, FOLD: 1, EPOCH: 17,train_loss: 0.01683874215012875, valid_loss: 0.017645461210871443\nSEED: 13, FOLD: 1, EPOCH: 18,train_loss: 0.016580521695963715, valid_loss: 0.017639159991898957\nSEED: 13, FOLD: 1, EPOCH: 19,train_loss: 0.01625994769046488, valid_loss: 0.017492340055896956\nSEED: 13, FOLD: 1, EPOCH: 20,train_loss: 0.015783198724460344, valid_loss: 0.017349900540840978\nSEED: 13, FOLD: 1, EPOCH: 21,train_loss: 0.015340244411018448, valid_loss: 0.0173741583712399\nSEED: 13, FOLD: 1, EPOCH: 22,train_loss: 0.014782174841325352, valid_loss: 0.017380303401938257\nSEED: 13, FOLD: 1, EPOCH: 23,train_loss: 0.014352695874707855, valid_loss: 0.01737609746701577\nSEED: 13, FOLD: 1, EPOCH: 24,train_loss: 0.01409412960967292, valid_loss: 0.017383555005140165\nFOLD: 2, EPOCH: 0,train_loss: 0.7366036301937656, valid_loss: 0.6979574629238674\nSEED: 13, FOLD: 2, EPOCH: 0,train_loss: 0.4672749369418707, valid_loss: 0.02405548154243401\nSEED: 13, FOLD: 2, EPOCH: 1,train_loss: 0.020870510164810264, valid_loss: 0.01877286753484181\nSEED: 13, FOLD: 2, EPOCH: 2,train_loss: 0.019017721850263035, valid_loss: 0.018060217105916567\nSEED: 13, FOLD: 2, EPOCH: 3,train_loss: 0.018209881925334532, valid_loss: 0.01843243470149381\nSEED: 13, FOLD: 2, EPOCH: 4,train_loss: 0.017799845640210137, valid_loss: 0.017616314414356436\nSEED: 13, FOLD: 2, EPOCH: 5,train_loss: 0.017858448910756386, valid_loss: 0.017529647052288055\nSEED: 13, FOLD: 2, EPOCH: 6,train_loss: 0.017841202004448227, valid_loss: 0.018340774199792315\nSEED: 13, FOLD: 2, EPOCH: 7,train_loss: 0.01792922578887015, valid_loss: 0.017548976971634798\nSEED: 13, FOLD: 2, EPOCH: 8,train_loss: 0.017858006141108017, valid_loss: 0.01778924763202667\nSEED: 13, FOLD: 2, EPOCH: 9,train_loss: 0.017874616070016138, valid_loss: 0.01854137506868158\nSEED: 13, FOLD: 2, EPOCH: 10,train_loss: 0.01782856588724299, valid_loss: 0.017734042688139846\nSEED: 13, FOLD: 2, EPOCH: 11,train_loss: 0.017754019379777754, valid_loss: 0.017729399699185577\nSEED: 13, FOLD: 2, EPOCH: 12,train_loss: 0.017686723616730043, valid_loss: 0.017575853025274618\nSEED: 13, FOLD: 2, EPOCH: 13,train_loss: 0.01761219763210502, valid_loss: 0.017416602825479847\nSEED: 13, FOLD: 2, EPOCH: 14,train_loss: 0.01750675970148565, valid_loss: 0.01737693284771272\nSEED: 13, FOLD: 2, EPOCH: 15,train_loss: 0.017343272805969784, valid_loss: 0.017364709371966974\nSEED: 13, FOLD: 2, EPOCH: 16,train_loss: 0.017174281929012224, valid_loss: 0.01726728209427425\nSEED: 13, FOLD: 2, EPOCH: 17,train_loss: 0.016920094526764275, valid_loss: 0.017302538667406355\nSEED: 13, FOLD: 2, EPOCH: 18,train_loss: 0.016601978038586138, valid_loss: 0.017251747607120445\nSEED: 13, FOLD: 2, EPOCH: 19,train_loss: 0.016283291790202475, valid_loss: 0.017181449756026267\nSEED: 13, FOLD: 2, EPOCH: 20,train_loss: 0.01592371946848605, valid_loss: 0.0172077444515058\nSEED: 13, FOLD: 2, EPOCH: 21,train_loss: 0.015414050314575434, valid_loss: 0.017169420580778805\nSEED: 13, FOLD: 2, EPOCH: 22,train_loss: 0.0148464595777509, valid_loss: 0.017076330765017442\nSEED: 13, FOLD: 2, EPOCH: 23,train_loss: 0.014462645044145376, valid_loss: 0.017062014474400453\nSEED: 13, FOLD: 2, EPOCH: 24,train_loss: 0.014206603371902653, valid_loss: 0.017054855291332518\nFOLD: 3, EPOCH: 0,train_loss: 0.7360629917931383, valid_loss: 0.6982383591788156\nSEED: 13, FOLD: 3, EPOCH: 0,train_loss: 0.46835557333309286, valid_loss: 0.04239577225276402\nSEED: 13, FOLD: 3, EPOCH: 1,train_loss: 0.02098233608977638, valid_loss: 0.018359334474163398\nSEED: 13, FOLD: 3, EPOCH: 2,train_loss: 0.01895667235944828, valid_loss: 0.017842614517680235\nSEED: 13, FOLD: 3, EPOCH: 3,train_loss: 0.018235009789031788, valid_loss: 0.017644617520272732\nSEED: 13, FOLD: 3, EPOCH: 4,train_loss: 0.017934493244673215, valid_loss: 0.017476844122367247\nSEED: 13, FOLD: 3, EPOCH: 5,train_loss: 0.017850979170116195, valid_loss: 0.017683614763830388\nSEED: 13, FOLD: 3, EPOCH: 6,train_loss: 0.0178460564912997, valid_loss: 0.01746281103364059\nSEED: 13, FOLD: 3, EPOCH: 7,train_loss: 0.017914108762068906, valid_loss: 0.017575715695108685\nSEED: 13, FOLD: 3, EPOCH: 8,train_loss: 0.017886860466079554, valid_loss: 0.01769327361668859\nSEED: 13, FOLD: 3, EPOCH: 9,train_loss: 0.017847482604484488, valid_loss: 0.017786269368869918\nSEED: 13, FOLD: 3, EPOCH: 10,train_loss: 0.01781949224834242, valid_loss: 0.017348269586052213\nSEED: 13, FOLD: 3, EPOCH: 11,train_loss: 0.01779582822545819, valid_loss: 0.017660610564053058\nSEED: 13, FOLD: 3, EPOCH: 12,train_loss: 0.01771503988734997, valid_loss: 0.017613407437290465\nSEED: 13, FOLD: 3, EPOCH: 13,train_loss: 0.017600643183410602, valid_loss: 0.017534049201224533\nSEED: 13, FOLD: 3, EPOCH: 14,train_loss: 0.01742192632416739, valid_loss: 0.017433272781116622\nSEED: 13, FOLD: 3, EPOCH: 15,train_loss: 0.017367727116402918, valid_loss: 0.01713868509978056\nSEED: 13, FOLD: 3, EPOCH: 16,train_loss: 0.017086217302257997, valid_loss: 0.01712141361619745\nSEED: 13, FOLD: 3, EPOCH: 17,train_loss: 0.016891972923202672, valid_loss: 0.017069624470812932\nSEED: 13, FOLD: 3, EPOCH: 18,train_loss: 0.016613056162630556, valid_loss: 0.017106229359550137\nSEED: 13, FOLD: 3, EPOCH: 19,train_loss: 0.016262520526121132, valid_loss: 0.016978261779461587\nSEED: 13, FOLD: 3, EPOCH: 20,train_loss: 0.015850142840921445, valid_loss: 0.016894552218062537\nSEED: 13, FOLD: 3, EPOCH: 21,train_loss: 0.015269562017417302, valid_loss: 0.01687893606722355\nSEED: 13, FOLD: 3, EPOCH: 22,train_loss: 0.014780130808370828, valid_loss: 0.016920251718589237\nSEED: 13, FOLD: 3, EPOCH: 23,train_loss: 0.014326343013748636, valid_loss: 0.01688939207898719\nSEED: 13, FOLD: 3, EPOCH: 24,train_loss: 0.014080487062515568, valid_loss: 0.016896666320306914\nFOLD: 4, EPOCH: 0,train_loss: 0.7358066574500425, valid_loss: 0.6970281992639814\nSEED: 13, FOLD: 4, EPOCH: 0,train_loss: 0.46725835814310684, valid_loss: 0.02436052779001849\nSEED: 13, FOLD: 4, EPOCH: 1,train_loss: 0.020551306759789043, valid_loss: 0.01981885140495641\nSEED: 13, FOLD: 4, EPOCH: 2,train_loss: 0.01886762416901162, valid_loss: 0.01901148547019277\nSEED: 13, FOLD: 4, EPOCH: 3,train_loss: 0.0180602876170382, valid_loss: 0.018630219463791165\nSEED: 13, FOLD: 4, EPOCH: 4,train_loss: 0.017755843059968773, valid_loss: 0.018462735999907765\nSEED: 13, FOLD: 4, EPOCH: 5,train_loss: 0.017751145849589013, valid_loss: 0.01855705284646579\nSEED: 13, FOLD: 4, EPOCH: 6,train_loss: 0.017692608146989433, valid_loss: 0.01856933156294482\nSEED: 13, FOLD: 4, EPOCH: 7,train_loss: 0.017782830143768857, valid_loss: 0.01976637292121138\nSEED: 13, FOLD: 4, EPOCH: 8,train_loss: 0.017729644493682542, valid_loss: 0.018795396494013922\nSEED: 13, FOLD: 4, EPOCH: 9,train_loss: 0.0177652907428624, valid_loss: 0.018519186175295285\nSEED: 13, FOLD: 4, EPOCH: 10,train_loss: 0.017659033750639343, valid_loss: 0.018640389453087533\nSEED: 13, FOLD: 4, EPOCH: 11,train_loss: 0.017616092642075823, valid_loss: 0.0184388774314097\nSEED: 13, FOLD: 4, EPOCH: 12,train_loss: 0.017554332169085522, valid_loss: 0.018161854360784803\nSEED: 13, FOLD: 4, EPOCH: 13,train_loss: 0.01740482021938928, valid_loss: 0.018283563054033686\nSEED: 13, FOLD: 4, EPOCH: 14,train_loss: 0.017358054468122712, valid_loss: 0.01808247236268861\nSEED: 13, FOLD: 4, EPOCH: 15,train_loss: 0.01720541612972526, valid_loss: 0.01834214281822954\nSEED: 13, FOLD: 4, EPOCH: 16,train_loss: 0.01706424878950972, valid_loss: 0.018002024213118212\nSEED: 13, FOLD: 4, EPOCH: 17,train_loss: 0.016772534773025635, valid_loss: 0.018079441413283347\nSEED: 13, FOLD: 4, EPOCH: 18,train_loss: 0.01651256530797177, valid_loss: 0.017947938293218613\nSEED: 13, FOLD: 4, EPOCH: 19,train_loss: 0.016134583425239053, valid_loss: 0.01787981212671314\nSEED: 13, FOLD: 4, EPOCH: 20,train_loss: 0.01573397814003873, valid_loss: 0.017777126282453537\nSEED: 13, FOLD: 4, EPOCH: 21,train_loss: 0.015227200803312942, valid_loss: 0.017687354662588663\nSEED: 13, FOLD: 4, EPOCH: 22,train_loss: 0.014717050997989022, valid_loss: 0.017724876159003804\nSEED: 13, FOLD: 4, EPOCH: 23,train_loss: 0.014271682407027178, valid_loss: 0.017694897231246745\nSEED: 13, FOLD: 4, EPOCH: 24,train_loss: 0.014013282499228516, valid_loss: 0.017705390762005533\nFOLD: 0, EPOCH: 0,train_loss: 0.7360708549402762, valid_loss: 0.7046979052179\nSEED: 14, FOLD: 0, EPOCH: 0,train_loss: 0.46556688011016534, valid_loss: 0.024342049680211964\nSEED: 14, FOLD: 0, EPOCH: 1,train_loss: 0.02065225700051456, valid_loss: 0.019113015821751428\nSEED: 14, FOLD: 0, EPOCH: 2,train_loss: 0.019164679005094196, valid_loss: 0.018402689246132094\nSEED: 14, FOLD: 0, EPOCH: 3,train_loss: 0.01819177137930756, valid_loss: 0.018927152268588543\nSEED: 14, FOLD: 0, EPOCH: 4,train_loss: 0.017909001741234377, valid_loss: 0.01804270808968474\nSEED: 14, FOLD: 0, EPOCH: 5,train_loss: 0.01782451936489214, valid_loss: 0.017986491295125556\nSEED: 14, FOLD: 0, EPOCH: 6,train_loss: 0.017917201327888863, valid_loss: 0.018052035340053195\nSEED: 14, FOLD: 0, EPOCH: 7,train_loss: 0.01792988247251597, valid_loss: 0.018003651981844622\nSEED: 14, FOLD: 0, EPOCH: 8,train_loss: 0.017915123378507036, valid_loss: 0.018262738855007815\nSEED: 14, FOLD: 0, EPOCH: 9,train_loss: 0.017857860011197088, valid_loss: 0.01844032286830685\nSEED: 14, FOLD: 0, EPOCH: 10,train_loss: 0.017823695171408464, valid_loss: 0.01819496295031379\nSEED: 14, FOLD: 0, EPOCH: 11,train_loss: 0.017825962496462507, valid_loss: 0.017901170094880986\nSEED: 14, FOLD: 0, EPOCH: 12,train_loss: 0.01769840924501203, valid_loss: 0.01799169322475791\nSEED: 14, FOLD: 0, EPOCH: 13,train_loss: 0.017650344874709845, valid_loss: 0.01768789837575134\nSEED: 14, FOLD: 0, EPOCH: 14,train_loss: 0.01755053916460146, valid_loss: 0.01779284911668476\nSEED: 14, FOLD: 0, EPOCH: 15,train_loss: 0.01740738410718631, valid_loss: 0.017876391244285247\nSEED: 14, FOLD: 0, EPOCH: 16,train_loss: 0.017175626347138397, valid_loss: 0.017377444159458664\nSEED: 14, FOLD: 0, EPOCH: 17,train_loss: 0.01700156791459607, valid_loss: 0.017406067043981132\nSEED: 14, FOLD: 0, EPOCH: 18,train_loss: 0.01676362471493042, valid_loss: 0.01737658800009419\nSEED: 14, FOLD: 0, EPOCH: 19,train_loss: 0.016326399547034416, valid_loss: 0.01723052854375804\nSEED: 14, FOLD: 0, EPOCH: 20,train_loss: 0.015954190507477175, valid_loss: 0.01719315322663854\nSEED: 14, FOLD: 0, EPOCH: 21,train_loss: 0.015501881166752697, valid_loss: 0.01722057892338318\nSEED: 14, FOLD: 0, EPOCH: 22,train_loss: 0.014980108315206093, valid_loss: 0.017126081182676202\nSEED: 14, FOLD: 0, EPOCH: 23,train_loss: 0.014577005530936995, valid_loss: 0.01715559999951545\nSEED: 14, FOLD: 0, EPOCH: 24,train_loss: 0.014341729348930328, valid_loss: 0.01712925880051711\nFOLD: 1, EPOCH: 0,train_loss: 0.735822396121756, valid_loss: 0.7047783272606986\nSEED: 14, FOLD: 1, EPOCH: 0,train_loss: 0.468090702269743, valid_loss: 0.02393106243440083\nSEED: 14, FOLD: 1, EPOCH: 1,train_loss: 0.021019094508059704, valid_loss: 0.019207225739955903\nSEED: 14, FOLD: 1, EPOCH: 2,train_loss: 0.0189211415330859, valid_loss: 0.0188596746219056\nSEED: 14, FOLD: 1, EPOCH: 3,train_loss: 0.018119892628904243, valid_loss: 0.01840927888240133\nSEED: 14, FOLD: 1, EPOCH: 4,train_loss: 0.01781089816677527, valid_loss: 0.018200824595987798\nSEED: 14, FOLD: 1, EPOCH: 5,train_loss: 0.017711148610896003, valid_loss: 0.0181916816426175\nSEED: 14, FOLD: 1, EPOCH: 6,train_loss: 0.017696967552395634, valid_loss: 0.018180878353970392\nSEED: 14, FOLD: 1, EPOCH: 7,train_loss: 0.01771790931939426, valid_loss: 0.018108599872461387\nSEED: 14, FOLD: 1, EPOCH: 8,train_loss: 0.017719887244603494, valid_loss: 0.01794010709439005\nSEED: 14, FOLD: 1, EPOCH: 9,train_loss: 0.017684338267647873, valid_loss: 0.018165914102324418\nSEED: 14, FOLD: 1, EPOCH: 10,train_loss: 0.017672546357460267, valid_loss: 0.018170574041349547\nSEED: 14, FOLD: 1, EPOCH: 11,train_loss: 0.017613743193937045, valid_loss: 0.018007887846657206\nSEED: 14, FOLD: 1, EPOCH: 12,train_loss: 0.017482237883564764, valid_loss: 0.017967853934637137\nSEED: 14, FOLD: 1, EPOCH: 13,train_loss: 0.017433113663246597, valid_loss: 0.018248264491558076\nSEED: 14, FOLD: 1, EPOCH: 14,train_loss: 0.017283964473890127, valid_loss: 0.018004860383059297\nSEED: 14, FOLD: 1, EPOCH: 15,train_loss: 0.01712482226808576, valid_loss: 0.017844957139875207\nSEED: 14, FOLD: 1, EPOCH: 16,train_loss: 0.01694527132450229, valid_loss: 0.017580779428992954\nSEED: 14, FOLD: 1, EPOCH: 17,train_loss: 0.01669581880942531, valid_loss: 0.01788903943129948\nSEED: 14, FOLD: 1, EPOCH: 18,train_loss: 0.016385072556725385, valid_loss: 0.017509198428264688\nSEED: 14, FOLD: 1, EPOCH: 19,train_loss: 0.016028043569276368, valid_loss: 0.01757023845400129\nSEED: 14, FOLD: 1, EPOCH: 20,train_loss: 0.015587863111256683, valid_loss: 0.017689739247517926\nSEED: 14, FOLD: 1, EPOCH: 21,train_loss: 0.015085834669914559, valid_loss: 0.017523370257445745\nSEED: 14, FOLD: 1, EPOCH: 22,train_loss: 0.014514251775278228, valid_loss: 0.017592413856514864\nSEED: 14, FOLD: 1, EPOCH: 23,train_loss: 0.014042374256481655, valid_loss: 0.017508890772504466\nSEED: 14, FOLD: 1, EPOCH: 24,train_loss: 0.013784025279111671, valid_loss: 0.017532037278371198\nFOLD: 2, EPOCH: 0,train_loss: 0.7362075042033541, valid_loss: 0.7039201347266927\nSEED: 14, FOLD: 2, EPOCH: 0,train_loss: 0.4677226970755104, valid_loss: 0.025411075967199662\nSEED: 14, FOLD: 2, EPOCH: 1,train_loss: 0.020530616365157177, valid_loss: 0.018724228584152812\nSEED: 14, FOLD: 2, EPOCH: 2,train_loss: 0.019173106664548748, valid_loss: 0.018441418788450605\nSEED: 14, FOLD: 2, EPOCH: 3,train_loss: 0.018584869106880564, valid_loss: 0.017925747889367974\nSEED: 14, FOLD: 2, EPOCH: 4,train_loss: 0.018012111547632492, valid_loss: 0.01781171390458065\nSEED: 14, FOLD: 2, EPOCH: 5,train_loss: 0.01792141581899014, valid_loss: 0.018007474020123482\nSEED: 14, FOLD: 2, EPOCH: 6,train_loss: 0.017900956342455702, valid_loss: 0.017912296906990165\nSEED: 14, FOLD: 2, EPOCH: 7,train_loss: 0.017860724685200745, valid_loss: 0.018163977300419527\nSEED: 14, FOLD: 2, EPOCH: 8,train_loss: 0.017862160595646805, valid_loss: 0.01788021709002993\nSEED: 14, FOLD: 2, EPOCH: 9,train_loss: 0.017869324396377888, valid_loss: 0.01791045055998599\nSEED: 14, FOLD: 2, EPOCH: 10,train_loss: 0.017830843915757927, valid_loss: 0.017975769608336335\nSEED: 14, FOLD: 2, EPOCH: 11,train_loss: 0.017801774422759594, valid_loss: 0.017864895929746768\nSEED: 14, FOLD: 2, EPOCH: 12,train_loss: 0.01775314759436077, valid_loss: 0.01777570593335173\nSEED: 14, FOLD: 2, EPOCH: 13,train_loss: 0.0175968994035561, valid_loss: 0.01764247547287275\nSEED: 14, FOLD: 2, EPOCH: 14,train_loss: 0.017523016389189423, valid_loss: 0.01748334731468383\nSEED: 14, FOLD: 2, EPOCH: 15,train_loss: 0.017274585377047028, valid_loss: 0.017541023436933756\nSEED: 14, FOLD: 2, EPOCH: 16,train_loss: 0.017114586466788383, valid_loss: 0.017298489726860735\nSEED: 14, FOLD: 2, EPOCH: 17,train_loss: 0.016902209198831217, valid_loss: 0.01731440011302338\nSEED: 14, FOLD: 2, EPOCH: 18,train_loss: 0.016564908309205286, valid_loss: 0.017359855612192082\nSEED: 14, FOLD: 2, EPOCH: 19,train_loss: 0.01629093232686105, valid_loss: 0.017240585348404506\nSEED: 14, FOLD: 2, EPOCH: 20,train_loss: 0.015866003350179264, valid_loss: 0.017277106177061796\nSEED: 14, FOLD: 2, EPOCH: 21,train_loss: 0.015409110923824102, valid_loss: 0.017163652187103733\nSEED: 14, FOLD: 2, EPOCH: 22,train_loss: 0.014900847263904154, valid_loss: 0.01716785614981371\nSEED: 14, FOLD: 2, EPOCH: 23,train_loss: 0.014480168121340483, valid_loss: 0.017167906852110344\nSEED: 14, FOLD: 2, EPOCH: 24,train_loss: 0.014262028888839743, valid_loss: 0.017161503735491457\nFOLD: 3, EPOCH: 0,train_loss: 0.7357473521337022, valid_loss: 0.7021662303379603\nSEED: 14, FOLD: 3, EPOCH: 0,train_loss: 0.46762287982460793, valid_loss: 0.023221424009118762\nSEED: 14, FOLD: 3, EPOCH: 1,train_loss: 0.021444835489357474, valid_loss: 0.01893228122166225\nSEED: 14, FOLD: 3, EPOCH: 2,train_loss: 0.019139767685619584, valid_loss: 0.018194148290370193\nSEED: 14, FOLD: 3, EPOCH: 3,train_loss: 0.018291889329570054, valid_loss: 0.0181078491466386\nSEED: 14, FOLD: 3, EPOCH: 4,train_loss: 0.018021769597310656, valid_loss: 0.018428454734385015\nSEED: 14, FOLD: 3, EPOCH: 5,train_loss: 0.017849547081511385, valid_loss: 0.018033953197300435\nSEED: 14, FOLD: 3, EPOCH: 6,train_loss: 0.017831514120428233, valid_loss: 0.01825541832617351\nSEED: 14, FOLD: 3, EPOCH: 7,train_loss: 0.017805509588742344, valid_loss: 0.01795510367623397\nSEED: 14, FOLD: 3, EPOCH: 8,train_loss: 0.017810461417275623, valid_loss: 0.01813273163778441\nSEED: 14, FOLD: 3, EPOCH: 9,train_loss: 0.01779204297022228, valid_loss: 0.017960520035454206\nSEED: 14, FOLD: 3, EPOCH: 10,train_loss: 0.017773252864279887, valid_loss: 0.01810164994427136\nSEED: 14, FOLD: 3, EPOCH: 11,train_loss: 0.017729098738653817, valid_loss: 0.01797051224857569\nSEED: 14, FOLD: 3, EPOCH: 12,train_loss: 0.017626072150947403, valid_loss: 0.017842001122023377\nSEED: 14, FOLD: 3, EPOCH: 13,train_loss: 0.017528907559050694, valid_loss: 0.018145939175571713\nSEED: 14, FOLD: 3, EPOCH: 14,train_loss: 0.017485155173353036, valid_loss: 0.017698495169835432\nSEED: 14, FOLD: 3, EPOCH: 15,train_loss: 0.01720354296131073, valid_loss: 0.017582418423678192\nSEED: 14, FOLD: 3, EPOCH: 16,train_loss: 0.017128997353197884, valid_loss: 0.017702331926141467\nSEED: 14, FOLD: 3, EPOCH: 17,train_loss: 0.016830581940547394, valid_loss: 0.017683295160532\nSEED: 14, FOLD: 3, EPOCH: 18,train_loss: 0.016529376536988428, valid_loss: 0.01751261225768498\nSEED: 14, FOLD: 3, EPOCH: 19,train_loss: 0.016157127237015397, valid_loss: 0.017559454643300602\nSEED: 14, FOLD: 3, EPOCH: 20,train_loss: 0.015734709921653253, valid_loss: 0.017481589503586293\nSEED: 14, FOLD: 3, EPOCH: 21,train_loss: 0.015241999994881832, valid_loss: 0.01752658834947007\nSEED: 14, FOLD: 3, EPOCH: 22,train_loss: 0.01471694637035584, valid_loss: 0.01748231604163136\nSEED: 14, FOLD: 3, EPOCH: 23,train_loss: 0.014281473666375135, valid_loss: 0.017521965876221658\nSEED: 14, FOLD: 3, EPOCH: 24,train_loss: 0.0140609118176529, valid_loss: 0.01750328160290207\nFOLD: 4, EPOCH: 0,train_loss: 0.7362167891794748, valid_loss: 0.7045777354921613\nSEED: 14, FOLD: 4, EPOCH: 0,train_loss: 0.46820404717739483, valid_loss: 0.02331676483154297\nSEED: 14, FOLD: 4, EPOCH: 1,train_loss: 0.02099543310919382, valid_loss: 0.01859829926065036\nSEED: 14, FOLD: 4, EPOCH: 2,train_loss: 0.019246135450845216, valid_loss: 0.01777797479714666\nSEED: 14, FOLD: 4, EPOCH: 3,train_loss: 0.018380077147897144, valid_loss: 0.017536558530160357\nSEED: 14, FOLD: 4, EPOCH: 4,train_loss: 0.01815273973710128, valid_loss: 0.017456520135913575\nSEED: 14, FOLD: 4, EPOCH: 5,train_loss: 0.018008469617551696, valid_loss: 0.01757645420730114\nSEED: 14, FOLD: 4, EPOCH: 6,train_loss: 0.017996707360131026, valid_loss: 0.01742872249867235\nSEED: 14, FOLD: 4, EPOCH: 7,train_loss: 0.017938253959219386, valid_loss: 0.017416326036410672\nSEED: 14, FOLD: 4, EPOCH: 8,train_loss: 0.017913472893083617, valid_loss: 0.017790356491293225\nSEED: 14, FOLD: 4, EPOCH: 9,train_loss: 0.017896357984927884, valid_loss: 0.017402914565588748\nSEED: 14, FOLD: 4, EPOCH: 10,train_loss: 0.01790921356066735, valid_loss: 0.01779021437146834\nSEED: 14, FOLD: 4, EPOCH: 11,train_loss: 0.017805366980822853, valid_loss: 0.017407304527504105\nSEED: 14, FOLD: 4, EPOCH: 12,train_loss: 0.017723445698999574, valid_loss: 0.01762829555996827\nSEED: 14, FOLD: 4, EPOCH: 13,train_loss: 0.01764666098068013, valid_loss: 0.017311919986137323\nSEED: 14, FOLD: 4, EPOCH: 14,train_loss: 0.0175842389015712, valid_loss: 0.01713889121477093\nSEED: 14, FOLD: 4, EPOCH: 15,train_loss: 0.017344768016333997, valid_loss: 0.017286636334444796\nSEED: 14, FOLD: 4, EPOCH: 16,train_loss: 0.01719936636025018, valid_loss: 0.017272234814507622\nSEED: 14, FOLD: 4, EPOCH: 17,train_loss: 0.016959444959613965, valid_loss: 0.01701984754098313\nSEED: 14, FOLD: 4, EPOCH: 18,train_loss: 0.01671367751801536, valid_loss: 0.016898854289736066\nSEED: 14, FOLD: 4, EPOCH: 19,train_loss: 0.016359015231965666, valid_loss: 0.016806798720998422\nSEED: 14, FOLD: 4, EPOCH: 20,train_loss: 0.01590078878114476, valid_loss: 0.017049618091966423\nSEED: 14, FOLD: 4, EPOCH: 21,train_loss: 0.015451743709344934, valid_loss: 0.016879074568195002\nSEED: 14, FOLD: 4, EPOCH: 22,train_loss: 0.014940150755110883, valid_loss: 0.016880853367703303\nSEED: 14, FOLD: 4, EPOCH: 23,train_loss: 0.014497934473528915, valid_loss: 0.01685051933995315\nSEED: 14, FOLD: 4, EPOCH: 24,train_loss: 0.014275778805578712, valid_loss: 0.016865245944687298\nFOLD: 0, EPOCH: 0,train_loss: 0.7379673697652608, valid_loss: 0.7077575530324663\nSEED: 15, FOLD: 0, EPOCH: 0,train_loss: 0.4692861087293956, valid_loss: 0.02309498888041292\nSEED: 15, FOLD: 0, EPOCH: 1,train_loss: 0.021166248736481597, valid_loss: 0.01949892890240465\nSEED: 15, FOLD: 0, EPOCH: 2,train_loss: 0.018871127784143397, valid_loss: 0.018354169146290848\nSEED: 15, FOLD: 0, EPOCH: 3,train_loss: 0.018050563929561714, valid_loss: 0.018593418332082886\nSEED: 15, FOLD: 0, EPOCH: 4,train_loss: 0.01783255322489643, valid_loss: 0.018374921647565705\nSEED: 15, FOLD: 0, EPOCH: 5,train_loss: 0.017781357403273565, valid_loss: 0.018136406849537576\nSEED: 15, FOLD: 0, EPOCH: 6,train_loss: 0.01777082193561279, valid_loss: 0.01817687659391335\nSEED: 15, FOLD: 0, EPOCH: 7,train_loss: 0.017764625615392722, valid_loss: 0.018289615187261785\nSEED: 15, FOLD: 0, EPOCH: 8,train_loss: 0.017768401999271263, valid_loss: 0.018108712136745454\nSEED: 15, FOLD: 0, EPOCH: 9,train_loss: 0.017745517241856912, valid_loss: 0.0179004325398377\nSEED: 15, FOLD: 0, EPOCH: 10,train_loss: 0.017762064308363155, valid_loss: 0.01805737843470914\nSEED: 15, FOLD: 0, EPOCH: 11,train_loss: 0.017658991650780186, valid_loss: 0.018025856757802623\nSEED: 15, FOLD: 0, EPOCH: 12,train_loss: 0.017633060523628317, valid_loss: 0.01794961839914322\nSEED: 15, FOLD: 0, EPOCH: 13,train_loss: 0.017544067226839762, valid_loss: 0.01811728123575449\nSEED: 15, FOLD: 0, EPOCH: 14,train_loss: 0.01740733581003699, valid_loss: 0.0179046504465597\nSEED: 15, FOLD: 0, EPOCH: 15,train_loss: 0.017222027396307373, valid_loss: 0.017954814859798978\nSEED: 15, FOLD: 0, EPOCH: 16,train_loss: 0.017006594626518497, valid_loss: 0.017777401661234243\nSEED: 15, FOLD: 0, EPOCH: 17,train_loss: 0.016823047704070154, valid_loss: 0.01768721698650292\nSEED: 15, FOLD: 0, EPOCH: 18,train_loss: 0.016495412711842652, valid_loss: 0.017732912009315833\nSEED: 15, FOLD: 0, EPOCH: 19,train_loss: 0.01616171224681783, valid_loss: 0.017727799766830036\nSEED: 15, FOLD: 0, EPOCH: 20,train_loss: 0.015744956217053598, valid_loss: 0.01764677789594446\nSEED: 15, FOLD: 0, EPOCH: 21,train_loss: 0.015240215179748344, valid_loss: 0.017610377711909157\nSEED: 15, FOLD: 0, EPOCH: 22,train_loss: 0.014729427996288687, valid_loss: 0.01766145785472223\nSEED: 15, FOLD: 0, EPOCH: 23,train_loss: 0.014270727889761872, valid_loss: 0.01761723200657538\nSEED: 15, FOLD: 0, EPOCH: 24,train_loss: 0.01402055054739879, valid_loss: 0.017626784555613995\n********************\nFlops for KAN: 37853010\n********************\nFOLD: 1, EPOCH: 0,train_loss: 0.7375899773576985, valid_loss: 0.7117770501545497\nSEED: 15, FOLD: 1, EPOCH: 0,train_loss: 0.46769667620622163, valid_loss: 0.024505229241081648\nSEED: 15, FOLD: 1, EPOCH: 1,train_loss: 0.021153301270543667, valid_loss: 0.02685963623225689\nSEED: 15, FOLD: 1, EPOCH: 2,train_loss: 0.019852538201687992, valid_loss: 0.020138745275991302\nSEED: 15, FOLD: 1, EPOCH: 3,train_loss: 0.018572834455340668, valid_loss: 0.0189163994842342\nSEED: 15, FOLD: 1, EPOCH: 4,train_loss: 0.018189551403233105, valid_loss: 0.019766557669000966\nSEED: 15, FOLD: 1, EPOCH: 5,train_loss: 0.018080178587494986, valid_loss: 0.01808604212211711\nSEED: 15, FOLD: 1, EPOCH: 6,train_loss: 0.018067667112294315, valid_loss: 0.019522660624768054\nSEED: 15, FOLD: 1, EPOCH: 7,train_loss: 0.018067025242076405, valid_loss: 0.018277526700070927\nSEED: 15, FOLD: 1, EPOCH: 8,train_loss: 0.018004237755161266, valid_loss: 0.018240386274244104\nSEED: 15, FOLD: 1, EPOCH: 9,train_loss: 0.017953324192406042, valid_loss: 0.018464970269373486\nSEED: 15, FOLD: 1, EPOCH: 10,train_loss: 0.01796208210694401, valid_loss: 0.017884801674102033\nSEED: 15, FOLD: 1, EPOCH: 11,train_loss: 0.017879005960202303, valid_loss: 0.01953676018331732\nSEED: 15, FOLD: 1, EPOCH: 12,train_loss: 0.017956312124927837, valid_loss: 0.017749670733298573\nSEED: 15, FOLD: 1, EPOCH: 13,train_loss: 0.017765951160665438, valid_loss: 0.017909031627433642\nSEED: 15, FOLD: 1, EPOCH: 14,train_loss: 0.017623415189808693, valid_loss: 0.01784303869519915\nSEED: 15, FOLD: 1, EPOCH: 15,train_loss: 0.01744244207182656, valid_loss: 0.017599320118980747\nSEED: 15, FOLD: 1, EPOCH: 16,train_loss: 0.017406191535132086, valid_loss: 0.01754045414605311\nSEED: 15, FOLD: 1, EPOCH: 17,train_loss: 0.017066571024664932, valid_loss: 0.01746491135231086\nSEED: 15, FOLD: 1, EPOCH: 18,train_loss: 0.01686951470817777, valid_loss: 0.017401147314480375\nSEED: 15, FOLD: 1, EPOCH: 19,train_loss: 0.016454713257110638, valid_loss: 0.017282242966549736\nSEED: 15, FOLD: 1, EPOCH: 20,train_loss: 0.016032412250026846, valid_loss: 0.017276440214897906\nSEED: 15, FOLD: 1, EPOCH: 21,train_loss: 0.015701828328757616, valid_loss: 0.017214745176689965\nSEED: 15, FOLD: 1, EPOCH: 22,train_loss: 0.015361871124933596, valid_loss: 0.017152350156434945\nSEED: 15, FOLD: 1, EPOCH: 23,train_loss: 0.015010875278570946, valid_loss: 0.017158693793628898\nSEED: 15, FOLD: 1, EPOCH: 24,train_loss: 0.014837645648884169, valid_loss: 0.0171873343576278\n********************\nFlops for KAN: 37853010\n********************\nFOLD: 2, EPOCH: 0,train_loss: 0.7372323253016541, valid_loss: 0.7095335353823269\nSEED: 15, FOLD: 2, EPOCH: 0,train_loss: 0.4672635174288914, valid_loss: 0.02667572332874817\nSEED: 15, FOLD: 2, EPOCH: 1,train_loss: 0.020885510815550453, valid_loss: 0.018495790030368987\nSEED: 15, FOLD: 2, EPOCH: 2,train_loss: 0.019164070824458115, valid_loss: 0.018158765153630692\nSEED: 15, FOLD: 2, EPOCH: 3,train_loss: 0.01835393813857134, valid_loss: 0.01777347330661381\nSEED: 15, FOLD: 2, EPOCH: 4,train_loss: 0.018061104824469574, valid_loss: 0.01794916476287386\nSEED: 15, FOLD: 2, EPOCH: 5,train_loss: 0.017952154377016468, valid_loss: 0.017592179123312235\nSEED: 15, FOLD: 2, EPOCH: 6,train_loss: 0.017974557091846415, valid_loss: 0.017525136224268115\nSEED: 15, FOLD: 2, EPOCH: 7,train_loss: 0.017940601914365223, valid_loss: 0.017715605359305355\nSEED: 15, FOLD: 2, EPOCH: 8,train_loss: 0.018019959310312635, valid_loss: 0.01765538683599409\nSEED: 15, FOLD: 2, EPOCH: 9,train_loss: 0.017981967105921627, valid_loss: 0.01837828314370092\nSEED: 15, FOLD: 2, EPOCH: 10,train_loss: 0.01792799014652121, valid_loss: 0.017606808502665338\nSEED: 15, FOLD: 2, EPOCH: 11,train_loss: 0.017903976459596037, valid_loss: 0.01744199777022004\nSEED: 15, FOLD: 2, EPOCH: 12,train_loss: 0.017773738461614088, valid_loss: 0.017577404457637492\nSEED: 15, FOLD: 2, EPOCH: 13,train_loss: 0.01768023486289641, valid_loss: 0.017448559841688943\nSEED: 15, FOLD: 2, EPOCH: 14,train_loss: 0.01759482966735959, valid_loss: 0.017461234155823204\nSEED: 15, FOLD: 2, EPOCH: 15,train_loss: 0.017459415904907644, valid_loss: 0.01731054964201415\nSEED: 15, FOLD: 2, EPOCH: 16,train_loss: 0.01718880711933193, valid_loss: 0.017251937978846187\nSEED: 15, FOLD: 2, EPOCH: 17,train_loss: 0.01700430505139672, valid_loss: 0.017271352630546865\nSEED: 15, FOLD: 2, EPOCH: 18,train_loss: 0.01674138141148116, valid_loss: 0.017125517924261445\nSEED: 15, FOLD: 2, EPOCH: 19,train_loss: 0.016440680736432903, valid_loss: 0.017110212897772297\nSEED: 15, FOLD: 2, EPOCH: 20,train_loss: 0.016048275487686413, valid_loss: 0.017018563716727143\nSEED: 15, FOLD: 2, EPOCH: 21,train_loss: 0.015537167946551588, valid_loss: 0.017014005084467286\nSEED: 15, FOLD: 2, EPOCH: 22,train_loss: 0.015032656652771908, valid_loss: 0.017084868624806404\nSEED: 15, FOLD: 2, EPOCH: 23,train_loss: 0.014600303226515003, valid_loss: 0.01706789168255294\nSEED: 15, FOLD: 2, EPOCH: 24,train_loss: 0.014393798777482647, valid_loss: 0.017043453586452147\n********************\nFlops for KAN: 37853010\n********************\nFOLD: 3, EPOCH: 0,train_loss: 0.7372226641661879, valid_loss: 0.7081945266042436\nSEED: 15, FOLD: 3, EPOCH: 0,train_loss: 0.4672669482457897, valid_loss: 0.024577405782682554\nSEED: 15, FOLD: 3, EPOCH: 1,train_loss: 0.020925501536955868, valid_loss: 0.023560422073517526\nSEED: 15, FOLD: 3, EPOCH: 2,train_loss: 0.019641867224666952, valid_loss: 0.022270216792821883\nSEED: 15, FOLD: 3, EPOCH: 3,train_loss: 0.01895011282539454, valid_loss: 0.018688013244952475\nSEED: 15, FOLD: 3, EPOCH: 4,train_loss: 0.018501763812441757, valid_loss: 0.018435482893671307\nSEED: 15, FOLD: 3, EPOCH: 5,train_loss: 0.01815644765029783, valid_loss: 0.01847660658614976\nSEED: 15, FOLD: 3, EPOCH: 6,train_loss: 0.018100665807993948, valid_loss: 0.018621448853186198\nSEED: 15, FOLD: 3, EPOCH: 7,train_loss: 0.018099319540720055, valid_loss: 0.018471248660768783\nSEED: 15, FOLD: 3, EPOCH: 8,train_loss: 0.018241466454945614, valid_loss: 0.01878108563167708\nSEED: 15, FOLD: 3, EPOCH: 9,train_loss: 0.017922297967057944, valid_loss: 0.01830595135688782\nSEED: 15, FOLD: 3, EPOCH: 10,train_loss: 0.017905650424190622, valid_loss: 0.018397927018148557\nSEED: 15, FOLD: 3, EPOCH: 11,train_loss: 0.017986759874105886, valid_loss: 0.01814440669757979\nSEED: 15, FOLD: 3, EPOCH: 12,train_loss: 0.017950253176462393, valid_loss: 0.018478767041649136\nSEED: 15, FOLD: 3, EPOCH: 13,train_loss: 0.01789221253273064, valid_loss: 0.01789959514779704\nSEED: 15, FOLD: 3, EPOCH: 14,train_loss: 0.017568464930830658, valid_loss: 0.017637269624641964\nSEED: 15, FOLD: 3, EPOCH: 15,train_loss: 0.01750668178083024, valid_loss: 0.017723491468599865\nSEED: 15, FOLD: 3, EPOCH: 16,train_loss: 0.017299031562077394, valid_loss: 0.01769501848944596\nSEED: 15, FOLD: 3, EPOCH: 17,train_loss: 0.017143360231125702, valid_loss: 0.0175266297268016\nSEED: 15, FOLD: 3, EPOCH: 18,train_loss: 0.017056164102277893, valid_loss: 0.017419441869216307\nSEED: 15, FOLD: 3, EPOCH: 19,train_loss: 0.016772357672722876, valid_loss: 0.01730035615286657\nSEED: 15, FOLD: 3, EPOCH: 20,train_loss: 0.016494828795987196, valid_loss: 0.01714701442314046\nSEED: 15, FOLD: 3, EPOCH: 21,train_loss: 0.016268572189669678, valid_loss: 0.01712176025445972\nSEED: 15, FOLD: 3, EPOCH: 22,train_loss: 0.01579997347721803, valid_loss: 0.017058713787368365\nSEED: 15, FOLD: 3, EPOCH: 23,train_loss: 0.015563979319742193, valid_loss: 0.017004938716334957\nSEED: 15, FOLD: 3, EPOCH: 24,train_loss: 0.015277769369329664, valid_loss: 0.017017856346709388\n********************\nFlops for KAN: 37853010\n********************\nFOLD: 4, EPOCH: 0,train_loss: 0.7375878138818602, valid_loss: 0.7113643714359829\nSEED: 15, FOLD: 4, EPOCH: 0,train_loss: 0.46691700470620306, valid_loss: 0.024442587101033756\nSEED: 15, FOLD: 4, EPOCH: 1,train_loss: 0.021007755352859047, valid_loss: 0.018810262504432882\nSEED: 15, FOLD: 4, EPOCH: 2,train_loss: 0.019045635679925697, valid_loss: 0.020557447682533946\nSEED: 15, FOLD: 4, EPOCH: 3,train_loss: 0.01837724619342581, valid_loss: 0.019664420027818\nSEED: 15, FOLD: 4, EPOCH: 4,train_loss: 0.01812182711032422, valid_loss: 0.018322608593319144\nSEED: 15, FOLD: 4, EPOCH: 5,train_loss: 0.017901404443588377, valid_loss: 0.017837157446358887\nSEED: 15, FOLD: 4, EPOCH: 6,train_loss: 0.017931098914772705, valid_loss: 0.017983918849911008\nSEED: 15, FOLD: 4, EPOCH: 7,train_loss: 0.018011806458504736, valid_loss: 0.017806695029139518\nSEED: 15, FOLD: 4, EPOCH: 8,train_loss: 0.018011567209833775, valid_loss: 0.018069420249334403\nSEED: 15, FOLD: 4, EPOCH: 9,train_loss: 0.017949625208595957, valid_loss: 0.017749613683138574\nSEED: 15, FOLD: 4, EPOCH: 10,train_loss: 0.017911057406361553, valid_loss: 0.018230479742799486\nSEED: 15, FOLD: 4, EPOCH: 11,train_loss: 0.01785524547154057, valid_loss: 0.01769071314483881\nSEED: 15, FOLD: 4, EPOCH: 12,train_loss: 0.017746111695263266, valid_loss: 0.01830071069832359\nSEED: 15, FOLD: 4, EPOCH: 13,train_loss: 0.017664631781424734, valid_loss: 0.017577563412487507\nSEED: 15, FOLD: 4, EPOCH: 14,train_loss: 0.017530814380101536, valid_loss: 0.017540683411061762\nSEED: 15, FOLD: 4, EPOCH: 15,train_loss: 0.017359088181747473, valid_loss: 0.017474219415869033\nSEED: 15, FOLD: 4, EPOCH: 16,train_loss: 0.017198020572085745, valid_loss: 0.017624161977853093\nSEED: 15, FOLD: 4, EPOCH: 17,train_loss: 0.017093191409240597, valid_loss: 0.01734913403966597\nSEED: 15, FOLD: 4, EPOCH: 18,train_loss: 0.01677768064689809, valid_loss: 0.01733087950519153\nSEED: 15, FOLD: 4, EPOCH: 19,train_loss: 0.0163558477036439, valid_loss: 0.017065861714737757\nSEED: 15, FOLD: 4, EPOCH: 20,train_loss: 0.016019360945168613, valid_loss: 0.017164818729673112\nSEED: 15, FOLD: 4, EPOCH: 21,train_loss: 0.015494442571872387, valid_loss: 0.017026005392628055\nSEED: 15, FOLD: 4, EPOCH: 22,train_loss: 0.015013550711876673, valid_loss: 0.017104012492511953\nSEED: 15, FOLD: 4, EPOCH: 23,train_loss: 0.014603318039165892, valid_loss: 0.01705824751406908\nSEED: 15, FOLD: 4, EPOCH: 24,train_loss: 0.014405273434206627, valid_loss: 0.017076316076729978\n********************\nFlops for KAN: 37853010\n********************\n0.016726018506983034\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"pd.DataFrame(sc_dic,index=['sc']).T","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T08:43:22.174715Z","iopub.execute_input":"2025-01-16T08:43:22.175070Z","iopub.status.idle":"2025-01-16T08:43:22.190751Z","shell.execute_reply.started":"2025-01-16T08:43:22.175040Z","shell.execute_reply":"2025-01-16T08:43:22.189756Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"          sc\n0   0.017171\n1   0.016952\n2   0.016866\n3   0.016827\n4   0.016794\n5   0.016779\n6   0.016767\n7   0.016759\n8   0.016748\n9   0.016746\n10  0.016740\n11  0.016735\n12  0.016730\n13  0.016730\n14  0.016729\n15  0.016726","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.017171</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.016952</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.016866</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.016827</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.016794</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.016779</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.016767</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.016759</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.016748</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.016746</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.016740</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.016735</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.016730</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.016730</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.016729</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.016726</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}